#!/usr/bin/env node

/**
 * @fileoverview é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶ä¸“é¡¹æµ‹è¯•
 *
 * æµ‹è¯•é”™è¯¯å¤„ç†å’Œé‡è¯•ç®¡ç†å™¨çš„å„ç§åœºæ™¯ï¼š
 * - é‡è¯•ç®¡ç†å™¨çš„ç­–ç•¥å’Œç®—æ³•éªŒè¯
 * - ç†”æ–­å™¨çŠ¶æ€åˆ‡æ¢å’Œæ¢å¤æµ‹è¯•
 * - é”™è¯¯åˆ†ç±»å’Œå¤„ç†ç­–ç•¥éªŒè¯
 * - ç›‘æ§æŒ‡æ ‡æ”¶é›†å’Œç»Ÿè®¡æµ‹è¯•
 * - å¤šç»„ä»¶é”™è¯¯éš”ç¦»æµ‹è¯•
 * - æ•…éšœæ¢å¤å’Œé™çº§æœºåˆ¶éªŒè¯
 *
 * @author Claude Code
 * @version 1.0.0
 */

const { performance } = require('perf_hooks')
const chalk = require('chalk')
const EventEmitter = require('events')

// å¯¼å…¥æ ¸å¿ƒæ¨¡å—
const logger = require('../src/utils/logger')

// æµ‹è¯•é…ç½®
const TEST_CONFIG = {
  retryTests: {
    maxRetries: 5,
    baseDelay: 100,
    maxDelay: 5000,
    backoffMultiplier: 2
  },

  circuitBreaker: {
    failureThreshold: 5,
    recoveryTimeout: 2000,
    monitoringWindow: 10000
  },

  errorScenarios: {
    networkErrors: ['ECONNRESET', 'ENOTFOUND', 'ETIMEDOUT'],
    apiErrors: [429, 500, 502, 503, 504],
    applicationErrors: ['ValidationError', 'AuthenticationError', 'RateLimitError']
  },

  performance: {
    maxRetryTime: 10000,
    maxRecoveryTime: 5000,
    minThroughput: 10
  },

  testDuration: {
    unit: 5000, // å•ä¸ªæµ‹è¯• 5ç§’
    stress: 15000, // å‹åŠ›æµ‹è¯• 15ç§’
    recovery: 10000 // æ¢å¤æµ‹è¯• 10ç§’
  },

  verbose: process.argv.includes('--verbose') || process.argv.includes('-v'),
  profile: process.argv.includes('--profile') || process.argv.includes('-p')
}

/**
 * é‡è¯•ç®¡ç†å™¨å®ç°
 */
class RetryManager extends EventEmitter {
  constructor(options = {}) {
    super()

    this.options = {
      maxRetries: options.maxRetries || 3,
      baseDelay: options.baseDelay || 1000,
      maxDelay: options.maxDelay || 30000,
      backoffMultiplier: options.backoffMultiplier || 2,
      jitter: options.jitter !== false,
      retryableErrors: options.retryableErrors || ['ECONNRESET', 'ETIMEDOUT', 'ENOTFOUND'],
      ...options
    }

    this.stats = {
      totalAttempts: 0,
      totalRetries: 0,
      successfulRetries: 0,
      failedRetries: 0,
      avgRetryDelay: 0,
      errorTypes: new Map()
    }
  }

  async executeWithRetry(fn, context = {}) {
    let lastError
    let attempt = 0
    const startTime = performance.now()

    while (attempt <= this.options.maxRetries) {
      try {
        this.stats.totalAttempts++

        const result = await fn(attempt, context)

        if (attempt > 0) {
          this.stats.successfulRetries++
          this.emit('retrySuccess', { attempt, context, duration: performance.now() - startTime })
        }

        return result
      } catch (error) {
        lastError = error
        attempt++

        // è®°å½•é”™è¯¯ç±»å‹
        const errorType = this.classifyError(error)
        this.stats.errorTypes.set(errorType, (this.stats.errorTypes.get(errorType) || 0) + 1)

        if (attempt <= this.options.maxRetries && this.shouldRetry(error)) {
          this.stats.totalRetries++

          const delay = this.calculateDelay(attempt)
          this.stats.avgRetryDelay =
            (this.stats.avgRetryDelay * (this.stats.totalRetries - 1) + delay) /
            this.stats.totalRetries

          this.emit('retryAttempt', { attempt, error, delay, context })

          await this.sleep(delay)
        } else {
          break
        }
      }
    }

    this.stats.failedRetries++
    this.emit('retryFailed', { attempts: attempt, error: lastError, context })
    throw lastError
  }

  shouldRetry(error) {
    const errorType = this.classifyError(error)

    // ç½‘ç»œé”™è¯¯ - é‡è¯•
    if (this.options.retryableErrors.includes(error.code)) {
      return true
    }

    // HTTPçŠ¶æ€ç é”™è¯¯
    if (error.status) {
      const retryableStatuses = [429, 500, 502, 503, 504]
      return retryableStatuses.includes(error.status)
    }

    // è¶…æ—¶é”™è¯¯ - é‡è¯•
    if (error.message.includes('timeout') || error.message.includes('TIMEOUT')) {
      return true
    }

    // è®¤è¯é”™è¯¯ - ä¸é‡è¯•
    if (error.status === 401 || error.status === 403) {
      return false
    }

    // å®¢æˆ·ç«¯é”™è¯¯ - ä¸é‡è¯•
    if (error.status >= 400 && error.status < 500 && error.status !== 429) {
      return false
    }

    return false
  }

  classifyError(error) {
    if (error.code) {
      return `NetworkError:${error.code}`
    }

    if (error.status) {
      return `HTTPError:${error.status}`
    }

    if (error.name) {
      return `ApplicationError:${error.name}`
    }

    return 'UnknownError'
  }

  calculateDelay(attempt) {
    let delay = this.options.baseDelay * Math.pow(this.options.backoffMultiplier, attempt - 1)

    // é™åˆ¶æœ€å¤§å»¶è¿Ÿ
    delay = Math.min(delay, this.options.maxDelay)

    // æ·»åŠ æŠ–åŠ¨
    if (this.options.jitter) {
      delay = delay + Math.random() * delay * 0.1
    }

    return Math.floor(delay)
  }

  sleep(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms))
  }

  getStats() {
    return {
      ...this.stats,
      successRate:
        this.stats.totalAttempts > 0
          ? (this.stats.totalAttempts - this.stats.failedRetries) / this.stats.totalAttempts
          : 0,
      retryRate:
        this.stats.totalAttempts > 0 ? this.stats.totalRetries / this.stats.totalAttempts : 0
    }
  }

  reset() {
    this.stats = {
      totalAttempts: 0,
      totalRetries: 0,
      successfulRetries: 0,
      failedRetries: 0,
      avgRetryDelay: 0,
      errorTypes: new Map()
    }
  }
}

/**
 * ç†”æ–­å™¨å®ç°
 */
class CircuitBreaker extends EventEmitter {
  constructor(options = {}) {
    super()

    this.options = {
      failureThreshold: options.failureThreshold || 5,
      recoveryTimeout: options.recoveryTimeout || 60000,
      monitoringWindow: options.monitoringWindow || 60000,
      ...options
    }

    this.state = 'CLOSED' // CLOSED, OPEN, HALF_OPEN
    this.failures = 0
    this.nextAttemptTime = null
    this.stats = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      circuitOpenCount: 0,
      lastStateChange: Date.now()
    }

    this.monitoringWindow = []
  }

  async execute(fn, context = {}) {
    this.stats.totalRequests++

    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttemptTime) {
        const error = new Error('Circuit breaker is OPEN')
        error.circuitBreakerState = 'OPEN'
        throw error
      } else {
        this.state = 'HALF_OPEN'
        this.emit('stateChange', { from: 'OPEN', to: 'HALF_OPEN', context })
      }
    }

    try {
      const result = await fn(context)
      this.onSuccess()
      return result
    } catch (error) {
      this.onFailure(error)
      throw error
    }
  }

  onSuccess() {
    this.stats.successfulRequests++

    if (this.state === 'HALF_OPEN') {
      this.reset()
      this.emit('stateChange', { from: 'HALF_OPEN', to: 'CLOSED' })
    }

    this.updateMonitoringWindow('success')
  }

  onFailure(error) {
    this.stats.failedRequests++
    this.failures++

    this.updateMonitoringWindow('failure')

    if (this.state === 'HALF_OPEN') {
      this.openCircuit()
    } else if (this.state === 'CLOSED' && this.failures >= this.options.failureThreshold) {
      this.openCircuit()
    }
  }

  openCircuit() {
    const previousState = this.state
    this.state = 'OPEN'
    this.nextAttemptTime = Date.now() + this.options.recoveryTimeout
    this.stats.circuitOpenCount++
    this.stats.lastStateChange = Date.now()

    this.emit('stateChange', { from: previousState, to: 'OPEN' })
  }

  reset() {
    this.state = 'CLOSED'
    this.failures = 0
    this.nextAttemptTime = null
    this.stats.lastStateChange = Date.now()
  }

  updateMonitoringWindow(result) {
    const now = Date.now()
    this.monitoringWindow.push({ result, timestamp: now })

    // æ¸…ç†è¶…å‡ºç›‘æ§çª—å£çš„è®°å½•
    const cutoff = now - this.options.monitoringWindow
    this.monitoringWindow = this.monitoringWindow.filter((entry) => entry.timestamp > cutoff)
  }

  getState() {
    return this.state
  }

  getStats() {
    const failureRate =
      this.stats.totalRequests > 0 ? this.stats.failedRequests / this.stats.totalRequests : 0

    const recentFailures = this.monitoringWindow.filter(
      (entry) => entry.result === 'failure'
    ).length
    const recentFailureRate =
      this.monitoringWindow.length > 0 ? recentFailures / this.monitoringWindow.length : 0

    return {
      ...this.stats,
      state: this.state,
      failureRate,
      recentFailureRate,
      timeUntilNextAttempt: this.nextAttemptTime
        ? Math.max(0, this.nextAttemptTime - Date.now())
        : 0
    }
  }
}

/**
 * é”™è¯¯æ¨¡æ‹Ÿå™¨
 */
class ErrorSimulator {
  constructor() {
    this.errorPatterns = {
      network: {
        rate: 0.1,
        errors: ['ECONNRESET', 'ETIMEDOUT', 'ENOTFOUND', 'ECONNREFUSED']
      },
      http: {
        rate: 0.15,
        errors: [429, 500, 502, 503, 504]
      },
      application: {
        rate: 0.05,
        errors: ['ValidationError', 'AuthenticationError', 'RateLimitError']
      },
      intermittent: {
        rate: 0.02,
        errors: ['TransientError', 'TemporaryUnavailable']
      }
    }

    this.currentPattern = 'normal'
    this.errorRateMultiplier = 1
  }

  setErrorPattern(pattern, multiplier = 1) {
    this.currentPattern = pattern
    this.errorRateMultiplier = multiplier
  }

  async simulateOperation(operationId, options = {}) {
    const delay = options.delay || 100 + Math.random() * 200
    await new Promise((resolve) => setTimeout(resolve, delay))

    if (this.shouldFail()) {
      throw this.generateError()
    }

    return { operationId, success: true, timestamp: Date.now() }
  }

  shouldFail() {
    if (this.currentPattern === 'normal') {
      return Math.random() < 0.05 * this.errorRateMultiplier // 5% åŸºç¡€é”™è¯¯ç‡
    }

    const pattern = this.errorPatterns[this.currentPattern]
    if (pattern) {
      return Math.random() < pattern.rate * this.errorRateMultiplier
    }

    return false
  }

  generateError() {
    const errorType = this.selectErrorType()
    const pattern = this.errorPatterns[errorType]

    if (!pattern) {
      return new Error('Unknown error')
    }

    const errorValue = pattern.errors[Math.floor(Math.random() * pattern.errors.length)]

    if (typeof errorValue === 'string') {
      if (errorValue.startsWith('E')) {
        // ç½‘ç»œé”™è¯¯
        const error = new Error(`Network error: ${errorValue}`)
        error.code = errorValue
        return error
      } else {
        // åº”ç”¨é”™è¯¯
        const error = new Error(`Application error: ${errorValue}`)
        error.name = errorValue
        return error
      }
    } else {
      // HTTPçŠ¶æ€ç é”™è¯¯
      const error = new Error(`HTTP error: ${errorValue}`)
      error.status = errorValue
      return error
    }
  }

  selectErrorType() {
    if (this.currentPattern !== 'normal' && this.errorPatterns[this.currentPattern]) {
      return this.currentPattern
    }

    const types = Object.keys(this.errorPatterns)
    return types[Math.floor(Math.random() * types.length)]
  }
}

/**
 * æµ‹è¯•ç»“æœæ”¶é›†å™¨
 */
class ErrorRetryTestResults {
  constructor() {
    this.tests = []
    this.retryStats = []
    this.circuitBreakerEvents = []
    this.errorPatterns = new Map()
  }

  addTest(name, passed, duration = 0, details = {}) {
    this.tests.push({
      name,
      passed,
      duration,
      details,
      timestamp: new Date()
    })

    if (TEST_CONFIG.verbose) {
      const status = passed ? chalk.green('âœ…') : chalk.red('âŒ')
      const time = duration > 0 ? chalk.gray(`(${duration.toFixed(2)}ms)`) : ''
      console.log(`${status} ${name} ${time}`)
    }
  }

  addRetryStats(stats) {
    this.retryStats.push({
      ...stats,
      timestamp: Date.now()
    })
  }

  addCircuitBreakerEvent(event) {
    this.circuitBreakerEvents.push({
      ...event,
      timestamp: Date.now()
    })
  }

  addErrorPattern(pattern, count) {
    this.errorPatterns.set(pattern, (this.errorPatterns.get(pattern) || 0) + count)
  }

  getSummary() {
    const passed = this.tests.filter((t) => t.passed).length
    const total = this.tests.length

    return {
      total,
      passed,
      failed: total - passed,
      successRate: total > 0 ? (passed / total) * 100 : 0,
      totalDuration: this.tests.reduce((sum, t) => sum + t.duration, 0)
    }
  }
}

const testResults = new ErrorRetryTestResults()

/**
 * æ—¥å¿—å·¥å…·
 */
const log = {
  info: (msg, ...args) => {
    console.log(chalk.blue('â„¹'), msg, ...args)
    if (TEST_CONFIG.verbose) {
      logger.info(msg, ...args)
    }
  },
  success: (msg, ...args) => {
    console.log(chalk.green('âœ…'), msg, ...args)
  },
  error: (msg, ...args) => {
    console.log(chalk.red('âŒ'), msg, ...args)
    logger.error(msg, ...args)
  },
  warn: (msg, ...args) => {
    console.log(chalk.yellow('âš ï¸'), msg, ...args)
  },
  debug: (msg, ...args) => {
    if (TEST_CONFIG.verbose) {
      console.log(chalk.gray('ğŸ”'), msg, ...args)
    }
  }
}

// å…¨å±€æµ‹è¯•å¯¹è±¡
let retryManager
let circuitBreaker
let errorSimulator

/**
 * åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
 */
async function initializeTestEnvironment() {
  log.info('ğŸš€ Initializing Error Retry Test Environment...')

  try {
    retryManager = new RetryManager({
      maxRetries: TEST_CONFIG.retryTests.maxRetries,
      baseDelay: TEST_CONFIG.retryTests.baseDelay,
      maxDelay: TEST_CONFIG.retryTests.maxDelay,
      backoffMultiplier: TEST_CONFIG.retryTests.backoffMultiplier
    })

    circuitBreaker = new CircuitBreaker({
      failureThreshold: TEST_CONFIG.circuitBreaker.failureThreshold,
      recoveryTimeout: TEST_CONFIG.circuitBreaker.recoveryTimeout,
      monitoringWindow: TEST_CONFIG.circuitBreaker.monitoringWindow
    })

    errorSimulator = new ErrorSimulator()

    // è®¾ç½®äº‹ä»¶ç›‘å¬
    retryManager.on('retryAttempt', (data) => {
      log.debug(`Retry attempt ${data.attempt} after ${data.delay}ms delay`)
    })

    retryManager.on('retrySuccess', (data) => {
      log.debug(`Retry succeeded after ${data.attempt} attempts`)
    })

    retryManager.on('retryFailed', (data) => {
      log.debug(`Retry failed after ${data.attempts} attempts`)
    })

    circuitBreaker.on('stateChange', (data) => {
      log.debug(`Circuit breaker state change: ${data.from} -> ${data.to}`)
      testResults.addCircuitBreakerEvent(data)
    })

    log.success('Error retry test environment initialized successfully')
    return true
  } catch (error) {
    log.error('Failed to initialize test environment:', error.message)
    throw error
  }
}

/**
 * æµ‹è¯•é‡è¯•æœºåˆ¶åŸºç¡€åŠŸèƒ½
 */
async function testBasicRetryMechanism() {
  log.info('ğŸ”„ Testing Basic Retry Mechanism...')

  try {
    const testStart = performance.now()

    // æµ‹è¯•1: æˆåŠŸé‡è¯•
    log.debug('Test 1: Successful retry after failures')
    let attemptCount = 0

    const successAfterRetries = async () => {
      attemptCount++
      if (attemptCount < 3) {
        const error = new Error('Temporary failure')
        error.code = 'ETIMEDOUT'
        throw error
      }
      return { success: true, attempts: attemptCount }
    }

    const retryResult = await retryManager.executeWithRetry(successAfterRetries)
    const basicRetryPassed = retryResult.success && retryResult.attempts === 3

    testResults.addTest('Retry-BasicSuccess', basicRetryPassed)

    // æµ‹è¯•2: æœ€ç»ˆå¤±è´¥
    log.debug('Test 2: Final failure after max retries')
    let failureAttempts = 0

    const alwaysFails = async () => {
      failureAttempts++
      const error = new Error('Persistent failure')
      error.code = 'ECONNRESET'
      throw error
    }

    try {
      await retryManager.executeWithRetry(alwaysFails)
      testResults.addTest('Retry-FinalFailure', false)
    } catch (error) {
      const maxRetriesPassed = failureAttempts === TEST_CONFIG.retryTests.maxRetries + 1
      testResults.addTest('Retry-FinalFailure', maxRetriesPassed)
    }

    // æµ‹è¯•3: ä¸å¯é‡è¯•é”™è¯¯
    log.debug('Test 3: Non-retryable error handling')
    let nonRetryableAttempts = 0

    const nonRetryableError = async () => {
      nonRetryableAttempts++
      const error = new Error('Authentication failed')
      error.status = 401
      throw error
    }

    try {
      await retryManager.executeWithRetry(nonRetryableError)
      testResults.addTest('Retry-NonRetryable', false)
    } catch (error) {
      const nonRetryablePassed = nonRetryableAttempts === 1 // åº”è¯¥åªå°è¯•ä¸€æ¬¡
      testResults.addTest('Retry-NonRetryable', nonRetryablePassed)
    }

    // æµ‹è¯•4: å»¶è¿Ÿè®¡ç®—å‡†ç¡®æ€§
    log.debug('Test 4: Delay calculation accuracy')
    const delays = []

    for (let i = 1; i <= 5; i++) {
      const delay = retryManager.calculateDelay(i)
      delays.push(delay)
    }

    // éªŒè¯æŒ‡æ•°é€€é¿
    const exponentialBackoffCorrect = delays.every((delay, index) => {
      if (index === 0) {
        return true
      }
      const expectedMinDelay =
        TEST_CONFIG.retryTests.baseDelay *
        Math.pow(TEST_CONFIG.retryTests.backoffMultiplier, index - 1)
      return delay >= expectedMinDelay * 0.9 // å…è®¸10%çš„æŠ–åŠ¨
    })

    testResults.addTest('Retry-DelayCalculation', exponentialBackoffCorrect)
    log.debug(`Retry delays: ${delays.join(', ')}ms`)

    const testDuration = performance.now() - testStart
    log.success(`Basic retry mechanism tests completed in ${testDuration.toFixed(2)}ms`)
  } catch (error) {
    testResults.addTest('Retry-General', false, 0, { error: error.message })
    log.error('Basic retry mechanism test failed:', error.message)
    throw error
  }
}

/**
 * æµ‹è¯•ç†”æ–­å™¨åŠŸèƒ½
 */
async function testCircuitBreakerFunctionality() {
  log.info('âš¡ Testing Circuit Breaker Functionality...')

  try {
    const testStart = performance.now()

    // æµ‹è¯•1: ç†”æ–­å™¨å¼€å¯
    log.debug('Test 1: Circuit breaker opening')

    // è¿ç»­å¤±è´¥å¯¼è‡´ç†”æ–­å™¨å¼€å¯
    for (let i = 0; i < TEST_CONFIG.circuitBreaker.failureThreshold; i++) {
      try {
        await circuitBreaker.execute(() => {
          throw new Error(`Failure ${i + 1}`)
        })
      } catch (error) {
        // é¢„æœŸçš„å¤±è´¥
      }
    }

    const circuitOpenPassed = circuitBreaker.getState() === 'OPEN'
    testResults.addTest('CircuitBreaker-Opening', circuitOpenPassed)
    log.debug(`Circuit breaker state after failures: ${circuitBreaker.getState()}`)

    // æµ‹è¯•2: ç†”æ–­å™¨é˜»æ­¢è¯·æ±‚
    log.debug('Test 2: Circuit breaker blocking requests')

    try {
      await circuitBreaker.execute(() => ({ success: true }))
      testResults.addTest('CircuitBreaker-Blocking', false)
    } catch (error) {
      const blockingPassed = error.circuitBreakerState === 'OPEN'
      testResults.addTest('CircuitBreaker-Blocking', blockingPassed)
    }

    // æµ‹è¯•3: åŠå¼€çŠ¶æ€è½¬æ¢
    log.debug('Test 3: Half-open state transition')

    // ç­‰å¾…æ¢å¤è¶…æ—¶
    await new Promise((resolve) =>
      setTimeout(resolve, TEST_CONFIG.circuitBreaker.recoveryTimeout + 100)
    )

    // ä¸‹ä¸€æ¬¡è°ƒç”¨åº”è¯¥è§¦å‘åŠå¼€çŠ¶æ€
    try {
      await circuitBreaker.execute(() => ({ success: true }))
      const halfOpenTransitionPassed = circuitBreaker.getState() === 'CLOSED'
      testResults.addTest('CircuitBreaker-HalfOpen', halfOpenTransitionPassed)
    } catch (error) {
      testResults.addTest('CircuitBreaker-HalfOpen', false)
    }

    // æµ‹è¯•4: ç†”æ–­å™¨é‡ç½®
    log.debug('Test 4: Circuit breaker reset')

    const initialStats = circuitBreaker.getStats()
    circuitBreaker.reset()
    const resetStats = circuitBreaker.getStats()

    const resetPassed =
      circuitBreaker.getState() === 'CLOSED' &&
      resetStats.lastStateChange > initialStats.lastStateChange

    testResults.addTest('CircuitBreaker-Reset', resetPassed)

    // æµ‹è¯•5: ç›‘æ§çª—å£
    log.debug('Test 5: Monitoring window functionality')

    const testOperations = 20
    let successCount = 0

    for (let i = 0; i < testOperations; i++) {
      try {
        if (i % 3 === 0) {
          throw new Error('Simulated failure')
        }
        await circuitBreaker.execute(() => ({ success: true }))
        successCount++
      } catch (error) {
        // é¢„æœŸçš„éƒ¨åˆ†å¤±è´¥
      }
    }

    const stats = circuitBreaker.getStats()
    const monitoringWindowPassed =
      stats.totalRequests === testOperations && stats.successfulRequests === successCount

    testResults.addTest('CircuitBreaker-MonitoringWindow', monitoringWindowPassed)
    log.debug(`Circuit breaker stats: ${JSON.stringify(stats, null, 2)}`)

    const testDuration = performance.now() - testStart
    log.success(`Circuit breaker functionality tests completed in ${testDuration.toFixed(2)}ms`)
  } catch (error) {
    testResults.addTest('CircuitBreaker-General', false, 0, { error: error.message })
    log.error('Circuit breaker functionality test failed:', error.message)
    throw error
  }
}

/**
 * æµ‹è¯•é”™è¯¯åˆ†ç±»å’Œå¤„ç†
 */
async function testErrorClassificationAndHandling() {
  log.info('ğŸ·ï¸ Testing Error Classification and Handling...')

  try {
    const testStart = performance.now()

    // æµ‹è¯•1: ç½‘ç»œé”™è¯¯åˆ†ç±»
    log.debug('Test 1: Network error classification')

    const networkErrors = ['ECONNRESET', 'ETIMEDOUT', 'ENOTFOUND', 'ECONNREFUSED']
    let networkErrorsClassified = 0

    for (const errorCode of networkErrors) {
      const error = new Error(`Network error: ${errorCode}`)
      error.code = errorCode

      const classification = retryManager.classifyError(error)
      const shouldRetry = retryManager.shouldRetry(error)

      if (classification.startsWith('NetworkError') && shouldRetry) {
        networkErrorsClassified++
      }
    }

    const networkClassificationPassed = networkErrorsClassified === networkErrors.length
    testResults.addTest('ErrorHandling-NetworkClassification', networkClassificationPassed)

    // æµ‹è¯•2: HTTPé”™è¯¯åˆ†ç±»
    log.debug('Test 2: HTTP error classification')

    const httpErrors = [
      { status: 429, shouldRetry: true }, // Rate limit - é‡è¯•
      { status: 500, shouldRetry: true }, // Server error - é‡è¯•
      { status: 401, shouldRetry: false }, // Unauthorized - ä¸é‡è¯•
      { status: 404, shouldRetry: false } // Not found - ä¸é‡è¯•
    ]

    let httpErrorsClassified = 0

    for (const { status, shouldRetry } of httpErrors) {
      const error = new Error(`HTTP error: ${status}`)
      error.status = status

      const classification = retryManager.classifyError(error)
      const actualShouldRetry = retryManager.shouldRetry(error)

      if (classification.startsWith('HTTPError') && actualShouldRetry === shouldRetry) {
        httpErrorsClassified++
      }
    }

    const httpClassificationPassed = httpErrorsClassified === httpErrors.length
    testResults.addTest('ErrorHandling-HTTPClassification', httpClassificationPassed)

    // æµ‹è¯•3: åº”ç”¨é”™è¯¯åˆ†ç±»
    log.debug('Test 3: Application error classification')

    const applicationErrors = [
      { name: 'ValidationError', shouldRetry: false },
      { name: 'AuthenticationError', shouldRetry: false },
      { name: 'RateLimitError', shouldRetry: true }
    ]

    let appErrorsClassified = 0

    for (const { name, shouldRetry } of applicationErrors) {
      const error = new Error(`Application error: ${name}`)
      error.name = name

      const classification = retryManager.classifyError(error)
      // æ³¨æ„ï¼šå½“å‰å®ç°ä¸­åº”ç”¨é”™è¯¯é€šå¸¸ä¸é‡è¯•ï¼Œä½†å¯ä»¥æ ¹æ®å…·ä½“é”™è¯¯ç±»å‹è°ƒæ•´

      if (classification.startsWith('ApplicationError')) {
        appErrorsClassified++
      }
    }

    const appClassificationPassed = appErrorsClassified === applicationErrors.length
    testResults.addTest('ErrorHandling-ApplicationClassification', appClassificationPassed)

    // æµ‹è¯•4: é”™è¯¯ç»Ÿè®¡æ”¶é›†
    log.debug('Test 4: Error statistics collection')

    retryManager.reset() // é‡ç½®ç»Ÿè®¡

    // æ¨¡æ‹Ÿå„ç§é”™è¯¯
    const errorTypes = [
      () => {
        const e = new Error('Network')
        e.code = 'ETIMEDOUT'
        throw e
      },
      () => {
        const e = new Error('HTTP')
        e.status = 500
        throw e
      },
      () => {
        const e = new Error('App')
        e.name = 'ValidationError'
        throw e
      }
    ]

    for (const errorGen of errorTypes) {
      try {
        await retryManager.executeWithRetry(errorGen)
      } catch (error) {
        // é¢„æœŸçš„å¤±è´¥
      }
    }

    const stats = retryManager.getStats()
    const statsCollectionPassed = stats.errorTypes.size >= 3 && stats.totalAttempts > 0

    testResults.addTest('ErrorHandling-StatisticsCollection', statsCollectionPassed)
    testResults.addRetryStats(stats)

    log.debug(`Error statistics: ${JSON.stringify(Object.fromEntries(stats.errorTypes))}`)

    const testDuration = performance.now() - testStart
    log.success(`Error classification and handling tests completed in ${testDuration.toFixed(2)}ms`)
  } catch (error) {
    testResults.addTest('ErrorHandling-General', false, 0, { error: error.message })
    log.error('Error classification and handling test failed:', error.message)
    throw error
  }
}

/**
 * æµ‹è¯•é›†æˆé”™è¯¯æ¢å¤åœºæ™¯
 */
async function testIntegratedErrorRecoveryScenarios() {
  log.info('ğŸ”§ Testing Integrated Error Recovery Scenarios...')

  try {
    const testStart = performance.now()

    // æµ‹è¯•1: é—´æ­‡æ€§é”™è¯¯æ¢å¤
    log.debug('Test 1: Intermittent error recovery')

    errorSimulator.setErrorPattern('intermittent', 2) // å¢åŠ é—´æ­‡æ€§é”™è¯¯
    let intermittentSuccesses = 0
    const intermittentTests = 10

    for (let i = 0; i < intermittentTests; i++) {
      try {
        const result = await retryManager.executeWithRetry(() =>
          errorSimulator.simulateOperation(`intermittent-${i}`)
        )
        if (result.success) {
          intermittentSuccesses++
        }
      } catch (error) {
        // ä¸€äº›å¤±è´¥æ˜¯é¢„æœŸçš„
      }
    }

    const intermittentRecoveryRate = intermittentSuccesses / intermittentTests
    const intermittentPassed = intermittentRecoveryRate >= 0.7 // æœŸæœ›70%çš„æ¢å¤ç‡

    testResults.addTest('Recovery-IntermittentErrors', intermittentPassed, 0, {
      successRate: `${(intermittentRecoveryRate * 100).toFixed(1)}%`
    })

    // æµ‹è¯•2: ç½‘ç»œé”™è¯¯æ¢å¤
    log.debug('Test 2: Network error recovery')

    errorSimulator.setErrorPattern('network', 1.5)
    let networkSuccesses = 0
    const networkTests = 15

    for (let i = 0; i < networkTests; i++) {
      try {
        const result = await retryManager.executeWithRetry(
          () => errorSimulator.simulateOperation(`network-${i}`),
          { maxRetries: 3 }
        )
        if (result.success) {
          networkSuccesses++
        }
      } catch (error) {
        // ç½‘ç»œé”™è¯¯å¯èƒ½ä»ç„¶å¤±è´¥
      }
    }

    const networkRecoveryRate = networkSuccesses / networkTests
    const networkPassed = networkRecoveryRate >= 0.6 // æœŸæœ›60%çš„æ¢å¤ç‡

    testResults.addTest('Recovery-NetworkErrors', networkPassed, 0, {
      successRate: `${(networkRecoveryRate * 100).toFixed(1)}%`
    })

    // æµ‹è¯•3: çº§è”æ•…éšœå¤„ç†
    log.debug('Test 3: Cascading failure handling')

    // åˆ›å»ºå¤šä¸ªç†”æ–­å™¨æ¨¡æ‹Ÿä¸åŒæœåŠ¡
    const serviceBreakers = Array.from(
      { length: 3 },
      (_, i) =>
        new CircuitBreaker({
          failureThreshold: 3,
          recoveryTimeout: 1000
        })
    )

    // æ¨¡æ‹Ÿçº§è”æ•…éšœ
    errorSimulator.setErrorPattern('http', 3) // é«˜é”™è¯¯ç‡

    const cascadeResults = []

    for (let i = 0; i < 20; i++) {
      const serviceIndex = i % 3
      const breaker = serviceBreakers[serviceIndex]

      try {
        const result = await breaker.execute(() => errorSimulator.simulateOperation(`cascade-${i}`))
        cascadeResults.push({ service: serviceIndex, success: true })
      } catch (error) {
        cascadeResults.push({ service: serviceIndex, success: false, error: error.message })
      }
    }

    // åˆ†æçº§è”æ•…éšœå¤„ç†
    const serviceFailures = new Map()
    cascadeResults.forEach((result) => {
      if (!result.success) {
        serviceFailures.set(result.service, (serviceFailures.get(result.service) || 0) + 1)
      }
    })

    const cascadeHandled = serviceBreakers.some((breaker) => breaker.getState() === 'OPEN')
    testResults.addTest('Recovery-CascadingFailure', cascadeHandled)

    // æµ‹è¯•4: è‡ªé€‚åº”é‡è¯•ç­–ç•¥
    log.debug('Test 4: Adaptive retry strategy')

    // é‡ç½®é”™è¯¯æ¨¡æ‹Ÿå™¨
    errorSimulator.setErrorPattern('normal', 1)

    // æµ‹è¯•ä¸åŒé”™è¯¯æ¨¡å¼ä¸‹çš„è‡ªé€‚åº”è¡Œä¸º
    const adaptiveResults = []

    for (const pattern of ['normal', 'network', 'http']) {
      errorSimulator.setErrorPattern(pattern, 1)

      const patternResults = []
      for (let i = 0; i < 5; i++) {
        const start = performance.now()
        try {
          await retryManager.executeWithRetry(() =>
            errorSimulator.simulateOperation(`adaptive-${pattern}-${i}`)
          )
          patternResults.push({ success: true, duration: performance.now() - start })
        } catch (error) {
          patternResults.push({ success: false, duration: performance.now() - start })
        }
      }

      adaptiveResults.push({
        pattern,
        successRate: patternResults.filter((r) => r.success).length / patternResults.length,
        avgDuration: patternResults.reduce((sum, r) => sum + r.duration, 0) / patternResults.length
      })
    }

    const adaptivePassed = adaptiveResults.every((result) => result.successRate >= 0.4)
    testResults.addTest('Recovery-AdaptiveStrategy', adaptivePassed, 0, { adaptiveResults })

    const testDuration = performance.now() - testStart
    log.success(
      `Integrated error recovery scenario tests completed in ${testDuration.toFixed(2)}ms`
    )
  } catch (error) {
    testResults.addTest('Recovery-General', false, 0, { error: error.message })
    log.error('Integrated error recovery scenario test failed:', error.message)
    throw error
  }
}

/**
 * æµ‹è¯•æ€§èƒ½å’Œå‹åŠ›åœºæ™¯
 */
async function testPerformanceAndStressScenarios() {
  log.info('ğŸš€ Testing Performance and Stress Scenarios...')

  try {
    const testStart = performance.now()

    // æµ‹è¯•1: é«˜å¹¶å‘é‡è¯•æ€§èƒ½
    log.debug('Test 1: High concurrency retry performance')

    const concurrentRequests = 50
    const concurrentStart = performance.now()

    const concurrentPromises = Array.from({ length: concurrentRequests }, async (_, i) => {
      const start = performance.now()
      try {
        const result = await retryManager.executeWithRetry(() =>
          errorSimulator.simulateOperation(`concurrent-${i}`)
        )
        return { success: true, duration: performance.now() - start, index: i }
      } catch (error) {
        return {
          success: false,
          duration: performance.now() - start,
          index: i,
          error: error.message
        }
      }
    })

    const concurrentResults = await Promise.all(concurrentPromises)
    const concurrentDuration = performance.now() - concurrentStart

    const concurrentSuccesses = concurrentResults.filter((r) => r.success).length
    const concurrentThroughput = concurrentRequests / (concurrentDuration / 1000)

    const concurrentPassed =
      concurrentThroughput >= TEST_CONFIG.performance.minThroughput &&
      concurrentSuccesses >= concurrentRequests * 0.8

    testResults.addTest('Performance-ConcurrentRetry', concurrentPassed, concurrentDuration, {
      throughput: `${concurrentThroughput.toFixed(1)} req/sec`,
      successRate: `${((concurrentSuccesses / concurrentRequests) * 100).toFixed(1)}%`
    })

    log.debug(
      `Concurrent test: ${concurrentSuccesses}/${concurrentRequests} successful, ${concurrentThroughput.toFixed(1)} req/sec`
    )

    // æµ‹è¯•2: å†…å­˜ä½¿ç”¨ç¨³å®šæ€§
    log.debug('Test 2: Memory usage stability under load')

    const memStart = process.memoryUsage()
    errorSimulator.setErrorPattern('network', 2) // å¢åŠ é”™è¯¯ç‡è§¦å‘æ›´å¤šé‡è¯•

    for (let i = 0; i < 100; i++) {
      try {
        await retryManager.executeWithRetry(() => errorSimulator.simulateOperation(`memory-${i}`))
      } catch (error) {
        // å¿½ç•¥é”™è¯¯ï¼Œä¸“æ³¨äºå†…å­˜ä½¿ç”¨
      }

      if (i % 20 === 0) {
        // å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if (global.gc) {
          global.gc()
        }
      }
    }

    const memEnd = process.memoryUsage()
    const memoryGrowth = (memEnd.heapUsed - memStart.heapUsed) / 1024 / 1024

    const memoryStable = memoryGrowth < 50 // 50MBå¢é•¿é™åˆ¶
    testResults.addTest('Performance-MemoryStability', memoryStable, 0, {
      memoryGrowthMB: memoryGrowth.toFixed(2)
    })

    // æµ‹è¯•3: ç†”æ–­å™¨æ€§èƒ½
    log.debug('Test 3: Circuit breaker performance under load')

    // é‡ç½®ç†”æ–­å™¨
    circuitBreaker.reset()
    errorSimulator.setErrorPattern('http', 3) // é«˜é”™è¯¯ç‡

    const circuitBreakerStart = performance.now()
    let circuitBreakerOperations = 0
    let circuitBreakerBlocked = 0

    for (let i = 0; i < 100; i++) {
      try {
        await circuitBreaker.execute(() => {
          circuitBreakerOperations++
          return errorSimulator.simulateOperation(`circuit-${i}`)
        })
      } catch (error) {
        if (error.circuitBreakerState === 'OPEN') {
          circuitBreakerBlocked++
        }
      }
    }

    const circuitBreakerDuration = performance.now() - circuitBreakerStart
    const circuitBreakerEfficiency =
      circuitBreakerBlocked > 0 && circuitBreakerDuration < TEST_CONFIG.performance.maxRetryTime

    testResults.addTest(
      'Performance-CircuitBreakerLoad',
      circuitBreakerEfficiency,
      circuitBreakerDuration,
      {
        operationsExecuted: circuitBreakerOperations,
        requestsBlocked: circuitBreakerBlocked,
        finalState: circuitBreaker.getState()
      }
    )

    // æµ‹è¯•4: é”™è¯¯æ¢å¤æ—¶é—´
    log.debug('Test 4: Error recovery time measurement')

    // æ¨¡æ‹ŸæœåŠ¡æ•…éšœ
    errorSimulator.setErrorPattern('http', 10) // æé«˜é”™è¯¯ç‡

    const recoveryStart = performance.now()
    let recoveryAttempts = 0
    let recoveryTime = null

    // å°è¯•æ¢å¤ç›´åˆ°æˆåŠŸ
    while (performance.now() - recoveryStart < TEST_CONFIG.performance.maxRecoveryTime) {
      try {
        recoveryAttempts++
        await retryManager.executeWithRetry(() =>
          errorSimulator.simulateOperation(`recovery-${recoveryAttempts}`)
        )
        recoveryTime = performance.now() - recoveryStart
        break
      } catch (error) {
        // ç»§ç»­å°è¯•æ¢å¤
        await new Promise((resolve) => setTimeout(resolve, 100))
      }
    }

    const recoveryPassed =
      recoveryTime !== null && recoveryTime < TEST_CONFIG.performance.maxRecoveryTime
    testResults.addTest('Performance-RecoveryTime', recoveryPassed, recoveryTime || 0, {
      attempts: recoveryAttempts,
      recoveryTimeMs: recoveryTime?.toFixed(2) || 'timeout'
    })

    const testDuration = performance.now() - testStart
    log.success(`Performance and stress scenario tests completed in ${testDuration.toFixed(2)}ms`)
  } catch (error) {
    testResults.addTest('Performance-General', false, 0, { error: error.message })
    log.error('Performance and stress scenario test failed:', error.message)
    throw error
  }
}

/**
 * ç”Ÿæˆé”™è¯¯é‡è¯•æµ‹è¯•æŠ¥å‘Š
 */
async function generateErrorRetryReport() {
  log.info('ğŸ“‹ Generating Error Retry Test Report...')

  const summary = testResults.getSummary()
  const retryStats = retryManager.getStats()
  const circuitBreakerStats = circuitBreaker.getStats()

  const report = {
    timestamp: new Date().toISOString(),
    testConfig: TEST_CONFIG,
    summary,

    retryManagerStats: retryStats,
    circuitBreakerStats,

    errorPatterns: Object.fromEntries(testResults.errorPatterns),
    circuitBreakerEvents: testResults.circuitBreakerEvents,

    testDetails: testResults.tests
  }

  // æ§åˆ¶å°è¾“å‡º
  console.log(`\n${'='.repeat(80)}`)
  console.log(chalk.bold.blue('ğŸ”„ ERROR HANDLING & RETRY MECHANISM TEST REPORT'))
  console.log('='.repeat(80))

  console.log(chalk.bold('\nğŸ“Š Test Summary:'))
  console.log(`  Total Tests: ${summary.total}`)
  console.log(`  Passed: ${chalk.green(summary.passed)}`)
  console.log(`  Failed: ${chalk.red(summary.failed)}`)
  console.log(`  Success Rate: ${chalk.bold(summary.successRate.toFixed(1))}%`)
  console.log(`  Total Duration: ${summary.totalDuration.toFixed(2)}ms`)

  console.log(chalk.bold('\nğŸ”„ Retry Manager Statistics:'))
  console.log(`  Total Attempts: ${retryStats.totalAttempts}`)
  console.log(`  Total Retries: ${retryStats.totalRetries}`)
  console.log(`  Successful Retries: ${retryStats.successfulRetries}`)
  console.log(`  Success Rate: ${(retryStats.successRate * 100).toFixed(1)}%`)
  console.log(`  Retry Rate: ${(retryStats.retryRate * 100).toFixed(1)}%`)
  console.log(`  Avg Retry Delay: ${retryStats.avgRetryDelay.toFixed(2)}ms`)

  console.log(chalk.bold('\nâš¡ Circuit Breaker Statistics:'))
  console.log(`  Total Requests: ${circuitBreakerStats.totalRequests}`)
  console.log(`  Successful Requests: ${circuitBreakerStats.successfulRequests}`)
  console.log(`  Failed Requests: ${circuitBreakerStats.failedRequests}`)
  console.log(`  Failure Rate: ${(circuitBreakerStats.failureRate * 100).toFixed(1)}%`)
  console.log(`  Current State: ${circuitBreakerStats.state}`)
  console.log(`  Circuit Opened: ${circuitBreakerStats.circuitOpenCount} times`)

  if (Object.keys(report.errorPatterns).length > 0) {
    console.log(chalk.bold('\nğŸ·ï¸ Error Patterns:'))
    Object.entries(report.errorPatterns)
      .sort(([, a], [, b]) => b - a)
      .forEach(([pattern, count]) => {
        console.log(`  ${pattern}: ${count} occurrences`)
      })
  }

  if (summary.failed > 0) {
    console.log(chalk.bold.red('\nâŒ Failed Tests:'))
    testResults.tests
      .filter((t) => !t.passed)
      .forEach((test) => {
        console.log(`  - ${test.name}: ${test.details?.error || 'Unknown error'}`)
      })
  }

  console.log('='.repeat(80))

  return report
}

/**
 * ä¸»æµ‹è¯•å‡½æ•°
 */
async function runErrorRetryTests() {
  console.log(chalk.bold.blue('\nğŸ”„ Starting Error Handling & Retry Mechanism Tests'))
  console.log(chalk.gray(`Profile Mode: ${TEST_CONFIG.profile} | Verbose: ${TEST_CONFIG.verbose}`))

  const overallStart = performance.now()

  try {
    // åˆå§‹åŒ–
    await initializeTestEnvironment()

    // è¿è¡Œæµ‹è¯•å¥—ä»¶
    await testBasicRetryMechanism()
    await testCircuitBreakerFunctionality()
    await testErrorClassificationAndHandling()
    await testIntegratedErrorRecoveryScenarios()
    await testPerformanceAndStressScenarios()

    // ç”ŸæˆæŠ¥å‘Š
    const report = await generateErrorRetryReport()

    const overallDuration = performance.now() - overallStart

    if (report.summary.failed === 0) {
      log.success(`ğŸ‰ All error retry tests passed! Total time: ${overallDuration.toFixed(2)}ms`)
      process.exit(0)
    } else {
      log.error(
        `ğŸ’¥ ${report.summary.failed} test(s) failed! Total time: ${overallDuration.toFixed(2)}ms`
      )
      process.exit(1)
    }
  } catch (error) {
    const overallDuration = performance.now() - overallStart
    log.error(`ğŸ’¥ Error retry test suite failed: ${error.message}`)
    log.error(`Total time: ${overallDuration.toFixed(2)}ms`)

    await generateErrorRetryReport()
    process.exit(1)
  }
}

/**
 * æ¸…ç†å‡½æ•°
 */
async function cleanup() {
  log.info('ğŸ§¹ Cleaning up error retry test environment...')

  try {
    if (retryManager) {
      retryManager.reset()
      retryManager.removeAllListeners()
    }

    if (circuitBreaker) {
      circuitBreaker.reset()
      circuitBreaker.removeAllListeners()
    }

    log.success('Error retry test cleanup completed')
  } catch (error) {
    log.warn('Error retry test cleanup failed:', error.message)
  }
}

// ä¸»ç¨‹åºå…¥å£
if (require.main === module) {
  // è®¾ç½®è¶…æ—¶
  const globalTimeout = setTimeout(() => {
    log.error('âŒ Error retry tests timed out')
    cleanup().finally(() => process.exit(1))
  }, 60000) // 60ç§’è¶…æ—¶

  // ä¼˜é›…å…³é—­å¤„ç†
  process.on('SIGINT', async () => {
    clearTimeout(globalTimeout)
    log.warn('Received SIGINT, cleaning up...')
    await cleanup()
    process.exit(130)
  })

  process.on('SIGTERM', async () => {
    clearTimeout(globalTimeout)
    log.warn('Received SIGTERM, cleaning up...')
    await cleanup()
    process.exit(143)
  })

  // è¿è¡Œæµ‹è¯•
  runErrorRetryTests().finally(() => {
    clearTimeout(globalTimeout)
  })
}

module.exports = {
  runErrorRetryTests,
  testBasicRetryMechanism,
  testCircuitBreakerFunctionality,
  testErrorClassificationAndHandling,
  testIntegratedErrorRecoveryScenarios,
  testPerformanceAndStressScenarios,
  RetryManager,
  CircuitBreaker,
  ErrorSimulator,
  TEST_CONFIG
}
