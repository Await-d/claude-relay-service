/**
 * @fileoverview æ•°æ®ç®¡ç†APIè·¯ç”±
 *
 * æä¾›Webç•Œé¢æ•°æ®å¯¼å‡º/å¯¼å…¥åŠŸèƒ½çš„APIæŽ¥å£
 * é›†æˆ2FAåŒå› ç´ éªŒè¯ä¿æŠ¤æ•æ„Ÿæ“ä½œ
 *
 * @author Claude Code
 * @version 1.0.0
 */

const express = require('express')
const path = require('path')
const fs = require('fs').promises
const multer = require('multer')
const archiver = require('archiver')
const logger = require('../utils/logger')
const twoFactorAuthService = require('../services/twoFactorAuthService')
const DataExportService = require('../services/dataExportService')
const DataImportService = require('../services/dataImportService')
const DataMigrationService = require('../services/dataMigrationService')
const database = require('../models/database')
const { authenticateAdmin } = require('../middleware/auth')

const router = express.Router()

// é…ç½®æ–‡ä»¶ä¸Šä¼ 
const upload = multer({
  dest: './temp/uploads/',
  limits: { fileSize: 50 * 1024 * 1024 }, // 50MBé™åˆ¶
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'application/zip' || file.mimetype === 'application/json') {
      cb(null, true)
    } else {
      cb(new Error('ä»…æ”¯æŒZIPå’ŒJSONæ–‡ä»¶'))
    }
  }
})

/**
 * èŽ·å–æ•°æ®ç®¡ç†æ¦‚è§ˆ
 */
router.get('/overview', authenticateAdmin, async (req, res) => {
  try {
    logger.info(`ðŸ“Š ç®¡ç†å‘˜ ${req.admin.username} èŽ·å–æ•°æ®ç®¡ç†æ¦‚è§ˆ`)

    const db = database
    await db.connect()

    // èŽ·å–æ•°æ®ç»Ÿè®¡
    const stats = {
      apiKeys: 0,
      claudeAccounts: 0,
      openaiAccounts: 0,
      systemConfig: 0,
      is2FAEnabled: false,
      lastExport: null
    }

    try {
      const apiKeys = await db.getAllApiKeys()
      stats.apiKeys = apiKeys.length
    } catch (error) {
      logger.warn('èŽ·å–API Keysç»Ÿè®¡å¤±è´¥:', error.message)
    }

    try {
      const claudeAccounts = await db.getAllClaudeAccounts()
      stats.claudeAccounts = claudeAccounts.length
    } catch (error) {
      logger.warn('èŽ·å–Claudeè´¦æˆ·ç»Ÿè®¡å¤±è´¥:', error.message)
    }

    try {
      const openaiAccounts = await db.getAllOpenAIAccounts()
      stats.openaiAccounts = openaiAccounts.length
    } catch (error) {
      logger.warn('èŽ·å–OpenAIè´¦æˆ·ç»Ÿè®¡å¤±è´¥:', error.message)
    }

    try {
      const config = await db.getSystemSchedulingConfig()
      stats.systemConfig = config ? 1 : 0
    } catch (error) {
      logger.warn('èŽ·å–ç³»ç»Ÿé…ç½®ç»Ÿè®¡å¤±è´¥:', error.message)
    }

    // æ£€æŸ¥2FAçŠ¶æ€
    logger.debug(`ðŸ” æ£€æŸ¥ç®¡ç†å‘˜ ${req.admin.username} çš„2FAçŠ¶æ€`)
    stats.is2FAEnabled = await twoFactorAuthService.is2FAEnabled(req.admin.username)
    logger.debug(`ðŸ” ç®¡ç†å‘˜ ${req.admin.username} 2FAçŠ¶æ€: ${stats.is2FAEnabled}`)

    // èŽ·å–æœ€åŽå¯¼å‡ºæ—¶é—´ï¼ˆå¦‚æžœæœ‰ï¼‰
    try {
      const lastExportInfo = await db.getSession('last_data_export')
      stats.lastExport = lastExportInfo?.timestamp || null
    } catch (error) {
      // å¿½ç•¥èŽ·å–æœ€åŽå¯¼å‡ºæ—¶é—´çš„é”™è¯¯
    }

    await db.disconnect()

    res.json({
      success: true,
      data: stats
    })
  } catch (error) {
    logger.error('âŒ èŽ·å–æ•°æ®ç®¡ç†æ¦‚è§ˆå¤±è´¥:', error)
    res.status(500).json({
      success: false,
      error: 'èŽ·å–æ•°æ®æ¦‚è§ˆå¤±è´¥'
    })
  }
})

/**
 * ç”Ÿæˆ2FAå¯†é’¥
 */
router.post('/2fa/generate', authenticateAdmin, async (req, res) => {
  try {
    logger.info(`ðŸ” ç®¡ç†å‘˜ ${req.admin.username} ç”Ÿæˆ2FAå¯†é’¥`)

    const twoFAConfig = await twoFactorAuthService.generate2FASecret(
      req.admin.username,
      req.admin.username
    )

    res.json({
      success: true,
      data: {
        qrCode: twoFAConfig.qrCode,
        manualEntryKey: twoFAConfig.manualEntryKey,
        backupCodes: twoFAConfig.backupCodes,
        setupToken: twoFAConfig.setupToken
      }
    })
  } catch (error) {
    logger.error('âŒ ç”Ÿæˆ2FAå¯†é’¥å¤±è´¥:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

/**
 * å¯ç”¨2FA
 */
router.post('/2fa/enable', authenticateAdmin, async (req, res) => {
  try {
    const { token } = req.body

    if (!token || !/^\d{6}$/.test(token)) {
      return res.status(400).json({
        success: false,
        error: 'è¯·è¾“å…¥6ä½éªŒè¯ç '
      })
    }

    await twoFactorAuthService.enable2FA(req.admin.username, token)

    logger.info(`âœ… ç®¡ç†å‘˜ ${req.admin.username} æˆåŠŸå¯ç”¨2FA`)

    res.json({
      success: true,
      message: '2FAå¯ç”¨æˆåŠŸ'
    })
  } catch (error) {
    logger.error('âŒ å¯ç”¨2FAå¤±è´¥:', error)
    res.status(400).json({
      success: false,
      error: error.message
    })
  }
})

/**
 * éªŒè¯2FAå¹¶åˆ›å»ºæ•æ„Ÿæ“ä½œä¼šè¯
 */
router.post('/2fa/verify', authenticateAdmin, async (req, res) => {
  try {
    const { password, token } = req.body
    const clientIP = req.ip || req.connection.remoteAddress

    // éªŒè¯ç®¡ç†å‘˜å¯†ç 
    const bcrypt = require('bcryptjs')

    // ä»Žæ•°æ®åº“èŽ·å–å®Œæ•´çš„ç®¡ç†å‘˜ä¿¡æ¯ï¼ˆåŒ…æ‹¬å“ˆå¸Œå¯†ç ï¼‰
    const db = database
    await db.connect()

    const fullAdminInfo = await db.getSession('admin_credentials')
    if (!fullAdminInfo || !fullAdminInfo.passwordHash) {
      await db.disconnect()
      return res.status(401).json({
        success: false,
        error: 'ç®¡ç†å‘˜ä¿¡æ¯ä¸å®Œæ•´'
      })
    }

    const isPasswordValid = await bcrypt.compare(password, fullAdminInfo.passwordHash)

    if (!isPasswordValid) {
      await db.disconnect()
      return res.status(401).json({
        success: false,
        error: 'ç®¡ç†å‘˜å¯†ç é”™è¯¯'
      })
    }

    // éªŒè¯2FA
    const is2FAEnabled = await twoFactorAuthService.is2FAEnabled(req.admin.username)

    if (!is2FAEnabled) {
      await db.disconnect()
      return res.status(400).json({
        success: false,
        error: 'è¯·å…ˆå¯ç”¨2FA'
      })
    }

    if (!token) {
      await db.disconnect()
      return res.status(400).json({
        success: false,
        error: 'è¯·è¾“å…¥2FAéªŒè¯ç '
      })
    }

    await twoFactorAuthService.verify2FA(req.admin.username, token, clientIP)

    // åˆ›å»ºæ•æ„Ÿæ“ä½œä¼šè¯ï¼ˆ15åˆ†é’Ÿæœ‰æ•ˆæœŸï¼‰
    const sensitiveSessionToken = require('crypto').randomUUID()

    await db.setSession(
      `sensitive_session:${sensitiveSessionToken}`,
      {
        adminUsername: req.admin.username,
        createdAt: new Date().toISOString(),
        clientIP
      },
      15 * 60
    ) // 15åˆ†é’Ÿ

    await db.disconnect()

    logger.info(`âœ… ç®¡ç†å‘˜ ${req.admin.username} é€šè¿‡æ•æ„Ÿæ“ä½œéªŒè¯`)

    res.json({
      success: true,
      data: {
        sessionToken: sensitiveSessionToken,
        expiresIn: 15 * 60 // ç§’
      }
    })
  } catch (error) {
    // ç¡®ä¿æ•°æ®åº“è¿žæŽ¥è¢«æ­£ç¡®å…³é—­
    try {
      const db = database
      await db.disconnect()
    } catch (disconnectError) {
      logger.warn('æ•°æ®åº“æ–­å¼€è¿žæŽ¥å¤±è´¥:', disconnectError.message)
    }

    logger.error('âŒ 2FAéªŒè¯å¤±è´¥:', error)
    res.status(400).json({
      success: false,
      error: error.message
    })
  }
})

/**
 * æ•°æ®å¯¼å‡º
 */
router.post('/export', authenticateAdmin, async (req, res) => {
  try {
    const { sessionToken, includeStats = true } = req.body

    // éªŒè¯æ•æ„Ÿæ“ä½œä¼šè¯
    const db = database
    await db.connect()

    const sensitiveSession = await db.getSession(`sensitive_session:${sessionToken}`)
    if (!sensitiveSession || sensitiveSession.adminUsername !== req.admin.username) {
      await db.disconnect()
      return res.status(401).json({
        success: false,
        error: 'æ•æ„Ÿæ“ä½œä¼šè¯æ— æ•ˆæˆ–å·²è¿‡æœŸ'
      })
    }

    logger.info(`ðŸ“¤ ç®¡ç†å‘˜ ${req.admin.username} å¼€å§‹æ•°æ®å¯¼å‡º`)

    // åˆ›å»ºå¯¼å‡ºç›®å½•
    const exportId = Date.now().toString()
    const exportDir = path.join('./temp/exports', exportId)
    await fs.mkdir(exportDir, { recursive: true })

    // æ‰§è¡Œæ•°æ®å¯¼å‡º
    const exportService = new DataExportService(db)
    const exportResult = await exportService.exportAllData(exportDir, {
      includeStats,
      includeSessions: false, // ä¼šè¯æ•°æ®ä¸å¯¼å‡º
      validateData: true
    })

    // åˆ›å»ºZIPåŽ‹ç¼©åŒ…
    const zipPath = path.join('./temp/exports', `data-export-${exportId}.zip`)
    await createZipArchive(exportDir, zipPath)

    // è®°å½•å¯¼å‡ºä¿¡æ¯
    await db.setSession(
      'last_data_export',
      {
        timestamp: new Date().toISOString(),
        adminId: req.admin.id,
        adminUsername: req.admin.username,
        exportId,
        recordCount: exportResult.totalRecords
      },
      30 * 24 * 60 * 60
    ) // ä¿å­˜30å¤©

    // æ¸…ç†æ•æ„Ÿæ“ä½œä¼šè¯
    await db.deleteSession(`sensitive_session:${sessionToken}`)

    // æ–­å¼€æ•°æ®åº“è¿žæŽ¥
    await db.disconnect()

    logger.info(`âœ… ç®¡ç†å‘˜ ${req.admin.username} æ•°æ®å¯¼å‡ºå®Œæˆ: ${exportResult.totalRecords} æ¡è®°å½•`)

    // éªŒè¯ZIPæ–‡ä»¶å­˜åœ¨ä¸”å¤§å°æ­£ç¡®
    const stats = await fs.stat(zipPath)
    if (stats.size === 0) {
      throw new Error('ç”Ÿæˆçš„ZIPæ–‡ä»¶ä¸ºç©º')
    }

    // è®¾ç½®å“åº”å¤´
    res.setHeader('Content-Type', 'application/zip')
    res.setHeader('Content-Disposition', `attachment; filename="claude-relay-data-${exportId}.zip"`)
    res.setHeader('Content-Length', stats.size)
    res.setHeader('Cache-Control', 'no-cache')

    // åˆ›å»ºæ–‡ä»¶æµå¹¶å¤„ç†é”™è¯¯
    const fileStream = require('fs').createReadStream(zipPath)

    fileStream.on('error', (error) => {
      logger.error('æ–‡ä»¶æµè¯»å–é”™è¯¯:', error)
      if (!res.headersSent) {
        res.status(500).json({ success: false, error: 'æ–‡ä»¶è¯»å–å¤±è´¥' })
      }
    })

    res.on('error', (error) => {
      logger.error('å“åº”æµé”™è¯¯:', error)
      fileStream.destroy()
    })

    res.on('close', () => {
      fileStream.destroy()
    })

    // å‘é€æ–‡ä»¶
    fileStream.pipe(res)

    // å¼‚æ­¥æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    setTimeout(async () => {
      try {
        await fs.rm(exportDir, { recursive: true, force: true })
        await fs.unlink(zipPath)
      } catch (error) {
        logger.warn('æ¸…ç†å¯¼å‡ºä¸´æ—¶æ–‡ä»¶å¤±è´¥:', error.message)
      }
    }, 60000) // 1åˆ†é’ŸåŽæ¸…ç†
  } catch (error) {
    logger.error('âŒ æ•°æ®å¯¼å‡ºå¤±è´¥:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

/**
 * æ•°æ®å¯¼å…¥
 */
router.post('/import', authenticateAdmin, upload.single('dataFile'), async (req, res) => {
  try {
    const { sessionToken, conflictStrategy = 'skip' } = req.body

    if (!req.file) {
      return res.status(400).json({
        success: false,
        error: 'è¯·é€‰æ‹©è¦å¯¼å…¥çš„æ•°æ®æ–‡ä»¶'
      })
    }

    // éªŒè¯æ•æ„Ÿæ“ä½œä¼šè¯
    const db = database
    await db.connect()

    const sensitiveSession = await db.getSession(`sensitive_session:${sessionToken}`)
    if (!sensitiveSession || sensitiveSession.adminUsername !== req.admin.username) {
      await db.disconnect()
      return res.status(401).json({
        success: false,
        error: 'æ•æ„Ÿæ“ä½œä¼šè¯æ— æ•ˆæˆ–å·²è¿‡æœŸ'
      })
    }

    logger.info(`ðŸ“¥ ç®¡ç†å‘˜ ${req.admin.username} å¼€å§‹æ•°æ®å¯¼å…¥`)

    let importDir = req.file.path

    // å¦‚æžœæ˜¯ZIPæ–‡ä»¶ï¼Œå…ˆè§£åŽ‹
    if (req.file.mimetype === 'application/zip') {
      const extractDir = path.join('./temp/imports', Date.now().toString())
      await extractZipArchive(req.file.path, extractDir)
      importDir = extractDir
    }

    // æ‰§è¡Œæ•°æ®å¯¼å…¥
    const importService = new DataImportService(db)
    const importResult = await importService.importAllData(importDir, {
      validateChecksums: true,
      conflictStrategy,
      includeCategories: null, // å¯¼å…¥æ‰€æœ‰ç±»åˆ«
      dryRun: false
    })

    await db.disconnect()

    // æ¸…ç†æ•æ„Ÿæ“ä½œä¼šè¯
    await db.deleteSession(`sensitive_session:${sessionToken}`)

    logger.info(`âœ… ç®¡ç†å‘˜ ${req.admin.username} æ•°æ®å¯¼å…¥å®Œæˆ: ${importResult.totalRecords} æ¡è®°å½•`)

    res.json({
      success: true,
      data: {
        importedRecords: importResult.totalRecords,
        skippedRecords: importResult.skippedRecords,
        categories: importResult.categories,
        conflictStrategy: importResult.conflictStrategy
      }
    })

    // å¼‚æ­¥æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    setTimeout(async () => {
      try {
        await fs.unlink(req.file.path)
        if (importDir !== req.file.path) {
          await fs.rm(importDir, { recursive: true, force: true })
        }
      } catch (error) {
        logger.warn('æ¸…ç†å¯¼å…¥ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', error.message)
      }
    }, 5000) // 5ç§’åŽæ¸…ç†
  } catch (error) {
    logger.error('âŒ æ•°æ®å¯¼å…¥å¤±è´¥:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

/**
 * æ•°æ®åº“è¿ç§»
 */
router.post('/migrate', authenticateAdmin, upload.single('configFile'), async (req, res) => {
  try {
    const { sessionToken, validateOnly = false } = req.body

    if (!req.file) {
      return res.status(400).json({
        success: false,
        error: 'è¯·ä¸Šä¼ ç›®æ ‡æ•°æ®åº“é…ç½®æ–‡ä»¶'
      })
    }

    // éªŒè¯æ•æ„Ÿæ“ä½œä¼šè¯
    const db = database
    await db.connect()

    const sensitiveSession = await db.getSession(`sensitive_session:${sessionToken}`)
    if (!sensitiveSession || sensitiveSession.adminUsername !== req.admin.username) {
      await db.disconnect()
      return res.status(401).json({
        success: false,
        error: 'æ•æ„Ÿæ“ä½œä¼šè¯æ— æ•ˆæˆ–å·²è¿‡æœŸ'
      })
    }

    logger.info(`ðŸ”„ ç®¡ç†å‘˜ ${req.admin.username} å¼€å§‹æ•°æ®åº“è¿ç§»`)

    // è¯»å–ç›®æ ‡æ•°æ®åº“é…ç½®
    const configContent = await fs.readFile(req.file.path, 'utf8')
    const targetConfig = JSON.parse(configContent)

    // æ‰§è¡Œè¿ç§»
    const migrationService = new DataMigrationService()
    const migrationResult = await migrationService.migrate(
      require('../../config/config'),
      targetConfig,
      {
        migrationDir: path.join('./temp/migrations', Date.now().toString()),
        strategy: 'export-import',
        validateOnly,
        backupTarget: !validateOnly,
        includeCategories: null
      }
    )

    await db.disconnect()

    // æ¸…ç†æ•æ„Ÿæ“ä½œä¼šè¯
    await db.deleteSession(`sensitive_session:${sessionToken}`)

    logger.info(`âœ… ç®¡ç†å‘˜ ${req.admin.username} æ•°æ®åº“è¿ç§»å®Œæˆ`)

    res.json({
      success: true,
      data: {
        sourceDatabase: migrationResult.sourceDatabase,
        targetDatabase: migrationResult.targetDatabase,
        totalRecords: migrationResult.totalRecords,
        phases: migrationResult.phases,
        validateOnly,
        errors: migrationResult.errors
      }
    })
  } catch (error) {
    logger.error('âŒ æ•°æ®åº“è¿ç§»å¤±è´¥:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ==================== è¾…åŠ©æ–¹æ³• ====================

/**
 * åˆ›å»ºZIPåŽ‹ç¼©åŒ…
 */
async function createZipArchive(sourceDir, outputPath) {
  return new Promise((resolve, reject) => {
    const output = require('fs').createWriteStream(outputPath)
    const archive = archiver('zip', { zlib: { level: 9 } })

    // å¤„ç†è¾“å‡ºæµäº‹ä»¶
    output.on('close', () => {
      logger.debug(`ZIPåŽ‹ç¼©å®Œæˆï¼Œæ–‡ä»¶å¤§å°: ${archive.pointer()} bytes`)
      resolve()
    })

    output.on('error', (error) => {
      logger.error('ZIPè¾“å‡ºæµé”™è¯¯:', error)
      reject(error)
    })

    // å¤„ç†archiveräº‹ä»¶
    archive.on('error', (error) => {
      logger.error('ZIPåŽ‹ç¼©é”™è¯¯:', error)
      reject(error)
    })

    archive.on('warning', (warning) => {
      logger.warn('ZIPåŽ‹ç¼©è­¦å‘Š:', warning)
    })

    // è¿žæŽ¥æµ
    archive.pipe(output)

    // æ·»åŠ ç›®å½•å†…å®¹
    archive.directory(sourceDir, false)

    // å®ŒæˆåŽ‹ç¼©
    archive.finalize()
  })
}

/**
 * è§£åŽ‹ZIPæ–‡ä»¶
 */
async function extractZipArchive(zipPath, extractDir) {
  const yauzl = require('yauzl')
  await fs.mkdir(extractDir, { recursive: true })

  return new Promise((resolve, reject) => {
    yauzl.open(zipPath, { lazyEntries: true }, (err, zipfile) => {
      if (err) {
        return reject(err)
      }

      zipfile.readEntry()
      zipfile.on('entry', (entry) => {
        if (/\/$/.test(entry.fileName)) {
          zipfile.readEntry()
        } else {
          zipfile.openReadStream(entry, (error, readStream) => {
            if (error) {
              return reject(error)
            }

            const outputPath = path.join(extractDir, entry.fileName)
            const outputDir = path.dirname(outputPath)

            fs.mkdir(outputDir, { recursive: true })
              .then(() => {
                const writeStream = require('fs').createWriteStream(outputPath)
                readStream.pipe(writeStream)
                writeStream.on('close', () => zipfile.readEntry())
              })
              .catch(reject)
          })
        }
      })

      zipfile.on('end', resolve)
    })
  })
}

module.exports = router
