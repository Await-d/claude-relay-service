/**
 * @fileoverview Redisæ•°æ®åº“é€‚é…å™¨å®ç°
 *
 * ç»§æ‰¿DatabaseAdapteræŠ½è±¡åŸºç±»ï¼Œå®ç°Redisç‰¹å®šçš„æ•°æ®åº“æ“ä½œ
 * ä»ç°æœ‰redis.jsè¿ç§»æ–¹æ³•ï¼Œä¿æŒå®Œå…¨çš„å‘åå…¼å®¹æ€§
 *
 * @author Claude Code
 * @version 1.0.0
 */

const Redis = require('ioredis')
const config = require('../../../config/config')
const logger = require('../../utils/logger')
const DatabaseAdapter = require('./DatabaseAdapter')
const Decimal = require('decimal.js')
const CostCalculator = require('../../utils/costCalculator')

// å¯¼å…¥ç»Ÿä¸€æ—¶åŒºå¤„ç†å·¥å…·
const dateHelper = require('../../utils/dateHelper')

// æ—¶åŒºè¾…åŠ©å‡½æ•°ï¼ˆç°åœ¨ç”± dateHelper æä¾›ï¼‰
// æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°çš„ç›®çš„æ˜¯è·å–æŸä¸ªæ—¶é—´ç‚¹åœ¨ç›®æ ‡æ—¶åŒºçš„"æœ¬åœ°"è¡¨ç¤º
// ä¾‹å¦‚ï¼šUTCæ—¶é—´ 2025-07-30 01:00:00 åœ¨ UTC+8 æ—¶åŒºè¡¨ç¤ºä¸º 2025-07-30 09:00:00
function getDateInTimezone(date = new Date()) {
  return dateHelper.getDateInTimezone(date)
}

// è·å–é…ç½®æ—¶åŒºçš„æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
function getDateStringInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)
  // ä½¿ç”¨UTCæ–¹æ³•è·å–åç§»åçš„ï¿½ï¿½æœŸéƒ¨åˆ†
  return `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}-${String(tzDate.getUTCDate()).padStart(2, '0')}`
}

// è·å–é…ç½®æ—¶åŒºçš„å°æ—¶ (0-23)
function getHourInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)
  return tzDate.getUTCHours()
}

/**
 * Redisæ•°æ®åº“é€‚é…å™¨
 *
 * å®ç°DatabaseAdapteræ¥å£ï¼Œæä¾›Redisç‰¹å®šçš„æ•°æ®åº“æ“ä½œ
 *
 * ç‰¹æ€§:
 * - å®Œå…¨ç»§æ‰¿è‡ªDatabaseAdapteråŸºç±»
 * - ä»redis.jsè¿ç§»æ‰€æœ‰æ–¹æ³•é€»è¾‘ï¼Œä¿æŒ100%å…¼å®¹æ€§
 * - ä¿ç•™ç°æœ‰çš„è¿æ¥ç®¡ç†å’Œé”™è¯¯å¤„ç†æœºåˆ¶
 * - ç»´æŒæ‰€æœ‰ç°æœ‰çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
 */
class RedisAdapter extends DatabaseAdapter {
  constructor() {
    super()
    this.client = null
    this._reconnecting = false // é‡è¿é”æ ‡å¿—
  }

  // ==================== è¿æ¥ç®¡ç† (4ä¸ªæ–¹æ³•) ====================

  /**
   * è¿æ¥åˆ°Redisæ•°æ®åº“
   * @returns {Promise<any>} Rediså®¢æˆ·ç«¯å®ä¾‹
   * @throws {Error} è¿æ¥å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async connect() {
    try {
      // å¦‚æœå·²ç»è¿æ¥ä¸”è¿æ¥çŠ¶æ€æ­£å¸¸ï¼Œåˆ™ç›´æ¥è¿”å›
      if (this.client && this.isConnected && this.client.status === 'ready') {
        return this.client
      }

      // å¦‚æœæœ‰æ—§çš„clientï¼Œå…ˆæ¸…ç†
      if (this.client) {
        try {
          // ç§»é™¤æ‰€æœ‰äº‹ä»¶ç›‘å¬å™¨ï¼Œé¿å…é‡å¤ç»‘å®š
          this.client.removeAllListeners()
          // å®‰å…¨æ–­å¼€è¿æ¥
          if (this.client.status !== 'end') {
            await this.client.quit()
          }
        } catch (error) {
          // å¿½ç•¥quité”™è¯¯
          logger.debug('Failed to quit old Redis client:', error)
        }
      }

      this.client = new Redis({
        host: config.redis.host,
        port: config.redis.port,
        password: config.redis.password,
        db: config.redis.db,
        retryDelayOnFailover: config.redis.retryDelayOnFailover,
        maxRetriesPerRequest: config.redis.maxRetriesPerRequest,
        lazyConnect: config.redis.lazyConnect,
        tls: config.redis.enableTLS ? {} : false,
        // æ·»åŠ è¿æ¥ä¿æ´»å’Œé‡è¿é…ç½®
        keepAlive: 30000, // 30ç§’ä¿æ´»
        connectTimeout: 10000, // 10ç§’è¿æ¥è¶…æ—¶
        commandTimeout: 5000, // 5ç§’å‘½ä»¤è¶…æ—¶
        retryDelayOnClusterDown: 300 // é›†ç¾¤æ•…éšœé‡è¯•å»¶è¿Ÿ
      })

      // ä½¿ç”¨onceè€Œä¸æ˜¯onï¼Œé¿å…é‡å¤ç»‘å®šäº‹ä»¶ç›‘å¬å™¨
      this.client.once('connect', () => {
        this.isConnected = true
        logger.info('ğŸ”— Redis connected successfully')
      })

      this.client.on('error', (err) => {
        // é¿å…é¢‘ç¹çš„é”™è¯¯æ—¥å¿—
        if (this.isConnected) {
          this.isConnected = false
          logger.error('âŒ Redis connection error:', err)
        }
      })

      this.client.on('close', () => {
        // åªåœ¨è¿æ¥çŠ¶æ€æ”¹å˜æ—¶è®°å½•æ—¥å¿—
        if (this.isConnected) {
          this.isConnected = false
          logger.warn('âš ï¸ Redis connection closed')
        }
      })

      // æ·»åŠ é‡è¿æˆåŠŸç›‘å¬å™¨
      this.client.on('ready', () => {
        if (!this.isConnected) {
          this.isConnected = true
          logger.info('ğŸ”„ Redis reconnected successfully')
        }
      })

      await this.client.connect()
      return this.client
    } catch (error) {
      logger.error('ğŸ’¥ Failed to connect to Redis:', error)
      throw error
    }
  }

  /**
   * æ–­å¼€Redisè¿æ¥
   * @returns {Promise<void>}
   */
  async disconnect() {
    if (this.client) {
      await this.client.quit()
      this.isConnected = false
      logger.info('ğŸ‘‹ Redis disconnected')
    }
  }

  /**
   * è·å–Rediså®¢æˆ·ç«¯å®ä¾‹ï¼ˆå¯èƒ½ä¸ºnullï¼‰
   * @returns {any|null} Rediså®¢æˆ·ç«¯å®ä¾‹æˆ–null
   */
  getClient() {
    // æ£€æŸ¥å®¢æˆ·ç«¯å­˜åœ¨æ€§å’Œè¿æ¥çŠ¶æ€
    if (!this.client || !this.isConnected || this.client.status !== 'ready') {
      // é¿å…é¢‘ç¹çš„è­¦å‘Šæ—¥å¿—ï¼Œåªåœ¨çŠ¶æ€çœŸæ­£æ”¹å˜æ—¶è®°å½•
      if (this.isConnected && this.client && this.client.status !== 'ready') {
        logger.warn('âš ï¸ Redis client status is not ready:', this.client.status)
      } else if (!this.client) {
        logger.warn('âš ï¸ Redis client is not initialized')
      }
      return null
    }
    return this.client
  }

  /**
   * å®‰å…¨è·å–Rediså®¢æˆ·ç«¯ï¼ˆå¿…é¡»å­˜åœ¨ï¼‰
   * @returns {any} Rediså®¢æˆ·ç«¯å®ä¾‹
   * @throws {Error} å®¢æˆ·ç«¯ä¸å­˜åœ¨æ—¶æŠ›å‡ºé”™è¯¯
   */
  getClientSafe() {
    const client = this.getClient()
    if (!client) {
      throw new Error('Redis client is not available')
    }
    return client
  }

  /**
   * è‡ªåŠ¨é‡è¿å¹¶è·å–å®¢æˆ·ç«¯ï¼ˆæ–°å¢ï¼‰
   * @returns {Promise<any>} Rediså®¢æˆ·ç«¯å®ä¾‹
   * @throws {Error} é‡è¿å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async getClientWithReconnect() {
    // å¦‚æœè¿æ¥æ­£å¸¸ä¸”çŠ¶æ€ä¸ºreadyï¼Œç›´æ¥è¿”å›
    if (this.client && this.isConnected && this.client.status === 'ready') {
      return this.client
    }

    // é¿å…å¹¶å‘é‡è¿ï¼Œä½¿ç”¨ç®€å•çš„é”æœºåˆ¶
    if (this._reconnecting) {
      logger.debug('â³ Reconnection already in progress, waiting...')
      // ç­‰å¾…é‡è¿å®Œæˆ
      let attempts = 0
      while (this._reconnecting && attempts < 50) {
        // æœ€å¤šç­‰å¾…5ç§’
        await new Promise((resolve) => setTimeout(resolve, 100))
        attempts++
      }

      if (this.client && this.isConnected && this.client.status === 'ready') {
        return this.client
      }
    }

    this._reconnecting = true
    logger.warn('âš ï¸ Redis connection lost, attempting to reconnect...')

    try {
      // å°è¯•é‡è¿
      await this.connect()
      this._reconnecting = false
      return this.client
    } catch (error) {
      this._reconnecting = false
      logger.error('ğŸ’¥ Failed to reconnect to Redis:', error)
      throw new Error(`Redis reconnection failed: ${error.message}`)
    }
  }

  /**
   * Ping RedisæœåŠ¡å™¨æ£€æŸ¥è¿æ¥çŠ¶æ€
   * @returns {Promise<string>} è¿”å›'PONG'è¡¨ç¤ºè¿æ¥æ­£å¸¸
   * @throws {Error} è¿æ¥å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async ping() {
    try {
      const client = this.getClientSafe()
      const result = await client.ping()
      return result
    } catch (error) {
      logger.error('ğŸ’¥ Redis ping failed:', error)
      throw error
    }
  }

  // Redisç‰ˆæœ¬å…¼å®¹çš„hsetæ–¹æ³•ï¼ˆæ”¯æŒå¤šå­—æ®µè®¾ç½®ï¼‰
  async hsetCompat(key, ...args) {
    const client = await this.getClientWithReconnect()

    // å¦‚æœå‚æ•°æ˜¯å¯¹è±¡å½¢å¼ hset(key, {field1: value1, field2: value2})
    if (args.length === 1 && typeof args[0] === 'object' && args[0] !== null) {
      const obj = args[0]
      const fields = Object.keys(obj)

      // å¯¹äºä½ç‰ˆæœ¬Redisï¼Œä½¿ç”¨pipelineé€ä¸€è®¾ç½®å­—æ®µ
      const pipeline = client.pipeline()
      for (const field of fields) {
        pipeline.hset(key, field, obj[field])
      }
      return await pipeline.exec()
    }

    // å…¶ä»–æƒ…å†µç›´æ¥è°ƒç”¨åŸç”Ÿhset
    return await client.hset(key, ...args)
  }

  // ==================== RedisåŸºç¡€æ“ä½œæ–¹æ³• ====================

  /**
   * Redis keyså‘½ä»¤ - è·å–åŒ¹é…æ¨¡å¼çš„æ‰€æœ‰é”®
   * @param {string} pattern åŒ¹é…æ¨¡å¼
   * @returns {Promise<Array>} é”®æ•°ç»„
   */
  async keys(pattern) {
    const client = this.getClientSafe()
    return await client.keys(pattern)
  }

  /**
   * Redis getå‘½ä»¤ - è·å–å­—ç¬¦ä¸²å€¼
   * @param {string} key é”®å
   * @returns {Promise<string>} å€¼
   */
  async get(key) {
    const client = this.getClientSafe()
    return await client.get(key)
  }

  /**
   * Redis setå‘½ä»¤ - è®¾ç½®å­—ç¬¦ä¸²å€¼
   * @param {string} key é”®å
   * @param {string} value å€¼
   * @param {string} mode è®¾ç½®æ¨¡å¼ (EX, PXç­‰)
   * @param {number} time è¿‡æœŸæ—¶é—´
   * @returns {Promise<string>} ç»“æœ
   */
  async set(key, value, ...args) {
    const client = this.getClientSafe()
    return await client.set(key, value, ...args)
  }

  /**
   * Redis delå‘½ä»¤ - åˆ é™¤é”®
   * @param {...string} keys è¦åˆ é™¤çš„é”®
   * @returns {Promise<number>} åˆ é™¤çš„é”®æ•°é‡
   */
  async del(...keys) {
    const client = this.getClientSafe()
    return await client.del(...keys)
  }

  /**
   * Redis hgetå‘½ä»¤ - è·å–å“ˆå¸Œå­—æ®µå€¼
   * @param {string} key é”®å
   * @param {string} field å­—æ®µå
   * @returns {Promise<string>} å­—æ®µå€¼
   */
  async hget(key, field) {
    const client = this.getClientSafe()
    return await client.hget(key, field)
  }

  /**
   * Redis hsetå‘½ä»¤ - è®¾ç½®å“ˆå¸Œå­—æ®µå€¼
   * @param {string} key é”®å
   * @param {...any} args å­—æ®µå’Œå€¼
   * @returns {Promise<number>} è®¾ç½®çš„å­—æ®µæ•°é‡
   */
  async hset(key, ...args) {
    const client = this.getClientSafe()
    return await client.hset(key, ...args)
  }

  /**
   * Redis hgetallå‘½ä»¤ - è·å–æ‰€æœ‰å“ˆå¸Œå­—æ®µå’Œå€¼
   * @param {string} key é”®å
   * @returns {Promise<Object>} å“ˆå¸Œå¯¹è±¡
   */
  async hgetall(key) {
    const client = this.getClientSafe()
    return await client.hgetall(key)
  }

  /**
   * Redis hdelå‘½ä»¤ - åˆ é™¤å“ˆå¸Œå­—æ®µ
   * @param {string} key é”®å
   * @param {...string} fields å­—æ®µå
   * @returns {Promise<number>} åˆ é™¤çš„å­—æ®µæ•°é‡
   */
  async hdel(key, ...fields) {
    const client = this.getClientSafe()
    return await client.hdel(key, ...fields)
  }

  /**
   * Redis hmsetå‘½ä»¤ - è®¾ç½®å¤šä¸ªå“ˆå¸Œå­—æ®µ (ä¸ºäº†å…¼å®¹æ€§)
   * @param {string} key é”®å
   * @param {Object|Array} hash å“ˆå¸Œæ•°æ®
   * @returns {Promise<string>} ç»“æœ
   */
  async hmset(key, hash) {
    const client = this.getClientSafe()
    return await client.hmset(key, hash)
  }

  /**
   * Redis expireå‘½ä»¤ - è®¾ç½®é”®è¿‡æœŸæ—¶é—´
   * @param {string} key é”®å
   * @param {number} seconds è¿‡æœŸç§’æ•°
   * @returns {Promise<number>} ç»“æœ
   */
  async expire(key, seconds) {
    const client = this.getClientSafe()
    return await client.expire(key, seconds)
  }

  /**
   * Redis incrå‘½ä»¤ - é€’å¢æ•°å€¼
   * @param {string} key é”®å
   * @returns {Promise<number>} é€’å¢åçš„å€¼
   */
  async incr(key) {
    const client = this.getClientSafe()
    return await client.incr(key)
  }

  /**
   * Redis decrå‘½ä»¤ - é€’å‡æ•°å€¼
   * @param {string} key é”®å
   * @returns {Promise<number>} é€’å‡åçš„å€¼
   */
  async decr(key) {
    const client = this.getClientSafe()
    return await client.decr(key)
  }

  /**
   * Redis typeå‘½ä»¤ - è·å–é”®çš„æ•°æ®ç±»å‹
   * @param {string} key é”®å
   * @returns {Promise<string>} æ•°æ®ç±»å‹
   */
  async type(key) {
    const client = this.getClientSafe()
    return await client.type(key)
  }

  // ==================== API Key æ“ä½œ (5ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®API Keyæ•°æ®
   * @param {string} keyId API Key ID
   * @param {Object} keyData API Keyæ•°æ®å¯¹è±¡
   * @param {string|null} hashedKey å“ˆå¸Œåçš„Keyå€¼ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾
   * @returns {Promise<void>}
   */
  async setApiKey(keyId, keyData, hashedKey = null) {
    const key = `apikey:${keyId}`
    const client = this.getClientSafe()

    // ç»´æŠ¤å“ˆå¸Œæ˜ å°„è¡¨ï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
    // hashedKeyå‚æ•°æ˜¯å®é™…çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»ºç«‹æ˜ å°„
    if (hashedKey) {
      await client.hset('apikey:hash_map', hashedKey, keyId)
    }

    await this.hsetCompat(key, keyData)
    await client.expire(key, 86400 * 365) // 1å¹´è¿‡æœŸ
  }

  /**
   * è·å–API Keyæ•°æ®
   * @param {string} keyId API Key ID
   * @returns {Promise<Object>} API Keyæ•°æ®å¯¹è±¡
   */
  async getApiKey(keyId) {
    const key = `apikey:${keyId}`
    return await this.client.hgetall(key)
  }

  /**
   * åˆ é™¤API Key
   * @param {string} keyId API Key ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteApiKey(keyId) {
    const key = `apikey:${keyId}`

    // è·å–è¦åˆ é™¤çš„API Keyå“ˆå¸Œå€¼ï¼Œä»¥ä¾¿ä»æ˜ å°„è¡¨ä¸­ç§»é™¤
    const keyData = await this.client.hgetall(key)
    if (keyData && keyData.apiKey) {
      // keyData.apiKeyç°åœ¨å­˜å‚¨çš„æ˜¯å“ˆå¸Œå€¼ï¼Œç›´æ¥ä»æ˜ å°„è¡¨åˆ é™¤
      await this.client.hdel('apikey:hash_map', keyData.apiKey)
    }

    return await this.client.del(key)
  }

  /**
   * è·å–æ‰€æœ‰API Keys
   * @returns {Promise<Array>} API Keyåˆ—è¡¨
   */
  async getAllApiKeys() {
    const keys = await this.client.keys('apikey:*')
    const apiKeys = []
    for (const key of keys) {
      // è¿‡æ»¤æ‰hash_mapï¼Œå®ƒä¸æ˜¯çœŸæ­£çš„API Key
      if (key === 'apikey:hash_map') {
        continue
      }

      const keyData = await this.client.hgetall(key)
      if (keyData && Object.keys(keyData).length > 0) {
        apiKeys.push({ id: key.replace('apikey:', ''), ...keyData })
      }
    }
    return apiKeys
  }

  /**
   * é€šè¿‡å“ˆå¸Œå€¼æŸ¥æ‰¾API Keyï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
   * @param {string} hashedKey å“ˆå¸Œåçš„Keyå€¼
   * @returns {Promise<Object|null>} API Keyæ•°æ®å¯¹è±¡æˆ–null
   */
  async findApiKeyByHash(hashedKey) {
    // ä½¿ç”¨åå‘æ˜ å°„è¡¨ï¼šhash -> keyId
    const keyId = await this.client.hget('apikey:hash_map', hashedKey)
    if (!keyId) {
      return null
    }

    const keyData = await this.client.hgetall(`apikey:${keyId}`)
    if (keyData && Object.keys(keyData).length > 0) {
      return { id: keyId, ...keyData }
    }

    // å¦‚æœæ•°æ®ä¸å­˜åœ¨ï¼Œæ¸…ç†æ˜ å°„è¡¨
    await this.client.hdel('apikey:hash_map', hashedKey)
    return null
  }

  // ==================== ä½¿ç”¨ç»Ÿè®¡æ“ä½œ (9ä¸ªæ–¹æ³•) ====================

  /**
   * æ ‡å‡†åŒ–æ¨¡å‹åç§°ï¼Œç”¨äºç»Ÿè®¡èšåˆ
   * @param {string} model åŸå§‹æ¨¡å‹åç§°
   * @returns {string} æ ‡å‡†åŒ–åçš„æ¨¡å‹åç§°
   * @private
   */
  _normalizeModelName(model) {
    if (!model || model === 'unknown') {
      return model
    }

    // å¯¹äºBedrockæ¨¡å‹ï¼Œå»æ‰åŒºåŸŸå‰ç¼€è¿›è¡Œç»Ÿä¸€
    if (model.includes('.anthropic.') || model.includes('.claude')) {
      // åŒ¹é…æ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼šregion.anthropic.model-name-v1:0 -> claude-model-name
      // æ”¯æŒæ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼Œå¦‚ï¼šus-east-1, eu-west-1, ap-southeast-1, ca-central-1ç­‰
      let normalized = model.replace(/^[a-z0-9-]+\./, '') // å»æ‰ä»»ä½•åŒºåŸŸå‰ç¼€ï¼ˆæ›´é€šç”¨ï¼‰
      normalized = normalized.replace('anthropic.', '') // å»æ‰anthropicå‰ç¼€
      normalized = normalized.replace(/-v\d+:\d+$/, '') // å»æ‰ç‰ˆæœ¬åç¼€ï¼ˆå¦‚-v1:0, -v2:1ç­‰ï¼‰
      return normalized
    }

    // å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œå»æ‰å¸¸è§çš„ç‰ˆæœ¬åç¼€ï¼ŒåŒ…æ‹¬1Mä¸Šä¸‹æ–‡æ ‡è¯†
    return model.replace(/-v\d+:\d+$|:latest$|\[\d+[a-zA-Z]*\]$|\[1M\]$/, '')
  }

  /**
   * å¢åŠ Tokenä½¿ç”¨ç»Ÿè®¡ï¼ˆæ”¯æŒå¤šç§ç¼“å­˜Tokenç±»å‹ï¼‰
   * @param {string} keyId API Key ID
   * @param {number} tokens æ€»Tokenæ•°
   * @param {number} inputTokens è¾“å…¥Tokenæ•°
   * @param {number} outputTokens è¾“å‡ºTokenæ•°
   * @param {number} cacheCreateTokens ç¼“å­˜åˆ›å»ºTokenæ•°
   * @param {number} cacheReadTokens ç¼“å­˜è¯»å–Tokenæ•°
   * @param {string} model æ¨¡å‹åç§°
   * @param {number} ephemeral5mTokens 5åˆ†é’Ÿç¼“å­˜Tokenæ•°
   * @param {number} ephemeral1hTokens 1å°æ—¶ç¼“å­˜Tokenæ•°
   * @returns {Promise<void>}
   */
  async incrementTokenUsage(
    keyId,
    tokens,
    inputTokens = 0,
    outputTokens = 0,
    cacheCreateTokens = 0,
    cacheReadTokens = 0,
    model = 'unknown',
    ephemeral5mTokens = 0, // æ–°å¢ï¼š5åˆ†é’Ÿç¼“å­˜ tokens
    ephemeral1hTokens = 0 // æ–°å¢ï¼š1å°æ—¶ç¼“å­˜ tokens
  ) {
    const key = `usage:${keyId}`
    const now = new Date()
    const today = getDateStringInTimezone(now)
    const tzDate = getDateInTimezone(now)
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const currentHour = `${today}:${String(getHourInTimezone(now)).padStart(2, '0')}` // æ–°å¢å°æ—¶çº§åˆ«

    const daily = `usage:daily:${keyId}:${today}`
    const monthly = `usage:monthly:${keyId}:${currentMonth}`
    const hourly = `usage:hourly:${keyId}:${currentHour}` // æ–°å¢å°æ—¶çº§åˆ«key

    // æ ‡å‡†åŒ–æ¨¡å‹åç”¨äºç»Ÿè®¡èšåˆ
    const normalizedModel = this._normalizeModelName(model)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡çš„é”®
    const modelDaily = `usage:model:daily:${normalizedModel}:${today}`
    const modelMonthly = `usage:model:monthly:${normalizedModel}:${currentMonth}`
    const modelHourly = `usage:model:hourly:${normalizedModel}:${currentHour}` // æ–°å¢æ¨¡å‹å°æ—¶çº§åˆ«

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡
    const keyModelDaily = `usage:${keyId}:model:daily:${normalizedModel}:${today}`
    const keyModelMonthly = `usage:${keyId}:model:monthly:${normalizedModel}:${currentMonth}`
    const keyModelHourly = `usage:${keyId}:model:hourly:${normalizedModel}:${currentHour}` // æ–°å¢API Keyæ¨¡å‹å°æ—¶çº§åˆ«

    // æ–°å¢ï¼šç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡
    const minuteTimestamp = Math.floor(now.getTime() / 60000)
    const systemMinuteKey = `system:metrics:minute:${minuteTimestamp}`

    // æ™ºèƒ½å¤„ç†è¾“å…¥è¾“å‡ºtokenåˆ†é…
    const finalInputTokens = inputTokens || 0
    const finalOutputTokens = outputTokens || (finalInputTokens > 0 ? 0 : tokens)
    const finalCacheCreateTokens = cacheCreateTokens || 0
    const finalCacheReadTokens = cacheReadTokens || 0

    // é‡æ–°è®¡ç®—çœŸå®çš„æ€»tokenæ•°ï¼ˆåŒ…æ‹¬ç¼“å­˜tokenï¼‰
    const totalTokens =
      finalInputTokens + finalOutputTokens + finalCacheCreateTokens + finalCacheReadTokens
    // æ ¸å¿ƒtokenï¼ˆä¸åŒ…æ‹¬ç¼“å­˜ï¼‰- ç”¨äºä¸å†å²æ•°æ®å…¼å®¹
    const coreTokens = finalInputTokens + finalOutputTokens

    // ä½¿ç”¨Pipelineä¼˜åŒ–æ€§èƒ½
    const pipeline = this.client.pipeline()

    // ç°æœ‰çš„ç»Ÿè®¡ä¿æŒä¸å˜
    // æ ¸å¿ƒtokenç»Ÿè®¡ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    pipeline.hincrby(key, 'totalTokens', coreTokens)
    pipeline.hincrby(key, 'totalInputTokens', finalInputTokens)
    pipeline.hincrby(key, 'totalOutputTokens', finalOutputTokens)
    // ç¼“å­˜tokenç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
    pipeline.hincrby(key, 'totalCacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(key, 'totalCacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(key, 'totalAllTokens', totalTokens) // åŒ…å«æ‰€æœ‰ç±»å‹çš„æ€»token
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
    pipeline.hincrby(key, 'totalEphemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(key, 'totalEphemeral1hTokens', ephemeral1hTokens)
    // è¯·æ±‚è®¡æ•°
    pipeline.hincrby(key, 'totalRequests', 1)

    // æ¯æ—¥ç»Ÿè®¡
    pipeline.hincrby(daily, 'tokens', coreTokens)
    pipeline.hincrby(daily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(daily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(daily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(daily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(daily, 'allTokens', totalTokens)
    pipeline.hincrby(daily, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(daily, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(daily, 'ephemeral1hTokens', ephemeral1hTokens)

    // æ¯æœˆç»Ÿè®¡
    pipeline.hincrby(monthly, 'tokens', coreTokens)
    pipeline.hincrby(monthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(monthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(monthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(monthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(monthly, 'allTokens', totalTokens)
    pipeline.hincrby(monthly, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(monthly, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(monthly, 'ephemeral1hTokens', ephemeral1hTokens)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
    pipeline.hincrby(modelDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelDaily, 'allTokens', totalTokens)
    pipeline.hincrby(modelDaily, 'requests', 1)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
    pipeline.hincrby(modelMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelMonthly, 'allTokens', totalTokens)
    pipeline.hincrby(modelMonthly, 'requests', 1)

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
    pipeline.hincrby(keyModelDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelDaily, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelDaily, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(keyModelDaily, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(keyModelDaily, 'ephemeral1hTokens', ephemeral1hTokens)

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
    pipeline.hincrby(keyModelMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelMonthly, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelMonthly, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(keyModelMonthly, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(keyModelMonthly, 'ephemeral1hTokens', ephemeral1hTokens)

    // å°æ—¶çº§åˆ«ç»Ÿè®¡
    pipeline.hincrby(hourly, 'tokens', coreTokens)
    pipeline.hincrby(hourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(hourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(hourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(hourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(hourly, 'allTokens', totalTokens)
    pipeline.hincrby(hourly, 'requests', 1)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
    pipeline.hincrby(modelHourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelHourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelHourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelHourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelHourly, 'allTokens', totalTokens)
    pipeline.hincrby(modelHourly, 'requests', 1)

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
    pipeline.hincrby(keyModelHourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelHourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelHourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelHourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelHourly, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelHourly, 'requests', 1)

    // æ–°å¢ï¼šç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡
    pipeline.hincrby(systemMinuteKey, 'requests', 1)
    pipeline.hincrby(systemMinuteKey, 'totalTokens', totalTokens)
    pipeline.hincrby(systemMinuteKey, 'inputTokens', finalInputTokens)
    pipeline.hincrby(systemMinuteKey, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(systemMinuteKey, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(systemMinuteKey, 'cacheReadTokens', finalCacheReadTokens)

    // è®¾ç½®è¿‡æœŸæ—¶é—´
    pipeline.expire(daily, 86400 * 32) // 32å¤©è¿‡æœŸ
    pipeline.expire(monthly, 86400 * 365) // 1å¹´è¿‡æœŸ
    pipeline.expire(hourly, 86400 * 7) // å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ
    pipeline.expire(modelDaily, 86400 * 32) // æ¨¡å‹æ¯æ—¥ç»Ÿè®¡32å¤©è¿‡æœŸ
    pipeline.expire(modelMonthly, 86400 * 365) // æ¨¡å‹æ¯æœˆç»Ÿè®¡1å¹´è¿‡æœŸ
    pipeline.expire(modelHourly, 86400 * 7) // æ¨¡å‹å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ
    pipeline.expire(keyModelDaily, 86400 * 32) // API Keyæ¨¡å‹æ¯æ—¥ç»Ÿè®¡32å¤©è¿‡æœŸ
    pipeline.expire(keyModelMonthly, 86400 * 365) // API Keyæ¨¡å‹æ¯æœˆç»Ÿè®¡1å¹´è¿‡æœŸ
    pipeline.expire(keyModelHourly, 86400 * 7) // API Keyæ¨¡å‹å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ

    // ç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡çš„è¿‡æœŸæ—¶é—´ï¼ˆçª—å£æ—¶é—´çš„2å€ï¼‰
    const configLocal = require('../../../config/config')
    const { metricsWindow } = configLocal.system
    pipeline.expire(systemMinuteKey, metricsWindow * 60 * 2)

    // æ‰§è¡ŒPipeline
    await pipeline.exec()
  }

  /**
   * è®°å½•è´¦æˆ·çº§åˆ«çš„ä½¿ç”¨ç»Ÿè®¡
   * @param {string} accountId è´¦æˆ·ID
   * @param {number} totalTokens æ€»Tokenæ•°
   * @param {number} inputTokens è¾“å…¥Tokenæ•°
   * @param {number} outputTokens è¾“å‡ºTokenæ•°
   * @param {number} cacheCreateTokens ç¼“å­˜åˆ›å»ºTokenæ•°
   * @param {number} cacheReadTokens ç¼“å­˜è¯»å–Tokenæ•°
   * @param {string} model æ¨¡å‹åç§°
   * @returns {Promise<void>}
   */
  async incrementAccountUsage(
    accountId,
    totalTokens,
    inputTokens = 0,
    outputTokens = 0,
    cacheCreateTokens = 0,
    cacheReadTokens = 0,
    model = 'unknown'
  ) {
    const now = new Date()
    const today = getDateStringInTimezone(now)
    const tzDate = getDateInTimezone(now)
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const currentHour = `${today}:${String(getHourInTimezone(now)).padStart(2, '0')}`

    // è´¦æˆ·çº§åˆ«ç»Ÿè®¡çš„é”®
    const accountKey = `account_usage:${accountId}`
    const accountDaily = `account_usage:daily:${accountId}:${today}`
    const accountMonthly = `account_usage:monthly:${accountId}:${currentMonth}`
    const accountHourly = `account_usage:hourly:${accountId}:${currentHour}`

    // æ ‡å‡†åŒ–æ¨¡å‹åç”¨äºç»Ÿè®¡èšåˆ
    const normalizedModel = this._normalizeModelName(model)

    // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡çš„é”®
    const accountModelDaily = `account_usage:model:daily:${accountId}:${normalizedModel}:${today}`
    const accountModelMonthly = `account_usage:model:monthly:${accountId}:${normalizedModel}:${currentMonth}`
    const accountModelHourly = `account_usage:model:hourly:${accountId}:${normalizedModel}:${currentHour}`

    // å¤„ç†tokenåˆ†é…
    const finalInputTokens = inputTokens || 0
    const finalOutputTokens = outputTokens || 0
    const finalCacheCreateTokens = cacheCreateTokens || 0
    const finalCacheReadTokens = cacheReadTokens || 0
    const actualTotalTokens =
      finalInputTokens + finalOutputTokens + finalCacheCreateTokens + finalCacheReadTokens
    const coreTokens = finalInputTokens + finalOutputTokens

    await Promise.all([
      // è´¦æˆ·æ€»ä½“ç»Ÿè®¡
      this.client.hincrby(accountKey, 'totalTokens', coreTokens),
      this.client.hincrby(accountKey, 'totalInputTokens', finalInputTokens),
      this.client.hincrby(accountKey, 'totalOutputTokens', finalOutputTokens),
      this.client.hincrby(accountKey, 'totalCacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountKey, 'totalCacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountKey, 'totalAllTokens', actualTotalTokens),
      this.client.hincrby(accountKey, 'totalRequests', 1),

      // è´¦æˆ·æ¯æ—¥ç»Ÿè®¡
      this.client.hincrby(accountDaily, 'tokens', coreTokens),
      this.client.hincrby(accountDaily, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountDaily, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountDaily, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountDaily, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountDaily, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountDaily, 'requests', 1),

      // è´¦æˆ·æ¯æœˆç»Ÿè®¡
      this.client.hincrby(accountMonthly, 'tokens', coreTokens),
      this.client.hincrby(accountMonthly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountMonthly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountMonthly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountMonthly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountMonthly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountMonthly, 'requests', 1),

      // è´¦æˆ·æ¯å°æ—¶ç»Ÿè®¡
      this.client.hincrby(accountHourly, 'tokens', coreTokens),
      this.client.hincrby(accountHourly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountHourly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountHourly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountHourly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountHourly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountHourly, 'requests', 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
      this.client.hincrby(accountModelDaily, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelDaily, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelDaily, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelDaily, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelDaily, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelDaily, 'requests', 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
      this.client.hincrby(accountModelMonthly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelMonthly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelMonthly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelMonthly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelMonthly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelMonthly, 'requests', 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
      this.client.hincrby(accountModelHourly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelHourly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelHourly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelHourly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelHourly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelHourly, 'requests', 1),

      // è®¾ç½®è¿‡æœŸæ—¶é—´
      this.client.expire(accountDaily, 86400 * 32), // 32å¤©è¿‡æœŸ
      this.client.expire(accountMonthly, 86400 * 365), // 1å¹´è¿‡æœŸ
      this.client.expire(accountHourly, 86400 * 7), // 7å¤©è¿‡æœŸ
      this.client.expire(accountModelDaily, 86400 * 32), // 32å¤©è¿‡æœŸ
      this.client.expire(accountModelMonthly, 86400 * 365), // 1å¹´è¿‡æœŸ
      this.client.expire(accountModelHourly, 86400 * 7) // 7å¤©è¿‡æœŸ
    ])
  }

  /**
   * è·å–API Keyä½¿ç”¨ç»Ÿè®¡ï¼ˆåŒ…æ‹¬å…¼å®¹æ€§å¤„ç†ï¼‰
   * @param {string} keyId API Key ID
   * @returns {Promise<Object>} ä½¿ç”¨ç»Ÿè®¡å¯¹è±¡
   */
  async getUsageStats(keyId) {
    const totalKey = `usage:${keyId}`
    const today = getDateStringInTimezone()
    const dailyKey = `usage:daily:${keyId}:${today}`
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const monthlyKey = `usage:monthly:${keyId}:${currentMonth}`

    const [total, daily, monthly] = await Promise.all([
      this.client.hgetall(totalKey),
      this.client.hgetall(dailyKey),
      this.client.hgetall(monthlyKey)
    ])

    // è·å–API Keyçš„åˆ›å»ºæ—¶é—´æ¥è®¡ç®—å¹³å‡å€¼
    const keyData = await this.client.hgetall(`apikey:${keyId}`)
    const createdAt = keyData.createdAt ? new Date(keyData.createdAt) : new Date()
    const now = new Date()
    const daysSinceCreated = Math.max(1, Math.ceil((now - createdAt) / (1000 * 60 * 60 * 24)))

    const totalTokens = parseInt(total.totalTokens) || 0
    const totalRequests = parseInt(total.totalRequests) || 0

    // è®¡ç®—å¹³å‡RPM (requests per minute) å’Œ TPM (tokens per minute)
    const totalMinutes = Math.max(1, daysSinceCreated * 24 * 60)
    const avgRPM = totalRequests / totalMinutes
    const avgTPM = totalTokens / totalMinutes

    // å¤„ç†æ—§æ•°æ®å…¼å®¹æ€§ï¼ˆæ”¯æŒç¼“å­˜tokenï¼‰
    const handleLegacyData = (data) => {
      // ä¼˜å…ˆä½¿ç”¨total*å­—æ®µï¼ˆå­˜å‚¨æ—¶ä½¿ç”¨çš„å­—æ®µï¼‰
      const tokens = parseInt(data.totalTokens) || parseInt(data.tokens) || 0
      const inputTokens = parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
      const outputTokens = parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
      const requests = parseInt(data.totalRequests) || parseInt(data.requests) || 0

      // æ–°å¢ç¼“å­˜tokenå­—æ®µ
      const cacheCreateTokens =
        parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
      const cacheReadTokens =
        parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
      const allTokens = parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0

      const totalFromSeparate = inputTokens + outputTokens
      // è®¡ç®—å®é™…çš„æ€»tokensï¼ˆåŒ…å«æ‰€æœ‰ç±»å‹ï¼‰
      const actualAllTokens =
        allTokens || inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

      if (totalFromSeparate === 0 && tokens > 0) {
        // æ—§æ•°æ®ï¼šæ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»
        return {
          tokens, // ä¿æŒå…¼å®¹æ€§ï¼Œä½†ç»Ÿä¸€ä½¿ç”¨allTokens
          inputTokens: Math.round(tokens * 0.3), // å‡è®¾30%ä¸ºè¾“å…¥
          outputTokens: Math.round(tokens * 0.7), // å‡è®¾70%ä¸ºè¾“å‡º
          cacheCreateTokens: 0, // æ—§æ•°æ®æ²¡æœ‰ç¼“å­˜token
          cacheReadTokens: 0,
          allTokens: tokens, // å¯¹äºæ—§æ•°æ®ï¼ŒallTokensç­‰äºtokens
          requests
        }
      } else {
        // æ–°æ•°æ®æˆ–æ— æ•°æ® - ç»Ÿä¸€ä½¿ç”¨allTokensä½œä¸ºtokensçš„å€¼
        return {
          tokens: actualAllTokens, // ç»Ÿä¸€ä½¿ç”¨allTokensä½œä¸ºæ€»æ•°
          inputTokens,
          outputTokens,
          cacheCreateTokens,
          cacheReadTokens,
          allTokens: actualAllTokens,
          requests
        }
      }
    }

    const totalData = handleLegacyData(total)
    const dailyData = handleLegacyData(daily)
    const monthlyData = handleLegacyData(monthly)

    return {
      total: totalData,
      daily: dailyData,
      monthly: monthlyData,
      averages: {
        rpm: Math.round(avgRPM * 100) / 100, // ä¿ç•™2ä½å°æ•°
        tpm: Math.round(avgTPM * 100) / 100,
        dailyRequests: Math.round((totalRequests / daysSinceCreated) * 100) / 100,
        dailyTokens: Math.round((totalTokens / daysSinceCreated) * 100) / 100
      }
    }
  }

  /**
   * è·å–å½“æ—¥è´¹ç”¨
   * @param {string} keyId API Key ID
   * @returns {Promise<number>} å½“æ—¥è´¹ç”¨
   */
  async getDailyCost(keyId) {
    const today = getDateStringInTimezone()
    const costKey = `usage:cost:daily:${keyId}:${today}`
    const cost = await this.client.get(costKey)
    const result = parseFloat(cost || 0)
    logger.debug(
      `ğŸ’° Getting daily cost for ${keyId}, date: ${today}, key: ${costKey}, value: ${cost}, result: ${result}`
    )
    return result
  }

  /**
   * è·å–æŒ‡å®šæ—¶é—´æ®µçš„æ¨¡å‹å°æ—¶ä½¿ç”¨ç»Ÿè®¡
   * @param {string} keyId API Key ID
   * @param {Date} startDate å¼€å§‹æ—¶é—´
   * @param {number} hours å°æ—¶æ•°(é»˜è®¤24ï¼Œæœ€å¤§168)
   * @returns {Promise<Array>} å°æ—¶ç»Ÿè®¡æ•°æ®æ•°ç»„
   */
  async getModelUsageHourly(keyId, startDate, hours = 24) {
    // å‚æ•°éªŒè¯
    if (!keyId || typeof keyId !== 'string') {
      throw new Error('Invalid keyId parameter')
    }

    if (!(startDate instanceof Date)) {
      throw new Error('startDate must be a Date object')
    }

    if (typeof hours !== 'number' || hours < 1 || hours > 168) {
      throw new Error('Hours parameter must be between 1 and 168')
    }

    const hourlyStats = []

    try {
      // ç”Ÿæˆæ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„å°æ—¶é”®
      const hourKeys = []
      for (let i = 0; i < hours; i++) {
        const currentDate = new Date(startDate.getTime() + i * 60 * 60 * 1000)
        const tzDate = getDateInTimezone(currentDate)
        const dateStr = getDateStringInTimezone(currentDate)
        const hourStr = String(tzDate.getUTCHours()).padStart(2, '0')
        const hourKey = `${dateStr}:${hourStr}`
        hourKeys.push({ hourKey, timestamp: currentDate.toISOString() })
      }

      // ä½¿ç”¨Pipelineæ‰¹é‡æŸ¥è¯¢ä»¥æé«˜æ€§èƒ½
      const pipeline = this.client.pipeline()
      const queryMap = new Map()

      for (const { hourKey } of hourKeys) {
        // æŸ¥è¯¢è¯¥å°æ—¶çš„æ‰€æœ‰æ¨¡å‹æ•°æ®
        const pattern = `usage:${keyId}:model:hourly:*:${hourKey}`
        pipeline.keys(pattern)
        queryMap.set(hourKey, pattern)
      }

      const patternResults = await pipeline.exec()

      // å¤„ç†æ¯ä¸ªå°æ—¶çš„æ•°æ®
      for (let i = 0; i < hourKeys.length; i++) {
        const { hourKey, timestamp } = hourKeys[i]
        const modelKeys = patternResults[i][1] || []

        const hourStat = {
          hour: hourKey,
          timestamp,
          models: {},
          totalTokens: 0,
          totalRequests: 0,
          totalCost: 0
        }

        if (modelKeys.length > 0) {
          // æ‰¹é‡è·å–è¯¥å°æ—¶æ‰€æœ‰æ¨¡å‹çš„è¯¦ç»†æ•°æ®
          const dataPipeline = this.client.pipeline()
          for (const modelKey of modelKeys) {
            dataPipeline.hgetall(modelKey)
          }

          const modelResults = await dataPipeline.exec()

          // å¤„ç†æ¯ä¸ªæ¨¡å‹çš„æ•°æ®
          for (let j = 0; j < modelKeys.length; j++) {
            const modelKey = modelKeys[j]
            const modelData = modelResults[j][1] || {}

            // ä»é”®åæå–æ¨¡å‹å: usage:{keyId}:model:hourly:{model}:{hour}
            const modelMatch = modelKey.match(/usage:.+:model:hourly:(.+):\d{4}-\d{2}-\d{2}:\d{2}$/)
            if (!modelMatch || !modelData || Object.keys(modelData).length === 0) {
              continue
            }

            const modelName = modelMatch[1]
            const inputTokens = parseInt(modelData.inputTokens) || 0
            const outputTokens = parseInt(modelData.outputTokens) || 0
            const cacheCreateTokens = parseInt(modelData.cacheCreateTokens) || 0
            const cacheReadTokens = parseInt(modelData.cacheReadTokens) || 0
            const requests = parseInt(modelData.requests) || 0
            const totalModelTokens =
              inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

            // è®¡ç®—æ¨¡å‹è´¹ç”¨
            const usage = {
              input_tokens: inputTokens,
              output_tokens: outputTokens,
              cache_creation_input_tokens: cacheCreateTokens,
              cache_read_input_tokens: cacheReadTokens
            }

            let modelCost = 0
            try {
              const costResult = CostCalculator.calculateCost(usage, modelName)
              modelCost = costResult.costs.total || 0
            } catch (error) {
              logger.warn(`Failed to calculate cost for model ${modelName}:`, error)
              modelCost = 0
            }

            // æ·»åŠ åˆ°æ¨¡å‹ç»Ÿè®¡
            hourStat.models[modelName] = {
              tokens: totalModelTokens,
              inputTokens,
              outputTokens,
              cacheCreateTokens,
              cacheReadTokens,
              requests,
              cost: modelCost
            }

            // ç´¯è®¡åˆ°å°æ—¶æ€»è®¡
            hourStat.totalTokens += totalModelTokens
            hourStat.totalRequests += requests
            hourStat.totalCost += modelCost
          }
        }

        hourlyStats.push(hourStat)
      }

      logger.debug(
        `ğŸ“Š Retrieved hourly model stats for keyId: ${keyId}, hours: ${hours}, results: ${hourlyStats.length}`
      )
      return hourlyStats
    } catch (error) {
      logger.error(`âŒ Failed to get hourly model usage for keyId ${keyId}:`, error)
      throw error
    }
  }

  /**
   * å¢åŠ å½“æ—¥è´¹ç”¨
   * @param {string} keyId API Key ID
   * @param {number} amount è´¹ç”¨é‡‘é¢
   * @returns {Promise<void>}
   */
  async incrementDailyCost(keyId, amount) {
    const today = getDateStringInTimezone()
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

    const dailyKey = `usage:cost:daily:${keyId}:${today}`
    const monthlyKey = `usage:cost:monthly:${keyId}:${currentMonth}`
    const hourlyKey = `usage:cost:hourly:${keyId}:${currentHour}`
    const totalKey = `usage:cost:total:${keyId}`

    logger.debug(
      `ğŸ’° Incrementing cost for ${keyId}, amount: $${amount}, date: ${today}, dailyKey: ${dailyKey}`
    )

    const results = await Promise.all([
      this.client.incrbyfloat(dailyKey, amount),
      this.client.incrbyfloat(monthlyKey, amount),
      this.client.incrbyfloat(hourlyKey, amount),
      this.client.incrbyfloat(totalKey, amount),
      // è®¾ç½®è¿‡æœŸæ—¶é—´
      this.client.expire(dailyKey, 86400 * 30), // 30å¤©
      this.client.expire(monthlyKey, 86400 * 90), // 90å¤©
      this.client.expire(hourlyKey, 86400 * 7) // 7å¤©
    ])

    logger.debug(`ğŸ’° Cost incremented successfully, new daily total: $${results[0]}`)
  }

  /**
   * è·å–è´¹ç”¨ç»Ÿè®¡
   * @param {string} keyId API Key ID
   * @returns {Promise<Object>} è´¹ç”¨ç»Ÿè®¡å¯¹è±¡
   */
  async getCostStats(keyId) {
    const today = getDateStringInTimezone()
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

    const [daily, monthly, hourly, total] = await Promise.all([
      this.client.get(`usage:cost:daily:${keyId}:${today}`),
      this.client.get(`usage:cost:monthly:${keyId}:${currentMonth}`),
      this.client.get(`usage:cost:hourly:${keyId}:${currentHour}`),
      this.client.get(`usage:cost:total:${keyId}`)
    ])

    return {
      daily: parseFloat(daily || 0),
      monthly: parseFloat(monthly || 0),
      hourly: parseFloat(hourly || 0),
      total: parseFloat(total || 0)
    }
  }

  /**
   * è·å–æ€»è´¹ç”¨
   * @param {string} keyId API Key ID
   * @returns {Promise<number>} æ€»è´¹ç”¨
   */
  async getTotalCost(keyId) {
    const totalKey = `usage:cost:total:${keyId}`
    const cost = await this.client.get(totalKey)
    const result = parseFloat(cost || 0)
    logger.debug(
      `ğŸ’° Getting total cost for ${keyId}, key: ${totalKey}, value: ${cost}, result: ${result}`
    )
    return result
  }

  /**
   * æ ¹æ®æ—¥æœŸèŒƒå›´è·å–è´¹ç”¨ï¼ˆç”¨äºå‘¨è´¹ç”¨å’Œæœˆè´¹ç”¨è®¡ç®—ï¼‰
   * @param {string} keyId API Key ID
   * @param {Date} startDate å¼€å§‹æ—¥æœŸ
   * @param {Date} endDate ç»“æŸæ—¥æœŸ
   * @returns {Promise<number>} æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„è´¹ç”¨
   */
  async getCostByDateRange(keyId, startDate, endDate) {
    try {
      const dates = []
      const current = new Date(startDate)

      // ç”Ÿæˆæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æ—¥æœŸ
      while (current <= endDate) {
        const dateString = current.toISOString().split('T')[0] // YYYY-MM-DD æ ¼å¼
        dates.push(dateString)
        current.setDate(current.getDate() + 1)
      }

      // å¦‚æœæ—¥æœŸèŒƒå›´è¶…è¿‡30å¤©ï¼Œä¸ºäº†æ€§èƒ½è€ƒè™‘ï¼Œä½¿ç”¨æœˆåº¦ç»Ÿè®¡
      if (dates.length > 30) {
        logger.debug(`ğŸ’° Using monthly aggregation for large date range: ${dates.length} days`)

        const monthKeys = new Set()
        dates.forEach((date) => {
          const [year, month] = date.split('-')
          monthKeys.add(`usage:cost:monthly:${keyId}:${year}-${month}`)
        })

        const monthlyResults = await Promise.all(
          Array.from(monthKeys).map((key) => this.client.get(key))
        )

        const totalCost = monthlyResults.reduce((sum, cost) => sum + parseFloat(cost || 0), 0)
        logger.debug(
          `ğŸ’° Cost by date range (monthly): ${keyId}, ${startDate.toISOString()} to ${endDate.toISOString()}, result: $${totalCost}`
        )
        return totalCost
      }

      // å¯¹äºè¾ƒå°çš„æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨æ—¥åº¦ç»Ÿè®¡
      const dailyKeys = dates.map((date) => `usage:cost:daily:${keyId}:${date}`)
      const dailyResults = await Promise.all(dailyKeys.map((key) => this.client.get(key)))

      const totalCost = dailyResults.reduce((sum, cost) => sum + parseFloat(cost || 0), 0)
      logger.debug(
        `ğŸ’° Cost by date range (daily): ${keyId}, ${startDate.toISOString()} to ${endDate.toISOString()}, result: $${totalCost}`
      )
      return totalCost
    } catch (error) {
      logger.warn(`âš ï¸ Failed to get cost by date range for ${keyId}:`, error.message)
      return 0
    }
  }

  /**
   * è·å–æŒ‡å®šClaudeè´¦æˆ·çš„æ¯æ—¥è´¹ç”¨
   * @param {string} accountId - Claudeè´¦æˆ·ID
   * @param {Date} date - æ—¥æœŸï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
   * @returns {Promise<number>} è´¦æˆ·æ¯æ—¥è´¹ç”¨
   */
  async getAccountDailyCost(accountId, date = new Date()) {
    try {
      // å‚æ•°éªŒè¯
      if (!accountId || typeof accountId !== 'string') {
        throw new Error('Invalid accountId: must be a non-empty string')
      }
      if (!(date instanceof Date) && date !== null && date !== undefined) {
        throw new Error('Invalid date: must be a Date object or null/undefined')
      }

      // ç¡®ä¿dateæ˜¯æœ‰æ•ˆçš„Dateå¯¹è±¡
      const targetDate = date || new Date()

      // ä½¿ç”¨æ—¶åŒºè½¬æ¢å‡½æ•°è·å–æ—¥æœŸå­—ç¬¦ä¸²
      const dateString = getDateStringInTimezone(targetDate)
      const costKey = `usage:cost:daily:account:${accountId}:${dateString}`

      const cost = await this.client.get(costKey)

      // ä½¿ç”¨Decimal.jsç¡®ä¿ç²¾åº¦
      const result = new Decimal(cost || 0).toNumber()

      logger.debug(
        `ğŸ’° Getting account daily cost for ${accountId}, date: ${dateString}, key: ${costKey}, result: $${result.toFixed(6)}`
      )

      return result
    } catch (error) {
      logger.error(`âŒ Failed to get account daily cost for ${accountId}:`, error)
      // é™çº§å¤„ç† - è¿”å›0è€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
      return 0
    }
  }

  /**
   * æ ¹æ®æ—¥æœŸèŒƒå›´è·å–è´¦æˆ·è´¹ç”¨
   * @param {string} accountId è´¦æˆ·ID
   * @param {Date} startDate å¼€å§‹æ—¥æœŸ
   * @param {Date} endDate ç»“æŸæ—¥æœŸ
   * @returns {Promise<number>} æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„è´¦æˆ·è´¹ç”¨
   */
  async getAccountCostByDateRange(accountId, startDate, endDate) {
    try {
      const dates = []
      const current = new Date(startDate)

      // ç”Ÿæˆæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æ—¥æœŸï¼Œä½¿ç”¨æ—¶åŒºè½¬æ¢
      while (current <= endDate) {
        const dateString = getDateStringInTimezone(current)
        dates.push(dateString)
        current.setDate(current.getDate() + 1)
      }

      // å¦‚æœæ—¥æœŸèŒƒå›´è¶…è¿‡30å¤©ï¼Œä¸ºäº†æ€§èƒ½è€ƒè™‘ï¼Œä½¿ç”¨æœˆåº¦ç»Ÿè®¡
      if (dates.length > 30) {
        logger.debug(
          `ğŸ’° Using monthly aggregation for account ${accountId} large date range: ${dates.length} days`
        )

        const monthKeys = new Set()
        dates.forEach((date) => {
          const [year, month] = date.split('-')
          monthKeys.add(`usage:cost:monthly:account:${accountId}:${year}-${month}`)
        })

        // å¹¶è¡Œè·å–æœˆåº¦æ•°æ®
        const monthCosts = await Promise.all(
          Array.from(monthKeys).map(async (key) => {
            const cost = await this.client.get(key)
            return parseFloat(cost || 0)
          })
        )

        const totalCost = monthCosts.reduce((sum, cost) => sum + cost, 0)
        logger.debug(
          `ğŸ’° Account ${accountId} cost by date range (monthly): $${totalCost.toFixed(6)}`
        )
        return totalCost
      }

      // å¯¹äºè¾ƒå°çš„æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨æ¯æ—¥ç»Ÿè®¡
      const dailyKeys = dates.map((date) => `usage:cost:daily:account:${accountId}:${date}`)

      // å¹¶è¡Œè·å–æ¯æ—¥è´¹ç”¨æ•°æ®
      const dailyCosts = await Promise.all(
        dailyKeys.map(async (key) => {
          const cost = await this.client.get(key)
          return parseFloat(cost || 0)
        })
      )

      const totalCost = dailyCosts.reduce((sum, cost) => sum + cost, 0)
      logger.debug(
        `ğŸ’° Account ${accountId} cost by date range (${dates.length} days): $${totalCost.toFixed(6)}`
      )
      return totalCost
    } catch (error) {
      logger.warn(`âš ï¸ Failed to get account cost by date range for ${accountId}:`, error.message)
      return 0
    }
  }

  /**
   * å¢é‡æ›´æ–°è´¦æˆ·è´¹ç”¨
   * @param {string} accountId - Claudeè´¦æˆ·ID
   * @param {number} amount - è´¹ç”¨å¢é‡
   * @param {string} model - æ¨¡å‹åç§°
   * @returns {Promise<number>} æ›´æ–°åçš„è´¹ç”¨
   */
  async incrementAccountCost(accountId, amount, model) {
    try {
      // å‚æ•°éªŒè¯
      if (!accountId || typeof accountId !== 'string') {
        throw new Error('Invalid accountId: must be a non-empty string')
      }
      if (typeof amount !== 'number' || amount < 0) {
        throw new Error('Invalid amount: must be a non-negative number')
      }
      if (!model || typeof model !== 'string') {
        throw new Error('Invalid model: must be a non-empty string')
      }

      // ä½¿ç”¨Decimal.jsç¡®ä¿ç²¾åº¦
      const preciseAmount = new Decimal(amount)

      const now = new Date()
      const tzDate = getDateInTimezone(now)
      const dateString = getDateStringInTimezone(now)
      const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
      const currentHour = `${dateString}:${String(tzDate.getUTCHours()).padStart(2, '0')}`

      // Redisé”®ç»“æ„
      const dailyKey = `usage:cost:daily:account:${accountId}:${dateString}`
      const monthlyKey = `usage:cost:monthly:account:${accountId}:${currentMonth}`
      const hourlyKey = `usage:cost:hourly:account:${accountId}:${currentHour}`
      const totalKey = `usage:cost:total:account:${accountId}`

      // æ¨¡å‹çº§åˆ«çš„è´¹ç”¨ç»Ÿè®¡
      const modelDailyKey = `usage:cost:daily:account:${accountId}:${model}:${dateString}`
      const modelMonthlyKey = `usage:cost:monthly:account:${accountId}:${model}:${currentMonth}`

      logger.debug(
        `ğŸ’° Incrementing account cost for ${accountId}, amount: $${preciseAmount.toString()}, model: ${model}, date: ${dateString}`
      )

      // ä½¿ç”¨Pipelineæ‰¹é‡æ“ä½œç¡®ä¿åŸå­æ€§
      const pipeline = this.client.pipeline()

      // åŸºç¡€è´¹ç”¨ç»Ÿè®¡
      pipeline.incrbyfloat(dailyKey, preciseAmount.toNumber())
      pipeline.incrbyfloat(monthlyKey, preciseAmount.toNumber())
      pipeline.incrbyfloat(hourlyKey, preciseAmount.toNumber())
      pipeline.incrbyfloat(totalKey, preciseAmount.toNumber())

      // æ¨¡å‹çº§åˆ«è´¹ç”¨ç»Ÿè®¡
      pipeline.incrbyfloat(modelDailyKey, preciseAmount.toNumber())
      pipeline.incrbyfloat(modelMonthlyKey, preciseAmount.toNumber())

      // è®¾ç½®è¿‡æœŸæ—¶é—´
      pipeline.expire(dailyKey, 86400 * 32) // 32å¤©
      pipeline.expire(monthlyKey, 86400 * 365) // 1å¹´
      pipeline.expire(hourlyKey, 86400 * 7) // 7å¤©
      pipeline.expire(modelDailyKey, 86400 * 32) // 32å¤©
      pipeline.expire(modelMonthlyKey, 86400 * 365) // 1å¹´

      const results = await pipeline.exec()

      // æ£€æŸ¥æ‰§è¡Œç»“æœ
      const dailyResult = results[0]
      if (dailyResult[0]) {
        logger.error(`âŒ Failed to increment daily cost for ${accountId}:`, dailyResult[0])
        throw dailyResult[0]
      }

      const newDailyTotal = parseFloat(dailyResult[1]) || 0

      logger.debug(
        `ğŸ’° Account cost incremented successfully for ${accountId}, model: ${model}, new daily total: $${newDailyTotal.toFixed(6)}`
      )

      return newDailyTotal
    } catch (error) {
      logger.error(`âŒ Failed to increment account cost for ${accountId}:`, error)
      // é™çº§å¤„ç† - è¿”å›0è€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
      return 0
    }
  }

  /**
   * è·å–è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<Object>} è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡å¯¹è±¡
   */
  async getAccountUsageStats(accountId) {
    const accountKey = `account_usage:${accountId}`
    const today = getDateStringInTimezone()
    const accountDailyKey = `account_usage:daily:${accountId}:${today}`
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const accountMonthlyKey = `account_usage:monthly:${accountId}:${currentMonth}`

    const [total, daily, monthly] = await Promise.all([
      this.client.hgetall(accountKey),
      this.client.hgetall(accountDailyKey),
      this.client.hgetall(accountMonthlyKey)
    ])

    // è·å–è´¦æˆ·åˆ›å»ºæ—¶é—´æ¥è®¡ç®—å¹³å‡å€¼ï¼ˆæ”¯æŒå¤šç§è´¦æˆ·ç±»å‹ï¼‰
    const accountPrefixes = [
      `claude:account:${accountId}`,
      `claude_console_account:${accountId}`,
      `gemini:account:${accountId}`,
      `openai:account:${accountId}`,
      `bedrock:account:${accountId}`,
      `azure_openai:account:${accountId}`
    ]

    let createdAt = new Date()
    let accountData = null

    // ä¾æ¬¡å°è¯•ä¸åŒçš„è´¦æˆ·ç±»å‹å‰ç¼€
    for (const prefix of accountPrefixes) {
      try {
        accountData = await this.client.hgetall(prefix)
        if (accountData && accountData.createdAt) {
          createdAt = new Date(accountData.createdAt)
          logger.debug(`âœ… Found account data for ${accountId} with prefix: ${prefix}`)
          break
        }
      } catch (error) {
        logger.debug(`âš ï¸ Failed to get account data with prefix ${prefix}:`, error.message)
      }
    }

    if (!accountData || !accountData.createdAt) {
      logger.debug(`â„¹ï¸ No creation time found for account ${accountId}, using current time`)
    }

    const now = new Date()
    const daysSinceCreated = Math.max(1, Math.ceil((now - createdAt) / (1000 * 60 * 60 * 24)))

    const totalTokens = parseInt(total.totalTokens) || 0
    const totalRequests = parseInt(total.totalRequests) || 0

    // è®¡ç®—å¹³å‡RPMå’ŒTPM
    const totalMinutes = Math.max(1, daysSinceCreated * 24 * 60)
    const avgRPM = totalRequests / totalMinutes
    const avgTPM = totalTokens / totalMinutes

    // å¤„ç†è´¦æˆ·ç»Ÿè®¡æ•°æ®
    const handleAccountData = (data) => {
      const tokens = parseInt(data.totalTokens) || parseInt(data.tokens) || 0
      const inputTokens = parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
      const outputTokens = parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
      const requests = parseInt(data.totalRequests) || parseInt(data.requests) || 0
      const cacheCreateTokens =
        parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
      const cacheReadTokens =
        parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
      const allTokens = parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0

      const actualAllTokens =
        allTokens || inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

      return {
        tokens,
        inputTokens,
        outputTokens,
        cacheCreateTokens,
        cacheReadTokens,
        allTokens: actualAllTokens,
        requests
      }
    }

    const totalData = handleAccountData(total)
    const dailyData = handleAccountData(daily)
    const monthlyData = handleAccountData(monthly)

    return {
      accountId,
      total: totalData,
      daily: dailyData,
      monthly: monthlyData,
      averages: {
        rpm: Math.round(avgRPM * 100) / 100,
        tpm: Math.round(avgTPM * 100) / 100,
        dailyRequests: Math.round((totalRequests / daysSinceCreated) * 100) / 100,
        dailyTokens: Math.round((totalTokens / daysSinceCreated) * 100) / 100
      }
    }
  }

  /**
   * è·å–æ‰€æœ‰è´¦æˆ·çš„ä½¿ç”¨ç»Ÿè®¡
   * @returns {Promise<Array>} æ‰€æœ‰è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡æ•°ç»„
   */
  async getAllAccountsUsageStats() {
    try {
      logger.debug('ğŸ” Starting to get all accounts usage stats with batch optimization...')

      // æ‰¹é‡è·å–æ‰€æœ‰è´¦æˆ·ç±»å‹çš„é”®å
      const [claudeKeys, consoleKeys, geminiKeys, openaiKeys, bedrockKeys, azureKeys] =
        await Promise.all([
          this.client.keys('claude:account:*'),
          this.client.keys('claude_console_account:*'),
          this.client.keys('gemini:account:*'),
          this.client.keys('openai:account:*'),
          this.client.keys('bedrock:account:*'),
          this.client.keys('azure_openai:account:*')
        ])

      logger.debug(
        `ğŸ“Š Found accounts: Claude=${claudeKeys.length}, Console=${consoleKeys.length}, Gemini=${geminiKeys.length}, OpenAI=${openaiKeys.length}, Bedrock=${bedrockKeys.length}, Azure=${azureKeys.length}`
      )

      // åˆå¹¶æ‰€æœ‰é”®ï¼Œå¹¶æ ‡è®°ç±»å‹
      const allAccountKeys = [
        ...claudeKeys.map((key) => ({ key, type: 'claude', prefix: 'claude:account:' })),
        ...consoleKeys.map((key) => ({
          key,
          type: 'claude_console',
          prefix: 'claude_console_account:'
        })),
        ...geminiKeys.map((key) => ({ key, type: 'gemini', prefix: 'gemini:account:' })),
        ...openaiKeys.map((key) => ({ key, type: 'openai', prefix: 'openai:account:' })),
        ...bedrockKeys.map((key) => ({ key, type: 'bedrock', prefix: 'bedrock:account:' })),
        ...azureKeys.map((key) => ({ key, type: 'azure_openai', prefix: 'azure_openai:account:' }))
      ]

      if (allAccountKeys.length === 0) {
        logger.debug('â„¹ï¸ No accounts found')
        return []
      }

      // æ‰¹é‡è·å–æ‰€æœ‰è´¦æˆ·æ•°æ®
      logger.debug(`ğŸ“¦ Batch fetching data for ${allAccountKeys.length} accounts...`)
      const pipeline = this.client.pipeline()
      allAccountKeys.forEach(({ key }) => pipeline.hgetall(key))
      const accountDataResults = await pipeline.exec()

      // è¿‡æ»¤æœ‰æ•ˆè´¦æˆ·å¹¶å‡†å¤‡æ‰¹é‡è·å–ä½¿ç”¨ç»Ÿè®¡
      const validAccounts = []
      accountDataResults.forEach(([err, data], index) => {
        if (!err && data && (data.name || data.email)) {
          const { key, type, prefix } = allAccountKeys[index]
          const accountId = key.replace(prefix, '')

          validAccounts.push({
            id: accountId,
            data,
            type,
            name: data.name || data.email || accountId,
            email: data.email || '',
            status: data.status || 'unknown',
            isActive: data.isActive === 'true'
          })
        }
      })

      logger.debug(`âœ… Found ${validAccounts.length} valid accounts, getting usage stats...`)

      // å¹¶è¡Œè·å–æ‰€æœ‰è´¦æˆ·çš„ä½¿ç”¨ç»Ÿè®¡
      const statsPromises = validAccounts.map((account) =>
        this.getAccountUsageStats(account.id).catch((error) => {
          logger.warn(`âš ï¸ Failed to get stats for account ${account.id}:`, error.message)
          return {
            total: { allTokens: 0, requests: 0 },
            daily: { allTokens: 0, requests: 0 },
            monthly: { allTokens: 0, requests: 0 },
            averages: { rpm: 0, tpm: 0 }
          }
        })
      )

      const statsResults = await Promise.all(statsPromises)

      // ç»„åˆç»“æœ
      const accountStats = validAccounts.map((account, index) => ({
        id: account.id,
        name: account.name,
        email: account.email,
        status: account.status,
        isActive: account.isActive,
        accountType: account.type,
        ...statsResults[index]
      }))

      // æŒ‰å½“æ—¥tokenä½¿ç”¨é‡æ’åº
      accountStats.sort((a, b) => (b.daily?.allTokens || 0) - (a.daily?.allTokens || 0))

      logger.debug(
        `ğŸ‰ Successfully processed ${accountStats.length} accounts with batch optimization`
      )
      return accountStats
    } catch (error) {
      logger.error('âŒ Failed to get all accounts usage stats:', error)
      return []
    }
  }

  /**
   * æ¸…ç©ºæ‰€æœ‰API Keyçš„ä½¿ç”¨ç»Ÿè®¡æ•°æ®
   * @returns {Promise<Object>} æ¸…ç†ç»Ÿè®¡ç»“æœ
   */
  async resetAllUsageStats() {
    const client = this.getClientSafe()
    const stats = {
      deletedKeys: 0,
      deletedDailyKeys: 0,
      deletedMonthlyKeys: 0,
      resetApiKeys: 0
    }

    try {
      // è·å–æ‰€æœ‰API Key ID
      const apiKeyIds = []
      const apiKeyKeys = await client.keys('apikey:*')

      for (const key of apiKeyKeys) {
        if (key === 'apikey:hash_map') {
          continue
        } // è·³è¿‡å“ˆå¸Œæ˜ å°„è¡¨
        const keyId = key.replace('apikey:', '')
        apiKeyIds.push(keyId)
      }

      // æ¸…ç©ºæ¯ä¸ªAPI Keyçš„ä½¿ç”¨ç»Ÿè®¡
      for (const keyId of apiKeyIds) {
        // åˆ é™¤æ€»ä½“ä½¿ç”¨ç»Ÿè®¡
        const usageKey = `usage:${keyId}`
        const deleted = await client.del(usageKey)
        if (deleted > 0) {
          stats.deletedKeys++
        }

        // åˆ é™¤è¯¥API Keyçš„æ¯æ—¥ç»Ÿè®¡ï¼ˆä½¿ç”¨ç²¾ç¡®çš„keyIdåŒ¹é…ï¼‰
        const dailyKeys = await client.keys(`usage:daily:${keyId}:*`)
        if (dailyKeys.length > 0) {
          await client.del(...dailyKeys)
          stats.deletedDailyKeys += dailyKeys.length
        }

        // åˆ é™¤è¯¥API Keyçš„æ¯æœˆç»Ÿè®¡ï¼ˆä½¿ç”¨ç²¾ç¡®çš„keyIdåŒ¹é…ï¼‰
        const monthlyKeys = await client.keys(`usage:monthly:${keyId}:*`)
        if (monthlyKeys.length > 0) {
          await client.del(...monthlyKeys)
          stats.deletedMonthlyKeys += monthlyKeys.length
        }

        // é‡ç½®API Keyçš„lastUsedAtå­—æ®µ
        const keyData = await client.hgetall(`apikey:${keyId}`)
        if (keyData && Object.keys(keyData).length > 0) {
          keyData.lastUsedAt = ''
          await client.hmset(`apikey:${keyId}`, keyData)
          stats.resetApiKeys++
        }
      }

      // é¢å¤–æ¸…ç†ï¼šåˆ é™¤æ‰€æœ‰å¯èƒ½é—æ¼çš„usageç›¸å…³é”®
      const allUsageKeys = await client.keys('usage:*')
      if (allUsageKeys.length > 0) {
        await client.del(...allUsageKeys)
        stats.deletedKeys += allUsageKeys.length
      }

      return stats
    } catch (error) {
      throw new Error(`Failed to reset usage stats: ${error.message}`)
    }
  }

  // ==================== ç³»ç»Ÿç»Ÿè®¡ (4ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–åŸºç¡€ç³»ç»Ÿç»Ÿè®¡æ•°æ®
   * @returns {Promise<Object>} ç³»ç»Ÿç»Ÿè®¡å¯¹è±¡ï¼ŒåŒ…å«API Keyã€Claudeè´¦æˆ·å’Œä½¿ç”¨è®°å½•çš„æ€»æ•°
   */
  async getSystemStats() {
    const keys = await Promise.all([
      this.client.keys('apikey:*'),
      this.client.keys('claude:account:*'),
      this.client.keys('usage:*')
    ])

    return {
      totalApiKeys: keys[0].length,
      totalClaudeAccounts: keys[1].length,
      totalUsageRecords: keys[2].length
    }
  }

  /**
   * è·å–å½“æ—¥ç³»ç»Ÿç»Ÿè®¡æ•°æ®ï¼ˆå¤æ‚çš„æ‰¹é‡Pipelineæ“ä½œå’Œå…¼å®¹æ€§å¤„ç†ï¼‰
   * @returns {Promise<Object>} å½“æ—¥ç»Ÿè®¡å¯¹è±¡ï¼ŒåŒ…å«è¯·æ±‚æ•°ã€Tokenæ•°å’ŒAPI Keyåˆ›å»ºæ•°
   */
  async getTodayStats() {
    try {
      const today = getDateStringInTimezone()
      const dailyKeys = await this.client.keys(`usage:daily:*:${today}`)

      let totalRequestsToday = 0
      let totalTokensToday = 0
      let totalInputTokensToday = 0
      let totalOutputTokensToday = 0
      let totalCacheCreateTokensToday = 0
      let totalCacheReadTokensToday = 0

      // æ‰¹é‡è·å–æ‰€æœ‰ä»Šæ—¥æ•°æ®ï¼Œæé«˜æ€§èƒ½
      if (dailyKeys.length > 0) {
        const pipeline = this.client.pipeline()
        dailyKeys.forEach((key) => pipeline.hgetall(key))
        const results = await pipeline.exec()

        for (const [error, dailyData] of results) {
          if (error || !dailyData) {
            continue
          }

          totalRequestsToday += parseInt(dailyData.requests) || 0
          const currentDayTokens = parseInt(dailyData.tokens) || 0
          totalTokensToday += currentDayTokens

          // å¤„ç†æ—§æ•°æ®å…¼å®¹æ€§ï¼šå¦‚æœæœ‰æ€»tokenä½†æ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»ï¼Œåˆ™ä½¿ç”¨æ€»tokenä½œä¸ºè¾“å‡ºtoken
          const inputTokens = parseInt(dailyData.inputTokens) || 0
          const outputTokens = parseInt(dailyData.outputTokens) || 0
          const cacheCreateTokens = parseInt(dailyData.cacheCreateTokens) || 0
          const cacheReadTokens = parseInt(dailyData.cacheReadTokens) || 0
          const totalTokensFromSeparate = inputTokens + outputTokens

          if (totalTokensFromSeparate === 0 && currentDayTokens > 0) {
            // æ—§æ•°æ®ï¼šæ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»ï¼Œå‡è®¾70%ä¸ºè¾“å‡ºï¼Œ30%ä¸ºè¾“å…¥ï¼ˆåŸºäºä¸€èˆ¬å¯¹è¯æ¯”ä¾‹ï¼‰
            totalOutputTokensToday += Math.round(currentDayTokens * 0.7)
            totalInputTokensToday += Math.round(currentDayTokens * 0.3)
          } else {
            // æ–°æ•°æ®ï¼šä½¿ç”¨å®é™…çš„è¾“å…¥è¾“å‡ºåˆ†ç¦»
            totalInputTokensToday += inputTokens
            totalOutputTokensToday += outputTokens
          }

          // æ·»åŠ cache tokenç»Ÿè®¡
          totalCacheCreateTokensToday += cacheCreateTokens
          totalCacheReadTokensToday += cacheReadTokens
        }
      }

      // è·å–ä»Šæ—¥åˆ›å»ºçš„API Keyæ•°é‡ï¼ˆæ‰¹é‡ä¼˜åŒ–ï¼‰
      const allApiKeys = await this.client.keys('apikey:*')
      let apiKeysCreatedToday = 0

      if (allApiKeys.length > 0) {
        const pipeline = this.client.pipeline()
        allApiKeys.forEach((key) => pipeline.hget(key, 'createdAt'))
        const results = await pipeline.exec()

        for (const [error, createdAt] of results) {
          if (!error && createdAt && createdAt.startsWith(today)) {
            apiKeysCreatedToday++
          }
        }
      }

      return {
        requestsToday: totalRequestsToday,
        tokensToday: totalTokensToday,
        inputTokensToday: totalInputTokensToday,
        outputTokensToday: totalOutputTokensToday,
        cacheCreateTokensToday: totalCacheCreateTokensToday,
        cacheReadTokensToday: totalCacheReadTokensToday,
        apiKeysCreatedToday
      }
    } catch (error) {
      logger.error('Error getting today stats:', error)
      return {
        requestsToday: 0,
        tokensToday: 0,
        inputTokensToday: 0,
        outputTokensToday: 0,
        cacheCreateTokensToday: 0,
        cacheReadTokensToday: 0,
        apiKeysCreatedToday: 0
      }
    }
  }

  /**
   * è·å–ç³»ç»Ÿçº§å¹³å‡RPM/TPMè®¡ç®—ï¼ˆå¤æ‚çš„æ‰¹é‡æ•°æ®å¤„ç†ï¼‰
   * @returns {Promise<Object>} ç³»ç»Ÿå¹³å‡å€¼å¯¹è±¡ï¼ŒåŒ…å«RPMã€TPMå’ŒTokenåˆ†å¸ƒæ•°æ®
   */
  async getSystemAverages() {
    try {
      const allApiKeys = await this.client.keys('apikey:*')
      let totalRequests = 0
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let oldestCreatedAt = new Date()

      // æ‰¹é‡è·å–æ‰€æœ‰usageæ•°æ®å’Œkeyæ•°æ®ï¼Œæé«˜æ€§èƒ½
      const usageKeys = allApiKeys.map((key) => `usage:${key.replace('apikey:', '')}`)
      const pipeline = this.client.pipeline()

      // æ·»åŠ æ‰€æœ‰usageæŸ¥è¯¢
      usageKeys.forEach((key) => pipeline.hgetall(key))
      // æ·»åŠ æ‰€æœ‰keyæ•°æ®æŸ¥è¯¢
      allApiKeys.forEach((key) => pipeline.hgetall(key))

      const results = await pipeline.exec()
      const usageResults = results.slice(0, usageKeys.length)
      const keyResults = results.slice(usageKeys.length)

      for (let i = 0; i < allApiKeys.length; i++) {
        const totalData = usageResults[i][1] || {}
        const keyData = keyResults[i][1] || {}

        totalRequests += parseInt(totalData.totalRequests) || 0
        totalTokens += parseInt(totalData.totalTokens) || 0
        totalInputTokens += parseInt(totalData.totalInputTokens) || 0
        totalOutputTokens += parseInt(totalData.totalOutputTokens) || 0

        const createdAt = keyData.createdAt ? new Date(keyData.createdAt) : new Date()
        if (createdAt < oldestCreatedAt) {
          oldestCreatedAt = createdAt
        }
      }

      const now = new Date()
      // ä¿æŒä¸ä¸ªäººAPI Keyè®¡ç®—ä¸€è‡´çš„ç®—æ³•ï¼šæŒ‰å¤©è®¡ç®—ç„¶åè½¬æ¢ä¸ºåˆ†é’Ÿ
      const daysSinceOldest = Math.max(
        1,
        Math.ceil((now - oldestCreatedAt) / (1000 * 60 * 60 * 24))
      )
      const totalMinutes = daysSinceOldest * 24 * 60

      return {
        systemRPM: Math.round((totalRequests / totalMinutes) * 100) / 100,
        systemTPM: Math.round((totalTokens / totalMinutes) * 100) / 100,
        totalInputTokens,
        totalOutputTokens,
        totalTokens
      }
    } catch (error) {
      logger.error('Error getting system averages:', error)
      return {
        systemRPM: 0,
        systemTPM: 0,
        totalInputTokens: 0,
        totalOutputTokens: 0,
        totalTokens: 0
      }
    }
  }

  /**
   * è·å–å®æ—¶ç³»ç»ŸæŒ‡æ ‡ï¼ˆåŸºäºæ»‘åŠ¨çª—å£çš„å¤æ‚è®¡ç®—é€»è¾‘ï¼‰
   * @returns {Promise<Object>} å®æ—¶ç³»ç»ŸæŒ‡æ ‡å¯¹è±¡ï¼ŒåŒ…å«å®æ—¶RPM/TPMå’Œçª—å£å†…è¯¦ç»†ç»Ÿè®¡
   */
  async getRealtimeSystemMetrics() {
    try {
      const configLocal = require('../../../config/config')
      const windowMinutes = configLocal.system.metricsWindow || 5

      const now = new Date()
      const currentMinute = Math.floor(now.getTime() / 60000)

      // è°ƒè¯•ï¼šæ‰“å°å½“å‰æ—¶é—´å’Œåˆ†é’Ÿæ—¶é—´æˆ³
      logger.debug(
        `ğŸ” Realtime metrics - Current time: ${now.toISOString()}, Minute timestamp: ${currentMinute}`
      )

      // ä½¿ç”¨Pipelineæ‰¹é‡è·å–çª—å£å†…çš„æ‰€æœ‰åˆ†é’Ÿæ•°æ®
      const pipeline = this.client.pipeline()
      const minuteKeys = []
      for (let i = 0; i < windowMinutes; i++) {
        const minuteKey = `system:metrics:minute:${currentMinute - i}`
        minuteKeys.push(minuteKey)
        pipeline.hgetall(minuteKey)
      }

      logger.debug(`ğŸ” Realtime metrics - Checking keys: ${minuteKeys.join(', ')}`)

      const results = await pipeline.exec()

      // èšåˆè®¡ç®—
      let totalRequests = 0
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let totalCacheCreateTokens = 0
      let totalCacheReadTokens = 0
      let validDataCount = 0

      results.forEach(([err, data], index) => {
        if (!err && data && Object.keys(data).length > 0) {
          validDataCount++
          totalRequests += parseInt(data.requests || 0)
          totalTokens += parseInt(data.totalTokens || 0)
          totalInputTokens += parseInt(data.inputTokens || 0)
          totalOutputTokens += parseInt(data.outputTokens || 0)
          totalCacheCreateTokens += parseInt(data.cacheCreateTokens || 0)
          totalCacheReadTokens += parseInt(data.cacheReadTokens || 0)

          logger.debug(`ğŸ” Realtime metrics - Key ${minuteKeys[index]} data:`, {
            requests: data.requests,
            totalTokens: data.totalTokens
          })
        }
      })

      logger.debug(
        `ğŸ” Realtime metrics - Valid data count: ${validDataCount}/${windowMinutes}, Total requests: ${totalRequests}, Total tokens: ${totalTokens}`
      )

      // è®¡ç®—å¹³å‡å€¼ï¼ˆæ¯åˆ†é’Ÿï¼‰
      const realtimeRPM =
        windowMinutes > 0 ? Math.round((totalRequests / windowMinutes) * 100) / 100 : 0
      const realtimeTPM =
        windowMinutes > 0 ? Math.round((totalTokens / windowMinutes) * 100) / 100 : 0

      const result = {
        realtimeRPM,
        realtimeTPM,
        windowMinutes,
        totalRequests,
        totalTokens,
        totalInputTokens,
        totalOutputTokens,
        totalCacheCreateTokens,
        totalCacheReadTokens
      }

      logger.debug('ğŸ” Realtime metrics - Final result:', result)

      return result
    } catch (error) {
      logger.error('Error getting realtime system metrics:', error)
      // å¦‚æœå‡ºé”™ï¼Œè¿”å›å†å²å¹³å‡å€¼ä½œä¸ºé™çº§æ–¹æ¡ˆ
      const historicalMetrics = await this.getSystemAverages()
      return {
        realtimeRPM: historicalMetrics.systemRPM,
        realtimeTPM: historicalMetrics.systemTPM,
        windowMinutes: 0, // æ ‡è¯†ä½¿ç”¨äº†å†å²æ•°æ®
        totalRequests: 0,
        totalTokens: historicalMetrics.totalTokens,
        totalInputTokens: historicalMetrics.totalInputTokens,
        totalOutputTokens: historicalMetrics.totalOutputTokens,
        totalCacheCreateTokens: 0,
        totalCacheReadTokens: 0
      }
    }
  }

  /**
   * è·å–è´¦æˆ·ä¼šè¯çª—å£ä½¿ç”¨ç»Ÿè®¡
   * @param {string} accountId è´¦æˆ·ID
   * @param {string} windowStart çª—å£å¼€å§‹æ—¶é—´ï¼ˆISOå­—ç¬¦ä¸²ï¼‰
   * @param {string} windowEnd çª—å£ç»“æŸæ—¶é—´ï¼ˆISOå­—ç¬¦ä¸²ï¼‰
   * @returns {Promise<Object>} ä¼šè¯çª—å£ä½¿ç”¨ç»Ÿè®¡
   */
  async getSessionWindowUsage(accountId, windowStart, windowEnd) {
    let retries = 0
    const maxRetries = 3

    while (retries < maxRetries) {
      try {
        // å‚æ•°éªŒè¯å’Œæ¸…ç†ï¼ˆè¿™äº›é”™è¯¯ä¸åº”è¯¥é‡è¯•ï¼‰
        if (!accountId || typeof accountId !== 'string') {
          throw new Error('Invalid accountId parameter')
        }
        if (!windowStart || !windowEnd) {
          throw new Error('Invalid time window parameters')
        }

        const startDate = new Date(windowStart)
        const endDate = new Date(windowEnd)

        // éªŒè¯æ—¶é—´çª—å£çš„æœ‰æ•ˆæ€§ï¼ˆè¿™äº›é”™è¯¯ä¸åº”è¯¥é‡è¯•ï¼‰
        if (isNaN(startDate.getTime()) || isNaN(endDate.getTime())) {
          throw new Error('Invalid date format in time window')
        }
        if (startDate >= endDate) {
          throw new Error('Start date must be before end date')
        }

        // é™åˆ¶æ—¶é—´çª—å£å¤§å°ä»¥é˜²æ­¢è¿‡å¤§æŸ¥è¯¢
        const windowSizeHours = (endDate.getTime() - startDate.getTime()) / (1000 * 60 * 60)
        if (windowSizeHours > 24 * 7) {
          // é™åˆ¶ä¸ºä¸€å‘¨
          logger.warn(
            `âš ï¸ Large time window detected: ${windowSizeHours} hours for account ${accountId}`
          )
        }

        // æ·»åŠ æ—¥å¿—ä»¥è°ƒè¯•æ—¶é—´çª—å£
        logger.debug(
          `ğŸ“Š Getting session window usage for account ${accountId} (attempt ${retries + 1}/${maxRetries})`
        )
        logger.debug(`   Window: ${windowStart} to ${windowEnd}`)
        logger.debug(`   Start UTC: ${startDate.toISOString()}, End UTC: ${endDate.toISOString()}`)

        // è·å–çª—å£å†…æ‰€æœ‰å¯èƒ½çš„å°æ—¶é”®
        // é‡è¦ï¼šéœ€è¦ä½¿ç”¨é…ç½®çš„æ—¶åŒºæ¥æ„å»ºé”®åï¼Œå› ä¸ºæ•°æ®å­˜å‚¨æ—¶ä½¿ç”¨çš„æ˜¯é…ç½®æ—¶åŒº
        const hourlyKeys = []
        const currentHour = new Date(startDate)
        currentHour.setMinutes(0)
        currentHour.setSeconds(0)
        currentHour.setMilliseconds(0)

        while (currentHour <= endDate) {
          try {
            // ä½¿ç”¨æ—¶åŒºè½¬æ¢å‡½æ•°æ¥è·å–æ­£ç¡®çš„æ—¥æœŸå’Œå°æ—¶
            const tzDateStr = getDateStringInTimezone(currentHour)
            const tzHour = String(getHourInTimezone(currentHour)).padStart(2, '0')
            const key = `account_usage:hourly:${accountId}:${tzDateStr}:${tzHour}`

            logger.debug(`   Adding hourly key: ${key}`)
            hourlyKeys.push(key)
            currentHour.setHours(currentHour.getHours() + 1)
          } catch (timeZoneError) {
            logger.warn(
              `âš ï¸ Failed to process hour ${currentHour.toISOString()}:`,
              timeZoneError.message
            )
            currentHour.setHours(currentHour.getHours() + 1)
            continue
          }
        }

        if (hourlyKeys.length === 0) {
          logger.debug('   No hourly keys to check, returning empty usage')
          return this._getEmptySessionUsage()
        }

        logger.debug(`   Total hourly keys to check: ${hourlyKeys.length}`)

        // ä½¿ç”¨è¿æ¥é‡è¯•æœºåˆ¶è·å–Rediså®¢æˆ·ç«¯
        const client = await this.getClientWithReconnect()

        let results = []
        try {
          // æ‰¹é‡è·å–æ‰€æœ‰å°æ—¶æ•°æ®ï¼Œæ·»åŠ è¶…æ—¶ä¿æŠ¤
          const pipeline = client.pipeline()
          hourlyKeys.forEach((key) => {
            pipeline.hgetall(key)
          })

          // æ·»åŠ ç®¡é“æ‰§è¡Œè¶…æ—¶
          const pipelinePromise = pipeline.exec()
          const timeoutPromise = new Promise(
            (_, reject) => setTimeout(() => reject(new Error('Pipeline execution timeout')), 30000) // 30ç§’è¶…æ—¶
          )

          results = await Promise.race([pipelinePromise, timeoutPromise])
          logger.debug(`   Successfully retrieved ${results.length} hourly results`)
        } catch (pipelineError) {
          logger.error(
            `âŒ Pipeline execution failed (attempt ${retries + 1}):`,
            pipelineError.message
          )
          throw pipelineError
        }

        // èšåˆæ•°æ®ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰
        let totalInputTokens = 0
        let totalOutputTokens = 0
        let totalCacheCreateTokens = 0
        let totalCacheReadTokens = 0
        let totalAllTokens = 0
        let totalRequests = 0
        const modelUsage = {}

        logger.debug(`   Processing ${results.length} hourly results`)

        try {
          for (const [error, data] of results) {
            if (error) {
              logger.debug(`   Skipping result due to error: ${error.message}`)
              continue
            }

            if (!data || Object.keys(data).length === 0) {
              continue
            }

            try {
              // å¤„ç†æ€»è®¡æ•°æ®ï¼ˆä¿®å¤å­—æ®µåä¸ä¸€è‡´é—®é¢˜ï¼‰ï¼Œå¢å¼ºæ•°æ®éªŒè¯
              const hourInputTokens = Math.max(0, parseInt(data.inputTokens || 0))
              const hourOutputTokens = Math.max(0, parseInt(data.outputTokens || 0))
              const hourCacheCreateTokens = Math.max(0, parseInt(data.cacheCreateTokens || 0))
              const hourCacheReadTokens = Math.max(0, parseInt(data.cacheReadTokens || 0))
              const hourAllTokens = Math.max(0, parseInt(data.allTokens || 0))
              const hourRequests = Math.max(0, parseInt(data.requests || 0))

              totalInputTokens += hourInputTokens
              totalOutputTokens += hourOutputTokens
              totalCacheCreateTokens += hourCacheCreateTokens
              totalCacheReadTokens += hourCacheReadTokens
              totalAllTokens += hourAllTokens
              totalRequests += hourRequests

              if (hourAllTokens > 0) {
                logger.debug(`   Hour data: allTokens=${hourAllTokens}, requests=${hourRequests}`)
              }
            } catch (dataProcessError) {
              logger.warn(`âš ï¸ Failed to process hour data:`, dataProcessError.message)
              // ç»§ç»­å¤„ç†å…¶ä»–å°æ—¶çš„æ•°æ®ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
            }
          }
        } catch (aggregationError) {
          logger.error(`âŒ Data aggregation failed:`, aggregationError.message)
          throw aggregationError
        }

        // è·å–çª—å£å†…çš„æ¨¡å‹ä½¿ç”¨æ•°æ®ï¼ˆä»ç‹¬ç«‹çš„æ¨¡å‹é”®ä¸­ï¼‰
        logger.debug(`ğŸ” Getting model-specific usage data for window...`)
        const modelKeys = []
        const modelHour = new Date(startDate)
        modelHour.setMinutes(0, 0, 0)

        try {
          while (modelHour <= endDate) {
            try {
              const tzDateStr = getDateStringInTimezone(modelHour)
              const tzHour = String(getHourInTimezone(modelHour)).padStart(2, '0')
              const hourStr = `${tzDateStr}:${tzHour}`

              // è·å–æ‰€æœ‰å¯èƒ½çš„æ¨¡å‹é”®ï¼Œæ·»åŠ è¶…æ—¶ä¿æŠ¤
              const modelPattern = `account_usage:model:hourly:${accountId}:*:${hourStr}`

              try {
                const keysPromise = client.keys(modelPattern)
                const keysTimeout = new Promise(
                  (_, reject) =>
                    setTimeout(() => reject(new Error('Model keys query timeout')), 10000) // 10ç§’è¶…æ—¶
                )

                const foundModelKeys = await Promise.race([keysPromise, keysTimeout])
                modelKeys.push(...foundModelKeys)
                logger.debug(`   Found ${foundModelKeys.length} model keys for hour ${hourStr}`)
              } catch (keyError) {
                logger.warn(`âš ï¸ Failed to get model keys for hour ${hourStr}:`, keyError.message)
                // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªå°æ—¶ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
              }

              modelHour.setHours(modelHour.getHours() + 1)
            } catch (hourProcessError) {
              logger.warn(
                `âš ï¸ Failed to process model hour ${modelHour.toISOString()}:`,
                hourProcessError.message
              )
              modelHour.setHours(modelHour.getHours() + 1)
              continue
            }
          }
        } catch (modelKeysError) {
          logger.error(`âŒ Model keys collection failed:`, modelKeysError.message)
          // ä¸ä¸­æ–­ä¸»æµç¨‹ï¼Œæ¨¡å‹æ•°æ®ä¸ºå¯é€‰æ•°æ®
        }

        // æ‰¹é‡è·å–æ¨¡å‹æ•°æ®ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰
        if (modelKeys.length > 0) {
          logger.debug(`ğŸ“Š Processing ${modelKeys.length} model keys...`)
          try {
            // æ·»åŠ æ¨¡å‹æ•°æ®ç®¡é“è¶…æ—¶ä¿æŠ¤
            const modelPipeline = client.pipeline()
            modelKeys.forEach((key) => modelPipeline.hgetall(key))

            const modelPipelinePromise = modelPipeline.exec()
            const modelTimeoutPromise = new Promise(
              (_, reject) =>
                setTimeout(() => reject(new Error('Model pipeline execution timeout')), 20000) // 20ç§’è¶…æ—¶
            )

            const modelResults = await Promise.race([modelPipelinePromise, modelTimeoutPromise])

            let processedModels = 0
            let skippedModels = 0

            modelResults.forEach(([err, data], index) => {
              if (err) {
                logger.debug(`   Skipping model result ${index} due to error: ${err.message}`)
                skippedModels++
                return
              }

              if (!data || Object.keys(data).length === 0) {
                return
              }

              try {
                // ä»é”®åä¸­æå–æ¨¡å‹å: account_usage:model:hourly:accountId:modelName:hour
                const keyParts = modelKeys[index].split(':')
                if (keyParts.length < 5) {
                  logger.warn(`âš ï¸ Invalid model key format: ${modelKeys[index]}`)
                  skippedModels++
                  return
                }

                const modelName = keyParts[4] // æ¨¡å‹ååœ¨ç¬¬5ä¸ªä½ç½®ï¼ˆç´¢å¼•4ï¼‰

                if (!modelUsage[modelName]) {
                  modelUsage[modelName] = {
                    inputTokens: 0,
                    outputTokens: 0,
                    cacheCreateTokens: 0,
                    cacheReadTokens: 0,
                    allTokens: 0,
                    requests: 0
                  }
                }

                // å¢å¼ºæ•°æ®éªŒè¯å’Œå¤„ç†
                modelUsage[modelName].inputTokens += Math.max(0, parseInt(data.inputTokens || 0))
                modelUsage[modelName].outputTokens += Math.max(0, parseInt(data.outputTokens || 0))
                modelUsage[modelName].cacheCreateTokens += Math.max(
                  0,
                  parseInt(data.cacheCreateTokens || 0)
                )
                modelUsage[modelName].cacheReadTokens += Math.max(
                  0,
                  parseInt(data.cacheReadTokens || 0)
                )
                modelUsage[modelName].allTokens += Math.max(0, parseInt(data.allTokens || 0))
                modelUsage[modelName].requests += Math.max(0, parseInt(data.requests || 0))
                processedModels++

                logger.debug(
                  `   Model ${modelName}: ${data.allTokens} tokens, ${data.requests} requests`
                )
              } catch (modelProcessError) {
                logger.warn(
                  `âš ï¸ Failed to process model data for key ${modelKeys[index]}:`,
                  modelProcessError.message
                )
                skippedModels++
              }
            })

            logger.debug(
              `âœ… Successfully processed ${processedModels} model entries, skipped ${skippedModels}`
            )
          } catch (modelPipelineError) {
            logger.error(`âŒ Failed to get model data:`, modelPipelineError.message)
            // ä¸ä¸­æ–­ä¸»æµç¨‹ï¼Œæ¨¡å‹æ•°æ®ä¸ºå¯é€‰æ•°æ®
          }
        } else {
          logger.debug(`â„¹ï¸ No model-specific data found for the time window`)
        }

        // æœ€ç»ˆç»“æœæ±‡æ€»å’ŒéªŒè¯
        logger.debug(`ğŸ“Š Session window usage summary:`)
        logger.debug(`   Total allTokens: ${totalAllTokens}`)
        logger.debug(`   Total requests: ${totalRequests}`)
        logger.debug(`   Input: ${totalInputTokens}, Output: ${totalOutputTokens}`)
        logger.debug(
          `   Cache Create: ${totalCacheCreateTokens}, Cache Read: ${totalCacheReadTokens}`
        )

        const result = {
          totalInputTokens,
          totalOutputTokens,
          totalCacheCreateTokens,
          totalCacheReadTokens,
          totalAllTokens,
          totalRequests,
          modelUsage,
          window: {
            start: windowStart,
            end: windowEnd,
            durationHours: Math.ceil((endDate.getTime() - startDate.getTime()) / (1000 * 60 * 60))
          }
        }

        // æˆåŠŸå®Œæˆï¼Œè¿”å›ç»“æœ
        logger.debug(
          `âœ… Successfully completed session window usage query for account ${accountId}`
        )
        return result
      } catch (error) {
        retries++

        // åŒºåˆ†ä¸åŒç±»å‹çš„é”™è¯¯
        const isRetryableError = !(
          error.message.includes('Invalid') ||
          error.message.includes('format') ||
          error.message.includes('before end date')
        )

        if (!isRetryableError) {
          logger.error(
            `âŒ Non-retryable error in getSessionWindowUsage for account ${accountId}:`,
            error.message
          )
          return this._getEmptySessionUsage()
        }

        if (retries >= maxRetries) {
          logger.error(
            `âŒ Failed to get session window usage for account ${accountId} after ${maxRetries} attempts:`,
            error.message
          )
          return this._getEmptySessionUsage()
        }

        // æŒ‡æ•°é€€é¿é‡è¯•
        const backoffDelay = Math.min(1000 * Math.pow(2, retries - 1), 5000)
        logger.warn(
          `âš ï¸ Retrying getSessionWindowUsage for account ${accountId} (attempt ${retries}/${maxRetries}) after ${backoffDelay}ms delay:`,
          error.message
        )

        await new Promise((resolve) => setTimeout(resolve, backoffDelay))
      }
    }

    // å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ
    logger.error(`âŒ All retry attempts exhausted for getSessionWindowUsage, account ${accountId}`)
    return this._getEmptySessionUsage()
  }

  /**
   * è¿”å›ç©ºçš„ä¼šè¯ä½¿ç”¨ç»Ÿè®¡å¯¹è±¡
   * @private
   * @returns {Object} ç©ºçš„ä½¿ç”¨ç»Ÿè®¡
   */
  _getEmptySessionUsage() {
    return {
      totalInputTokens: 0,
      totalOutputTokens: 0,
      totalCacheCreateTokens: 0,
      totalCacheReadTokens: 0,
      totalAllTokens: 0,
      totalRequests: 0,
      modelUsage: {},
      window: {
        start: null,
        end: null,
        durationHours: 0
      }
    }
  }

  // ==================== Claude è´¦æˆ·ç®¡ç† (6ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®Claudeè´¦æˆ·æ•°æ®ï¼ˆåŒ…å«è°ƒåº¦ç­–ç•¥å­—æ®µï¼‰
   * @param {string} accountId è´¦æˆ·ID
   * @param {Object} accountData è´¦æˆ·æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   */
  async setClaudeAccount(accountId, accountData) {
    const key = `claude:account:${accountId}`

    // ç¡®ä¿æ–°çš„è°ƒåº¦ç­–ç•¥å­—æ®µæœ‰é»˜è®¤å€¼
    const enrichedAccountData = {
      ...accountData,
      // è°ƒåº¦ç­–ç•¥å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
      schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
      schedulingWeight: accountData.schedulingWeight || '1',
      sequentialOrder: accountData.sequentialOrder || '1',
      roundRobinIndex: accountData.roundRobinIndex || '0',
      usageCount: accountData.usageCount || '0',
      lastScheduledAt: accountData.lastScheduledAt || '',
      // æ–°å¢è­¦å‘Šæ§åˆ¶å­—æ®µçš„é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
      autoStopOnWarning: accountData.autoStopOnWarning || 'false'
    }

    await this.client.hmset(key, enrichedAccountData)
  }

  /**
   * è·å–Claudeè´¦æˆ·æ•°æ®ï¼ˆç¡®ä¿è°ƒåº¦å­—æ®µé»˜è®¤å€¼ï¼‰
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<Object>} è´¦æˆ·æ•°æ®å¯¹è±¡
   */
  async getClaudeAccount(accountId) {
    const key = `claude:account:${accountId}`
    const accountData = await this.client.hgetall(key)

    if (!accountData || Object.keys(accountData).length === 0) {
      return accountData
    }

    // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
    return {
      ...accountData,
      schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
      schedulingWeight: accountData.schedulingWeight || '1',
      sequentialOrder: accountData.sequentialOrder || '1',
      roundRobinIndex: accountData.roundRobinIndex || '0',
      usageCount: accountData.usageCount || '0',
      lastScheduledAt: accountData.lastScheduledAt || '',
      // æ–°å¢è­¦å‘Šæ§åˆ¶å­—æ®µçš„é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
      autoStopOnWarning: accountData.autoStopOnWarning || 'false'
    }
  }

  /**
   * è·å–æ‰€æœ‰Claudeè´¦æˆ·ï¼ˆæ‰¹é‡é»˜è®¤å€¼å¤„ç†ï¼‰
   * @returns {Promise<Array>} Claudeè´¦æˆ·åˆ—è¡¨
   */
  async getAllClaudeAccounts() {
    const keys = await this.client.keys('claude:account:*')
    const accounts = []
    for (const key of keys) {
      const accountData = await this.client.hgetall(key)
      if (accountData && Object.keys(accountData).length > 0) {
        // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
        const enrichedAccount = {
          id: key.replace('claude:account:', ''),
          ...accountData,
          schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
          schedulingWeight: accountData.schedulingWeight || '1',
          sequentialOrder: accountData.sequentialOrder || '1',
          roundRobinIndex: accountData.roundRobinIndex || '0',
          usageCount: accountData.usageCount || '0',
          lastScheduledAt: accountData.lastScheduledAt || '',
          // æ–°å¢è­¦å‘Šæ§åˆ¶å­—æ®µçš„é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
          autoStopOnWarning: accountData.autoStopOnWarning || 'false'
        }
        accounts.push(enrichedAccount)
      }
    }
    return accounts
  }

  /**
   * è·å–æ‰€æœ‰Claude Consoleè´¦æˆ·
   * @returns {Promise<Array>} Claude Consoleè´¦æˆ·æ•°æ®æ•°ç»„
   */
  async getAllClaudeConsoleAccounts() {
    const keys = await this.client.keys('claude_console_account:*')
    const accounts = []
    for (const key of keys) {
      const accountData = await this.client.hgetall(key)
      if (accountData && Object.keys(accountData).length > 0) {
        // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
        const enrichedAccount = {
          id: key.replace('claude_console_account:', ''),
          ...accountData,
          schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
          schedulingWeight: accountData.schedulingWeight || '1',
          sequentialOrder: accountData.sequentialOrder || '1',
          roundRobinIndex: accountData.roundRobinIndex || '0',
          usageCount: accountData.usageCount || '0',
          lastScheduledAt: accountData.lastScheduledAt || '',
          // æ–°å¢è­¦å‘Šæ§åˆ¶å­—æ®µçš„é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
          autoStopOnWarning: accountData.autoStopOnWarning || 'false'
        }
        accounts.push(enrichedAccount)
      }
    }
    return accounts
  }

  /**
   * åˆ é™¤Claudeè´¦æˆ·
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteClaudeAccount(accountId) {
    const key = `claude:account:${accountId}`
    return await this.client.del(key)
  }

  /**
   * æ›´æ–°Claudeè´¦æˆ·è°ƒåº¦ç›¸å…³å­—æ®µ
   * @param {string} accountId è´¦æˆ·ID
   * @param {Object} updates æ›´æ–°çš„å­—æ®µå¯¹è±¡
   * @returns {Promise<void>}
   */
  async updateClaudeAccountSchedulingFields(accountId, updates) {
    const key = `claude:account:${accountId}`

    // ä»…æ›´æ–°è°ƒåº¦ç›¸å…³çš„å­—æ®µ
    const schedulingUpdates = {}

    if (updates.usageCount !== undefined) {
      schedulingUpdates.usageCount = updates.usageCount.toString()
    }

    if (updates.lastScheduledAt !== undefined) {
      schedulingUpdates.lastScheduledAt = updates.lastScheduledAt
    }

    if (updates.roundRobinIndex !== undefined) {
      schedulingUpdates.roundRobinIndex = updates.roundRobinIndex.toString()
    }

    if (Object.keys(schedulingUpdates).length > 0) {
      await this.client.hmset(key, schedulingUpdates)
    }
  }

  /**
   * åŸå­æ€§å¢åŠ Claudeè´¦æˆ·ä½¿ç”¨è®¡æ•°
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<number>} å¢åŠ åçš„ä½¿ç”¨è®¡æ•°
   */
  async incrementClaudeAccountUsageCount(accountId) {
    const key = `claude:account:${accountId}`
    return await this.client.hincrby(key, 'usageCount', 1)
  }

  // ==================== ä¼šè¯ç®¡ç† (12ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®ä¼šè¯æ•°æ®
   * @param {string} sessionId ä¼šè¯ID
   * @param {Object} sessionData ä¼šè¯æ•°æ®å¯¹è±¡
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤86400ç§’ï¼ˆ1å¤©ï¼‰
   * @returns {Promise<void>}
   */
  async setSession(sessionId, sessionData, ttl = 86400) {
    try {
      const key = `session:${sessionId}`
      const client = await this.getClientWithReconnect()

      logger.info(`ğŸ”§ Setting session: ${sessionId}`) // ä½¿ç”¨infoçº§åˆ«ç¡®ä¿èƒ½çœ‹åˆ°

      // ä½¿ç”¨hmsetæ–¹æ³•ï¼Œè¿™æ˜¯Rediså…¼å®¹æ€§æœ€å¥½çš„æ–¹å¼
      await client.hmset(key, sessionData)

      // åªæœ‰å½“ttlå¤§äº0æ—¶æ‰è®¾ç½®è¿‡æœŸæ—¶é—´
      if (ttl > 0) {
        await client.expire(key, ttl)
      }

      logger.info(`âœ… Session set successfully: ${sessionId}`)
    } catch (error) {
      logger.error('âŒ Failed to set session:', error)
      throw error
    }
  }

  /**
   * è·å–ä¼šè¯æ•°æ®
   * @param {string} sessionId ä¼šè¯ID
   * @returns {Promise<Object>} ä¼šè¯æ•°æ®å¯¹è±¡
   */
  async getSession(sessionId) {
    try {
      const client = await this.getClientWithReconnect()
      const key = `session:${sessionId}`
      return await client.hgetall(key)
    } catch (error) {
      logger.error('âŒ Failed to get session:', error)
      return {}
    }
  }

  /**
   * åˆ é™¤ä¼šè¯
   * @param {string} sessionId ä¼šè¯ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteSession(sessionId) {
    try {
      const key = `session:${sessionId}`
      const client = await this.getClientWithReconnect()
      return await client.del(key)
    } catch (error) {
      logger.error('âŒ Failed to delete session:', error)
      throw error
    }
  }

  /**
   * è®¾ç½®API Keyå“ˆå¸Œç´¢å¼•
   * @param {string} hashedKey å“ˆå¸Œåçš„Keyå€¼
   * @param {Object} keyData API Keyæ•°æ®
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤0è¡¨ç¤ºä¸è¿‡æœŸ
   * @returns {Promise<void>}
   */
  async setApiKeyHash(hashedKey, keyData, ttl = 0) {
    const key = `apikey_hash:${hashedKey}`
    const client = this.getClientSafe()
    await client.hmset(key, keyData)
    if (ttl > 0) {
      await client.expire(key, ttl)
    }
  }

  /**
   * è·å–API Keyå“ˆå¸Œç´¢å¼•æ•°æ®
   * @param {string} hashedKey å“ˆå¸Œåçš„Keyå€¼
   * @returns {Promise<Object>} API Keyæ•°æ®å¯¹è±¡
   */
  async getApiKeyHash(hashedKey) {
    const key = `apikey_hash:${hashedKey}`
    return await this.client.hgetall(key)
  }

  /**
   * åˆ é™¤API Keyå“ˆå¸Œç´¢å¼•
   * @param {string} hashedKey å“ˆå¸Œåçš„Keyå€¼
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteApiKeyHash(hashedKey) {
    const key = `apikey_hash:${hashedKey}`
    return await this.client.del(key)
  }

  /**
   * è®¾ç½®OAuthä¼šè¯æ•°æ®ï¼ˆåŒ…å«å¤æ‚å¯¹è±¡åºåˆ—åŒ–ï¼‰
   * @param {string} sessionId ä¼šè¯ID
   * @param {Object} sessionData ä¼šè¯æ•°æ®å¯¹è±¡
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰
   * @returns {Promise<void>}
   */
  async setOAuthSession(sessionId, sessionData, ttl = 600) {
    const key = `oauth:${sessionId}`
    const client = this.getClientSafe()

    // åºåˆ—åŒ–å¤æ‚å¯¹è±¡ï¼Œç‰¹åˆ«æ˜¯ proxy é…ç½®
    const serializedData = {}
    for (const [dataKey, value] of Object.entries(sessionData)) {
      if (typeof value === 'object' && value !== null) {
        serializedData[dataKey] = JSON.stringify(value)
      } else {
        serializedData[dataKey] = value
      }
    }

    await client.hmset(key, serializedData)
    await client.expire(key, ttl)
  }

  /**
   * è·å–OAuthä¼šè¯æ•°æ®ï¼ˆåŒ…å«å¤æ‚å¯¹è±¡ååºåˆ—åŒ–ï¼‰
   * @param {string} sessionId ä¼šè¯ID
   * @returns {Promise<Object>} OAuthä¼šè¯æ•°æ®å¯¹è±¡
   */
  async getOAuthSession(sessionId) {
    const key = `oauth:${sessionId}`
    const data = await this.client.hgetall(key)

    // ååºåˆ—åŒ– proxy å­—æ®µ
    if (data.proxy) {
      try {
        data.proxy = JSON.parse(data.proxy)
      } catch (error) {
        // å¦‚æœè§£æå¤±è´¥ï¼Œè®¾ç½®ä¸º null
        data.proxy = null
      }
    }

    return data
  }

  /**
   * åˆ é™¤OAuthä¼šè¯
   * @param {string} sessionId ä¼šè¯ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteOAuthSession(sessionId) {
    const key = `oauth:${sessionId}`
    return await this.client.del(key)
  }

  /**
   * è®¾ç½®ä¼šè¯è´¦æˆ·æ˜ å°„ï¼ˆSticky Sessionï¼‰
   * @param {string} sessionHash ä¼šè¯å“ˆå¸Œ
   * @param {string} accountId è´¦æˆ·ID
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3600ç§’ï¼ˆ1å°æ—¶ï¼‰
   * @returns {Promise<void>}
   */
  async setSessionAccountMapping(sessionHash, accountId, ttl = 3600) {
    const key = `sticky_session:${sessionHash}`
    const client = this.getClientSafe()
    await client.set(key, accountId, 'EX', ttl)
  }

  /**
   * è·å–ä¼šè¯è´¦æˆ·æ˜ å°„ï¼ˆSticky Sessionï¼‰
   * @param {string} sessionHash ä¼šè¯å“ˆå¸Œ
   * @returns {Promise<string|null>} è´¦æˆ·IDæˆ–null
   */
  async getSessionAccountMapping(sessionHash) {
    const key = `sticky_session:${sessionHash}`
    return await this.client.get(key)
  }

  /**
   * åˆ é™¤ä¼šè¯è´¦æˆ·æ˜ å°„ï¼ˆSticky Sessionï¼‰
   * @param {string} sessionHash ä¼šè¯å“ˆå¸Œ
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteSessionAccountMapping(sessionHash) {
    const key = `sticky_session:${sessionHash}`
    return await this.client.del(key)
  }

  // ==================== ç»´æŠ¤åŠŸèƒ½ (4ä¸ªæ–¹æ³•) ====================

  /**
   * ç³»ç»Ÿæ¸…ç†åŠŸèƒ½ï¼ŒåŒ…å«æ‰¹é‡é”®æŸ¥è¯¢å’ŒTTLè®¾ç½®é€»è¾‘
   * ç”¨äºæ¸…ç†è¿‡æœŸæ•°æ®ï¼Œç¡®ä¿æ•°æ®åº“å¥åº·è¿è¡Œ
   * @returns {Promise<void>}
   */
  async cleanup() {
    try {
      const patterns = ['usage:daily:*', 'ratelimit:*', 'session:*', 'sticky_session:*', 'oauth:*']

      for (const pattern of patterns) {
        const keys = await this.client.keys(pattern)
        const pipeline = this.client.pipeline()

        for (const key of keys) {
          const ttl = await this.client.ttl(key)
          if (ttl === -1) {
            // æ²¡æœ‰è®¾ç½®è¿‡æœŸæ—¶é—´çš„é”®
            if (key.startsWith('oauth:')) {
              pipeline.expire(key, 600) // OAuthä¼šè¯è®¾ç½®10åˆ†é’Ÿè¿‡æœŸ
            } else {
              pipeline.expire(key, 86400) // å…¶ä»–è®¾ç½®1å¤©è¿‡æœŸ
            }
          }
        }

        await pipeline.exec()
      }

      logger.info('ğŸ§¹ Redis cleanup completed')
    } catch (error) {
      logger.error('âŒ Redis cleanup failed:', error)
    }
  }

  /**
   * å¢åŠ å¹¶å‘è®¡æ•°ï¼ŒåŒ…å«è¿‡æœŸæ—¶é—´è®¾ç½®
   * ç”¨äºè·Ÿè¸ªAPI Keyçš„å¹¶å‘è¯·æ±‚æ•°é‡
   * @param {string} apiKeyId API Key ID
   * @returns {Promise<number>} å¢åŠ åçš„å¹¶å‘è®¡æ•°
   */
  async incrConcurrency(apiKeyId) {
    try {
      const key = `concurrency:${apiKeyId}`
      const count = await this.client.incr(key)

      // è®¾ç½®è¿‡æœŸæ—¶é—´ä¸º180ç§’ï¼ˆ3åˆ†é’Ÿï¼‰ï¼Œé˜²æ­¢è®¡æ•°å™¨æ°¸è¿œä¸æ¸…é›¶
      // æ­£å¸¸æƒ…å†µä¸‹è¯·æ±‚ä¼šåœ¨å®Œæˆæ—¶ä¸»åŠ¨å‡å°‘è®¡æ•°ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå®‰å…¨ä¿éšœ
      // 180ç§’è¶³å¤Ÿæ”¯æŒè¾ƒé•¿çš„æµå¼è¯·æ±‚
      await this.client.expire(key, 180)

      logger.database(`ğŸ”¢ Incremented concurrency for key ${apiKeyId}: ${count}`)
      return count
    } catch (error) {
      logger.error('âŒ Failed to increment concurrency:', error)
      throw error
    }
  }

  /**
   * å‡å°‘å¹¶å‘è®¡æ•°ï¼Œä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åŸå­æ€§æ“ä½œ
   * é˜²æ­¢è®¡æ•°å™¨å˜æˆè´Ÿæ•°ï¼Œç¡®ä¿å¹¶å‘è®¡æ•°çš„å‡†ç¡®æ€§
   * @param {string} apiKeyId API Key ID
   * @returns {Promise<number>} å‡å°‘åçš„å¹¶å‘è®¡æ•°
   */
  async decrConcurrency(apiKeyId) {
    try {
      const key = `concurrency:${apiKeyId}`

      // ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åŸå­æ€§æ“ä½œï¼Œé˜²æ­¢è®¡æ•°å™¨å˜æˆè´Ÿæ•°
      const luaScript = `
        local key = KEYS[1]
        local current = tonumber(redis.call('get', key) or "0")
        
        if current <= 0 then
          redis.call('del', key)
          return 0
        else
          local new_value = redis.call('decr', key)
          if new_value <= 0 then
            redis.call('del', key)
            return 0
          else
            return new_value
          end
        end
      `

      const count = await this.client.eval(luaScript, 1, key)
      logger.database(`ğŸ”¢ Decremented concurrency for key ${apiKeyId}: ${count}`)
      return count
    } catch (error) {
      logger.error('âŒ Failed to decrement concurrency:', error)
      throw error
    }
  }

  /**
   * è·å–å½“å‰å¹¶å‘æ•°
   * ç”¨äºæ£€æŸ¥API Keyçš„å½“å‰å¹¶å‘è¯·æ±‚æ•°é‡
   * @param {string} apiKeyId API Key ID
   * @returns {Promise<number>} å½“å‰å¹¶å‘æ•°
   */
  async getConcurrency(apiKeyId) {
    try {
      const key = `concurrency:${apiKeyId}`
      const count = await this.client.get(key)
      return parseInt(count || 0)
    } catch (error) {
      logger.error('âŒ Failed to get concurrency:', error)
      return 0
    }
  }

  // ==================== Gemini è´¦æˆ·ç®¡ç† (4ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–æ‰€æœ‰Geminiè´¦æˆ·
   * @returns {Promise<Array>} Geminiè´¦æˆ·æ•°ç»„
   */
  async getAllGeminiAccounts() {
    try {
      const keys = await this.client.keys('gemini:account:*')
      const accounts = []

      for (const key of keys) {
        const accountData = await this.client.hgetall(key)
        if (accountData && Object.keys(accountData).length > 0) {
          // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
          const enrichedAccount = {
            id: key.replace('gemini:account:', ''),
            ...accountData,
            schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
            schedulingWeight: accountData.schedulingWeight || '1',
            sequentialOrder: accountData.sequentialOrder || '1',
            roundRobinIndex: accountData.roundRobinIndex || '0',
            usageCount: accountData.usageCount || '0',
            lastScheduledAt: accountData.lastScheduledAt || ''
          }
          accounts.push(enrichedAccount)
        }
      }

      return accounts
    } catch (error) {
      logger.error('âŒ Failed to get all Gemini accounts:', error)
      throw error
    }
  }

  /**
   * è·å–å•ä¸ªGeminiè´¦æˆ·
   * @param {string} accountId Geminiè´¦æˆ·ID
   * @returns {Promise<Object|null>} Geminiè´¦æˆ·æ•°æ®å¯¹è±¡æˆ–null
   */
  async getGeminiAccount(accountId) {
    try {
      const key = `gemini:account:${accountId}`
      const accountData = await this.client.hgetall(key)

      if (!accountData || Object.keys(accountData).length === 0) {
        return null
      }

      // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
      return {
        id: accountId,
        ...accountData,
        schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
        schedulingWeight: accountData.schedulingWeight || '1',
        sequentialOrder: accountData.sequentialOrder || '1',
        roundRobinIndex: accountData.roundRobinIndex || '0',
        usageCount: accountData.usageCount || '0',
        lastScheduledAt: accountData.lastScheduledAt || ''
      }
    } catch (error) {
      logger.error(`âŒ Failed to get Gemini account ${accountId}:`, error)
      throw error
    }
  }

  /**
   * è®¾ç½®Geminiè´¦æˆ·æ•°æ®
   * @param {string} accountId Geminiè´¦æˆ·ID
   * @param {Object} accountData Geminiè´¦æˆ·æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} è´¦æˆ·æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setGeminiAccount(accountId, accountData) {
    try {
      const key = `gemini:account:${accountId}`
      const client = this.getClientSafe()

      // éªŒè¯è´¦æˆ·æ•°æ®
      if (
        !accountData ||
        typeof accountData !== 'object' ||
        Object.keys(accountData).length === 0
      ) {
        throw new Error('Invalid Gemini account data provided')
      }

      // ç¡®ä¿æ–°çš„è°ƒåº¦ç­–ç•¥å­—æ®µæœ‰é»˜è®¤å€¼
      const enrichedAccountData = {
        ...accountData,
        // è°ƒåº¦ç­–ç•¥å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
        schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
        schedulingWeight: accountData.schedulingWeight || '1',
        sequentialOrder: accountData.sequentialOrder || '1',
        roundRobinIndex: accountData.roundRobinIndex || '0',
        usageCount: accountData.usageCount || '0',
        lastScheduledAt: accountData.lastScheduledAt || ''
      }

      await client.hmset(key, enrichedAccountData)
      logger.info(`ğŸ¤– Gemini account ${accountId} data updated`)
    } catch (error) {
      logger.error(`âŒ Failed to set Gemini account ${accountId}:`, error)
      throw error
    }
  }

  /**
   * åˆ é™¤Geminiè´¦æˆ·
   * @param {string} accountId Geminiè´¦æˆ·ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteGeminiAccount(accountId) {
    try {
      const key = `gemini:account:${accountId}`
      const result = await this.client.del(key)
      logger.info(`ğŸ—‘ï¸ Gemini account ${accountId} deleted`)
      return result
    } catch (error) {
      logger.error(`âŒ Failed to delete Gemini account ${accountId}:`, error)
      throw error
    }
  }

  // ==================== OpenAI è´¦æˆ·ç®¡ç† (4ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®OpenAIè´¦æˆ·æ•°æ®
   * @param {string} accountId è´¦æˆ·ID
   * @param {Object} accountData è´¦æˆ·æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   */
  async setOpenAiAccount(accountId, accountData) {
    const key = `openai:account:${accountId}`

    // ç¡®ä¿æ–°çš„è°ƒåº¦ç­–ç•¥å­—æ®µæœ‰é»˜è®¤å€¼
    const enrichedAccountData = {
      ...accountData,
      // è°ƒåº¦ç­–ç•¥å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
      schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
      schedulingWeight: accountData.schedulingWeight || '1',
      sequentialOrder: accountData.sequentialOrder || '1',
      roundRobinIndex: accountData.roundRobinIndex || '0',
      usageCount: accountData.usageCount || '0',
      lastScheduledAt: accountData.lastScheduledAt || ''
    }

    await this.client.hmset(key, enrichedAccountData)
  }

  /**
   * è·å–OpenAIè´¦æˆ·æ•°æ®
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<Object>} è´¦æˆ·æ•°æ®å¯¹è±¡
   */
  async getOpenAiAccount(accountId) {
    const key = `openai:account:${accountId}`
    const accountData = await this.client.hgetall(key)

    if (!accountData || Object.keys(accountData).length === 0) {
      return accountData
    }

    // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
    return {
      ...accountData,
      schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
      schedulingWeight: accountData.schedulingWeight || '1',
      sequentialOrder: accountData.sequentialOrder || '1',
      roundRobinIndex: accountData.roundRobinIndex || '0',
      usageCount: accountData.usageCount || '0',
      lastScheduledAt: accountData.lastScheduledAt || ''
    }
  }

  /**
   * åˆ é™¤OpenAIè´¦æˆ·
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteOpenAiAccount(accountId) {
    const key = `openai:account:${accountId}`
    return await this.client.del(key)
  }

  /**
   * è·å–æ‰€æœ‰OpenAIè´¦æˆ·
   * @returns {Promise<Array>} OpenAIè´¦æˆ·åˆ—è¡¨
   */
  async getAllOpenAIAccounts() {
    const keys = await this.client.keys('openai:account:*')
    const accounts = []
    for (const key of keys) {
      const accountData = await this.client.hgetall(key)
      if (accountData && Object.keys(accountData).length > 0) {
        // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
        const enrichedAccount = {
          id: key.replace('openai:account:', ''),
          ...accountData,
          schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
          schedulingWeight: accountData.schedulingWeight || '1',
          sequentialOrder: accountData.sequentialOrder || '1',
          roundRobinIndex: accountData.roundRobinIndex || '0',
          usageCount: accountData.usageCount || '0',
          lastScheduledAt: accountData.lastScheduledAt || ''
        }
        accounts.push(enrichedAccount)
      }
    }
    return accounts
  }

  // ==================== å“ç‰Œè®¾ç½®ç®¡ç† (3ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–å“ç‰Œé…ç½®
   * @returns {Promise<Object|null>} å“ç‰Œé…ç½®å¯¹è±¡æˆ–null
   */
  async getBrandingConfig() {
    try {
      const key = 'system:branding_config'
      const brandingConfig = await this.client.hgetall(key)

      if (!brandingConfig || Object.keys(brandingConfig).length === 0) {
        return null
      }

      return brandingConfig
    } catch (error) {
      logger.error('âŒ Failed to get branding config:', error)
      throw error
    }
  }

  /**
   * è®¾ç½®å“ç‰Œé…ç½®
   * @param {Object} config å“ç‰Œé…ç½®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setBrandingConfig(brandingConfig) {
    try {
      const key = 'system:branding_config'
      const client = this.getClientSafe()

      // éªŒè¯é…ç½®æ•°æ®
      if (
        !brandingConfig ||
        typeof brandingConfig !== 'object' ||
        Object.keys(brandingConfig).length === 0
      ) {
        throw new Error('Invalid branding configuration data provided')
      }

      // ä½¿ç”¨hsetæ–¹æ³•è®¾ç½®å¤šä¸ªhashå­—æ®µ
      await client.hmset(key, brandingConfig)
      logger.info('ğŸ¨ Branding configuration updated')
    } catch (error) {
      logger.error('âŒ Failed to set branding config:', error)
      throw error
    }
  }

  /**
   * åˆ é™¤å“ç‰Œé…ç½®
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteBrandingConfig() {
    try {
      const key = 'system:branding_config'
      const result = await this.client.del(key)
      logger.info('ğŸ—‘ï¸ Branding configuration deleted')
      return result
    } catch (error) {
      logger.error('âŒ Failed to delete branding config:', error)
      throw error
    }
  }

  // ==================== é€šçŸ¥è®¾ç½®ç®¡ç† (3ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–é€šçŸ¥é…ç½®
   * @returns {Promise<Object|null>} é€šçŸ¥é…ç½®å¯¹è±¡æˆ–null
   */
  async getNotificationConfig() {
    try {
      const key = 'system:notification_config'
      const notificationConfig = await this.client.hgetall(key)

      if (!notificationConfig || Object.keys(notificationConfig).length === 0) {
        return null
      }

      return notificationConfig
    } catch (error) {
      logger.error('âŒ Failed to get notification config:', error)
      throw error
    }
  }

  /**
   * è®¾ç½®é€šçŸ¥é…ç½®
   * @param {Object} config é€šçŸ¥é…ç½®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setNotificationConfig(notificationConfig) {
    try {
      const key = 'system:notification_config'
      const client = this.getClientSafe()

      // éªŒè¯é…ç½®æ•°æ®
      if (
        !notificationConfig ||
        typeof notificationConfig !== 'object' ||
        Object.keys(notificationConfig).length === 0
      ) {
        throw new Error('Invalid notification configuration data provided')
      }

      // ä½¿ç”¨hsetæ–¹æ³•è®¾ç½®å¤šä¸ªhashå­—æ®µ
      await client.hmset(key, notificationConfig)
      logger.info('ğŸ”” Notification configuration updated')
    } catch (error) {
      logger.error('âŒ Failed to set notification config:', error)
      throw error
    }
  }

  /**
   * åˆ é™¤é€šçŸ¥é…ç½®
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteNotificationConfig() {
    try {
      const key = 'system:notification_config'
      const result = await this.client.del(key)
      logger.info('ğŸ—‘ï¸ Notification configuration deleted')
      return result
    } catch (error) {
      logger.error('âŒ Failed to delete notification config:', error)
      throw error
    }
  }

  // ==================== é…ç½®ç®¡ç† (3ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®ç³»ç»Ÿè°ƒåº¦é…ç½®
   * @param {Object} configData é…ç½®æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setSystemSchedulingConfig(configData) {
    const key = 'system:scheduling_config'
    const client = this.getClientSafe()

    // éªŒè¯é…ç½®æ•°æ®
    if (!configData || typeof configData !== 'object' || Object.keys(configData).length === 0) {
      throw new Error('Invalid configuration data provided')
    }

    // ä½¿ç”¨hsetæ–¹æ³•è®¾ç½®å¤šä¸ªhashå­—æ®µ
    await client.hmset(key, configData)
    logger.info('ğŸ“ System scheduling configuration updated')
  }

  /**
   * è·å–ç³»ç»Ÿè°ƒåº¦é…ç½®ï¼ˆåŒ…å«é»˜è®¤é…ç½®å›é€€é€»è¾‘ï¼‰
   * @returns {Promise<Object>} ç³»ç»Ÿè°ƒåº¦é…ç½®å¯¹è±¡
   */
  async getSystemSchedulingConfig() {
    const key = 'system:scheduling_config'
    const schedulingConfig = await this.client.hgetall(key)

    // è¿”å›é»˜è®¤é…ç½®å¦‚æœæ²¡æœ‰å­˜å‚¨çš„é…ç½®
    if (!schedulingConfig || Object.keys(schedulingConfig).length === 0) {
      const defaultConfig = {
        defaultStrategy: 'least_recent',
        enableAccountOverride: 'true',
        enableGroupOverride: 'true'
      }

      // ä¿å­˜é»˜è®¤é…ç½®åˆ°Redis
      await this.setSystemSchedulingConfig(defaultConfig)
      return defaultConfig
    }

    return schedulingConfig
  }

  /**
   * åˆ é™¤ç³»ç»Ÿè°ƒåº¦é…ç½®
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteSystemSchedulingConfig() {
    const key = 'system:scheduling_config'
    return await this.client.del(key)
  }

  // ==================== ç®¡ç†å‘˜ä¿¡æ¯ç®¡ç† (4ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–æ‰€æœ‰ç®¡ç†å‘˜ä¿¡æ¯
   * @returns {Promise<Array>} ç®¡ç†å‘˜ä¿¡æ¯æ•°ç»„
   */
  async getAllAdmins() {
    try {
      const keys = await this.client.keys('admin:*')
      const admins = []

      for (const key of keys) {
        // è¿‡æ»¤æ‰ç”¨æˆ·åæ˜ å°„é”®ï¼Œåªå¤„ç†å®é™…çš„ç®¡ç†å‘˜æ•°æ®
        if (key.startsWith('admin_username:')) {
          continue
        }

        const adminData = await this.client.hgetall(key)
        if (adminData && Object.keys(adminData).length > 0) {
          const adminId = key.replace('admin:', '')
          admins.push({
            id: adminId,
            ...adminData
          })
        }
      }

      return admins
    } catch (error) {
      logger.error('âŒ Failed to get all admins:', error)
      throw error
    }
  }

  /**
   * æ ¹æ®IDè·å–ç®¡ç†å‘˜ä¿¡æ¯
   * @param {string} adminId ç®¡ç†å‘˜ID
   * @returns {Promise<Object|null>} ç®¡ç†å‘˜ä¿¡æ¯å¯¹è±¡æˆ–null
   */
  async getAdminById(adminId) {
    try {
      const key = `admin:${adminId}`
      const adminData = await this.client.hgetall(key)

      if (!adminData || Object.keys(adminData).length === 0) {
        return null
      }

      return {
        id: adminId,
        ...adminData
      }
    } catch (error) {
      logger.error(`âŒ Failed to get admin by ID ${adminId}:`, error)
      throw error
    }
  }

  /**
   * è®¾ç½®ç®¡ç†å‘˜æ•°æ®
   * @param {string} adminId ç®¡ç†å‘˜ID
   * @param {Object} adminData ç®¡ç†å‘˜æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} ç®¡ç†å‘˜æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setAdmin(adminId, adminData) {
    try {
      const key = `admin:${adminId}`
      const client = this.getClientSafe()

      // éªŒè¯ç®¡ç†å‘˜æ•°æ®
      if (!adminData || typeof adminData !== 'object' || Object.keys(adminData).length === 0) {
        throw new Error('Invalid admin data provided')
      }

      // è®¾ç½®ç®¡ç†å‘˜æ•°æ®
      await client.hmset(key, adminData)

      // ç»´æŠ¤ç”¨æˆ·åæ˜ å°„ï¼ˆå¦‚æœæä¾›äº†ç”¨æˆ·åï¼‰
      if (adminData.username) {
        const usernameMapKey = `admin_username:${adminData.username}`
        await client.set(usernameMapKey, adminId)
      }

      logger.info(`ğŸ‘¤ Admin ${adminId} data updated`)
    } catch (error) {
      logger.error(`âŒ Failed to set admin ${adminId}:`, error)
      throw error
    }
  }

  /**
   * åˆ é™¤ç®¡ç†å‘˜
   * @param {string} adminId ç®¡ç†å‘˜ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteAdmin(adminId) {
    try {
      const key = `admin:${adminId}`

      // è·å–ç®¡ç†å‘˜æ•°æ®ä»¥ä¾¿æ¸…ç†ç”¨æˆ·åæ˜ å°„
      const adminData = await this.client.hgetall(key)

      // åˆ é™¤ç®¡ç†å‘˜æ•°æ®
      const result = await this.client.del(key)

      // æ¸…ç†ç”¨æˆ·åæ˜ å°„
      if (adminData && adminData.username) {
        const usernameMapKey = `admin_username:${adminData.username}`
        await this.client.del(usernameMapKey)
      }

      logger.info(`ğŸ—‘ï¸ Admin ${adminId} deleted`)
      return result
    } catch (error) {
      logger.error(`âŒ Failed to delete admin ${adminId}:`, error)
      throw error
    }
  }

  // ==================== 2FAé…ç½®ç®¡ç† (3ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–æŒ‡å®šç”¨æˆ·åçš„2FAé…ç½®
   * @param {string} username ç”¨æˆ·å
   * @returns {Promise<Object|null>} 2FAé…ç½®å¯¹è±¡æˆ–null
   */
  async getTwoFactorConfig(username) {
    try {
      const key = `2fa:config:${username}`
      const twoFactorConfig = await this.client.hgetall(key)

      if (!twoFactorConfig || Object.keys(twoFactorConfig).length === 0) {
        return null
      }

      return {
        username,
        ...twoFactorConfig
      }
    } catch (error) {
      logger.error(`âŒ Failed to get 2FA config for ${username}:`, error)
      throw error
    }
  }

  /**
   * è®¾ç½®æŒ‡å®šç”¨æˆ·åçš„2FAé…ç½®
   * @param {string} username ç”¨æˆ·å
   * @param {Object} config 2FAé…ç½®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setTwoFactorConfig(username, twoFactorConfig) {
    try {
      const key = `2fa:config:${username}`
      const client = this.getClientSafe()

      // éªŒè¯é…ç½®æ•°æ®
      if (
        !twoFactorConfig ||
        typeof twoFactorConfig !== 'object' ||
        Object.keys(twoFactorConfig).length === 0
      ) {
        throw new Error('Invalid 2FA configuration data provided')
      }

      // éªŒè¯ç”¨æˆ·å
      if (!username || typeof username !== 'string' || username.trim().length === 0) {
        throw new Error('Invalid username provided')
      }

      // è®¾ç½®2FAé…ç½®ï¼ŒåŒ…å«å®‰å…¨æ•æ„Ÿä¿¡æ¯çš„å¤„ç†
      const configToStore = {
        ...twoFactorConfig,
        createdAt: twoFactorConfig.createdAt || new Date().toISOString(),
        updatedAt: new Date().toISOString()
      }

      await client.hmset(key, configToStore)
      logger.info(`ğŸ” 2FA configuration updated for user: ${username}`)
    } catch (error) {
      logger.error(`âŒ Failed to set 2FA config for ${username}:`, error)
      throw error
    }
  }

  /**
   * è·å–æ‰€æœ‰2FAé…ç½®
   * @returns {Promise<Array>} æ‰€æœ‰2FAé…ç½®æ•°ç»„
   */
  async getAllTwoFactorConfigs() {
    try {
      const keys = await this.client.keys('2fa:config:*')
      const configs = []

      for (const key of keys) {
        const configData = await this.client.hgetall(key)
        if (configData && Object.keys(configData).length > 0) {
          const username = key.replace('2fa:config:', '')
          configs.push({
            username,
            ...configData
          })
        }
      }

      return configs
    } catch (error) {
      logger.error('âŒ Failed to get all 2FA configs:', error)
      throw error
    }
  }

  /**
   * è®°å½•è¯·æ±‚æ—¥å¿—åˆ°Redisï¼ˆå¢å¼ºç‰ˆæœ¬ - æ”¯æŒHeadersã€è¯¦ç»†ä¿¡æ¯å’Œæ™ºèƒ½åˆå¹¶ï¼‰
   * @param {string} keyId API Key ID
   * @param {Object} logData æ—¥å¿—æ•°æ®å¯¹è±¡
   * @param {Object} logData.requestHeaders è¿‡æ»¤åçš„è¯·æ±‚å¤´ä¿¡æ¯
   * @param {Object} logData.responseHeaders å“åº”å¤´ä¿¡æ¯
   * @param {Object} logData.tokenDetails è¯¦ç»†çš„Tokenç»Ÿè®¡ä¿¡æ¯
   * @param {Object} logData.costDetails è´¹ç”¨è¯¦ç»†ä¿¡æ¯
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤604800ç§’ï¼ˆ7å¤©ï¼‰
   * @param {Object} mergeOptions æ—¥å¿—åˆå¹¶é…ç½®é€‰é¡¹
   * @param {boolean} mergeOptions.enabled æ˜¯å¦å¯ç”¨åˆå¹¶åŠŸèƒ½ï¼Œé»˜è®¤false
   * @param {number} mergeOptions.windowMs åˆå¹¶æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤15000ï¼ˆ15ç§’ï¼‰
   * @param {string} mergeOptions.priority æ—¥å¿—ä¼˜å…ˆçº§ï¼ˆenhanced|basic|unknownï¼‰ï¼Œé»˜è®¤'unknown'
   * @param {boolean} mergeOptions.forceWrite æ˜¯å¦å¼ºåˆ¶å†™å…¥ï¼ˆå¿½ç•¥åˆå¹¶ï¼‰ï¼Œé»˜è®¤false
   * @param {Function} mergeOptions.onDuplicate å¤„ç†é‡å¤æ—¥å¿—çš„å›è°ƒå‡½æ•°
   * @returns {Promise<string>} æ—¥å¿—å”¯ä¸€ID
   */
  async logRequest(keyId, logData, ttl = 604800, mergeOptions = {}) {
    try {
      const now = new Date()
      const today = getDateStringInTimezone(now)
      const timestamp = now.getTime()
      const logId = `request_log:${keyId}:${timestamp}`

      // è®¾ç½®åˆå¹¶é€‰é¡¹çš„é»˜è®¤å€¼
      const mergeConfig = {
        enabled: mergeOptions.enabled || false,
        windowMs: mergeOptions.windowMs || 15000, // 15ç§’æ—¶é—´çª—å£
        priority: mergeOptions.priority || 'unknown',
        forceWrite: mergeOptions.forceWrite || false,
        onDuplicate: mergeOptions.onDuplicate || null,
        ...mergeOptions
      }

      const defaultData = {
        timestamp,
        keyId,
        path: '',
        method: '',
        status: 0,
        model: '',
        tokens: 0,
        responseTime: 0,
        error: null,
        // æ–°å¢å­—æ®µ
        requestHeaders: null,
        responseHeaders: null,
        tokenDetails: null,
        costDetails: null,
        // åˆå¹¶ç›¸å…³å­—æ®µ
        logVersion: '2.1',
        priority: mergeConfig.priority,
        mergeCount: 0,
        originalTimestamp: timestamp,
        isDuplicate: false
      }

      const finalLogData = { ...defaultData, ...logData }

      // æ™ºèƒ½åˆå¹¶é€»è¾‘ - å¦‚æœå¯ç”¨åˆå¹¶åŠŸèƒ½ä¸”ä¸å¼ºåˆ¶å†™å…¥
      if (mergeConfig.enabled && !mergeConfig.forceWrite) {
        logger.debug(`ğŸ”„ æ£€æŸ¥é‡å¤æ—¥å¿—ï¼ŒkeyId: ${keyId}, æ—¶é—´çª—å£: ${mergeConfig.windowMs}ms`)

        try {
          // æ£€æµ‹é‡å¤æ—¥å¿—
          const duplicates = await this.detectDuplicateLogs(
            keyId,
            finalLogData,
            mergeConfig.windowMs
          )

          if (duplicates.length > 0) {
            logger.debug(`ğŸ” å‘ç° ${duplicates.length} ä¸ªé‡å¤æ—¥å¿—å€™é€‰é¡¹`)

            // æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„é‡å¤æ—¥å¿—
            const bestMatch = duplicates.reduce((best, current) =>
              current.similarity > best.similarity ? current : best
            )

            // å¦‚æœç›¸ä¼¼åº¦è¶³å¤Ÿé«˜ï¼Œåˆ™æ‰§è¡Œåˆå¹¶
            if (bestMatch.similarity > 0.8) {
              // 80%ç›¸ä¼¼åº¦é˜ˆå€¼
              logger.info(
                `ğŸš€ åˆå¹¶æ—¥å¿—: ${logId} -> ${bestMatch.logId} (ç›¸ä¼¼åº¦: ${(bestMatch.similarity * 100).toFixed(1)}%)`
              )

              // æ‰§è¡Œåˆå¹¶æ“ä½œ
              const mergeResult = await this.mergeLogEntries(bestMatch.logId, [logId], {
                priority: mergeConfig.priority === 'enhanced' ? 'higher' : 'lower',
                preserveHeaders: true,
                aggregateTokens: true
              })

              // è°ƒç”¨é‡å¤å¤„ç†å›è°ƒ
              if (mergeConfig.onDuplicate && typeof mergeConfig.onDuplicate === 'function') {
                try {
                  await mergeConfig.onDuplicate({
                    originalLogId: bestMatch.logId,
                    duplicateLogId: logId,
                    similarity: bestMatch.similarity,
                    mergeResult
                  })
                } catch (callbackError) {
                  logger.warn('âš ï¸ é‡å¤æ—¥å¿—å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥:', callbackError.message)
                }
              }

              return mergeResult.mergedLogId
            }
          }
        } catch (mergeError) {
          logger.warn('âš ï¸ æ—¥å¿—åˆå¹¶æ£€æµ‹å¤±è´¥ï¼Œç»§ç»­æ­£å¸¸å†™å…¥:', mergeError.message)
          // åˆå¹¶å¤±è´¥æ—¶ç»§ç»­æ­£å¸¸å†™å…¥ï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½
        }
      }

      // æ­£å¸¸å†™å…¥é€»è¾‘ï¼ˆå¦‚æœæ²¡æœ‰åˆå¹¶æˆ–åˆå¹¶å¤±è´¥ï¼‰

      // å¤„ç†å¤æ‚å¯¹è±¡å­—æ®µ - åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²ä»¥æ”¯æŒRediså­˜å‚¨
      if (finalLogData.requestHeaders && typeof finalLogData.requestHeaders === 'object') {
        finalLogData.requestHeaders = JSON.stringify(finalLogData.requestHeaders)
      }

      if (finalLogData.responseHeaders && typeof finalLogData.responseHeaders === 'object') {
        finalLogData.responseHeaders = JSON.stringify(finalLogData.responseHeaders)
      }

      if (finalLogData.tokenDetails && typeof finalLogData.tokenDetails === 'object') {
        finalLogData.tokenDetails = JSON.stringify(finalLogData.tokenDetails)
      }

      if (finalLogData.costDetails && typeof finalLogData.costDetails === 'object') {
        finalLogData.costDetails = JSON.stringify(finalLogData.costDetails)
      }

      const client = this.getClientSafe()

      // ä½¿ç”¨Pipelineæ‰¹é‡æ“ä½œæå‡æ€§èƒ½
      const pipeline = client.pipeline()

      // 1. å­˜å‚¨æ—¥å¿—æ•°æ®
      pipeline.hmset(logId, finalLogData)
      pipeline.expire(logId, ttl)

      // 2. å»ºç«‹å¤šç»´åº¦ç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢
      const dailyIndex = `request_log_index:${keyId}:${today}`
      pipeline.sadd(dailyIndex, logId)
      pipeline.expire(dailyIndex, ttl)

      // 3. æŒ‰çŠ¶æ€ç ç´¢å¼•ï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾é”™è¯¯æ—¥å¿—ï¼‰
      if (finalLogData.status) {
        const statusIndex = `request_log_status:${finalLogData.status}:${today}`
        pipeline.sadd(statusIndex, logId)
        pipeline.expire(statusIndex, ttl)
      }

      // 4. æŒ‰æ¨¡å‹ç´¢å¼•ï¼ˆç”¨äºæ¨¡å‹ä½¿ç”¨ç»Ÿè®¡ï¼‰
      if (finalLogData.model) {
        const modelIndex = `request_log_model:${finalLogData.model}:${today}`
        pipeline.sadd(modelIndex, logId)
        pipeline.expire(modelIndex, ttl)
      }

      // 5. å…¨å±€æ—¶é—´ç´¢å¼•ï¼ˆç”¨äºæ—¶é—´èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–ï¼‰
      const hourKey = `request_log_time:${Math.floor(timestamp / 3600000)}`
      pipeline.sadd(hourKey, logId)
      pipeline.expire(hourKey, ttl)

      // 6. é”™è¯¯æ—¥å¿—ç‰¹æ®Šç´¢å¼•
      if (finalLogData.error && finalLogData.error !== 'null') {
        const errorIndex = `request_log_errors:${today}`
        pipeline.sadd(errorIndex, logId)
        pipeline.expire(errorIndex, ttl)
      }

      await pipeline.exec()

      return logId
    } catch (error) {
      logger.error('Failed to log request:', error)
      throw error
    }
  }

  /**
   * æœç´¢è¯·æ±‚æ—¥å¿—ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @param {Object} options æŸ¥è¯¢é€‰é¡¹ï¼ˆåˆ†é¡µã€æ’åºç­‰ï¼‰
   * @param {boolean} options.includeEnhancedStats æ˜¯å¦åŒ…å«å¢å¼ºçš„ç»Ÿè®¡ä¿¡æ¯
   * @returns {Promise<Array>} æ—¥å¿—æ•°ç»„
   */
  async searchLogs(query = {}, options = {}) {
    const { offset = 0, limit = 20, sortOrder = 'desc', includeEnhancedStats = false } = options
    const startTime = Date.now()

    try {
      const client = this.getClientSafe()
      let matchingLogs = []

      // è®°å½•æœç´¢å‚æ•°
      if (query.search) {
        logger.debug(`æ‰§è¡Œæ–‡æœ¬æœç´¢: "${query.search}", é™åˆ¶: ${limit}, åç§»: ${offset}`)
      }

      // ä¼˜åŒ–ç­–ç•¥ï¼šåŸºäºæŸ¥è¯¢æ¡ä»¶é€‰æ‹©æœ€ä½³æœç´¢æ–¹æ³•
      if (query.status && query.dateRange) {
        // ä¼˜å…ˆä½¿ç”¨çŠ¶æ€ç ç´¢å¼•
        matchingLogs = await this._searchLogsByStatusAndDate(client, query.status, query.dateRange)
      } else if (query.model && query.dateRange) {
        // ä½¿ç”¨æ¨¡å‹ç´¢å¼•
        matchingLogs = await this._searchLogsByModelAndDate(client, query.model, query.dateRange)
      } else if (query.hasError && query.dateRange) {
        // ä½¿ç”¨é”™è¯¯ç´¢å¼•
        matchingLogs = await this._searchErrorLogsByDate(client, query.dateRange)
      } else if (query.keyId && query.dateRange) {
        // å¦‚æœæœ‰ keyId å’Œæ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨æ—¥å¿—ç´¢å¼•
        matchingLogs = await this._searchLogsByKeyIdAndDate(client, query.keyId, query.dateRange)
      } else if (query.keyId) {
        // å¦‚æœåªæœ‰ keyIdï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„æ¨¡å¼åŒ¹é…
        const pattern = `request_log:${query.keyId}:*`
        matchingLogs = await client.keys(pattern)
      } else if (query.dateRange) {
        // å¦‚æœåªæœ‰æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨æ—¥å¿—ç´¢å¼•
        matchingLogs = await this._searchLogsByDateRange(client, query.dateRange)
      } else if (query.status) {
        // ä»…çŠ¶æ€ç æŸ¥è¯¢ï¼Œä½¿ç”¨ä»Šæ—¥çŠ¶æ€ç ç´¢å¼•
        const today = getDateStringInTimezone()
        const statusIndex = `request_log_status:${query.status}:${today}`
        try {
          matchingLogs = await client.smembers(statusIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else if (query.model) {
        // ä»…æ¨¡å‹æŸ¥è¯¢ï¼Œä½¿ç”¨ä»Šæ—¥æ¨¡å‹ç´¢å¼•
        const today = getDateStringInTimezone()
        const modelIndex = `request_log_model:${query.model}:${today}`
        try {
          matchingLogs = await client.smembers(modelIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else {
        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å®é™…å­˜åœ¨çš„é”®æ¨¡å¼è¿›è¡Œå…¨é‡æœç´¢
        logger.info('ğŸ” DEBUGGING: Performing full scan for request logs')

        // æœç´¢æ‰€æœ‰è¯·æ±‚æ—¥å¿—ç›¸å…³çš„é”®æ¨¡å¼
        const [indexKeys, statusKeys, modelKeys, errorKeys, timeKeys] = await Promise.all([
          client.keys('request_log_index:*'),
          client.keys('request_log_status:*'),
          client.keys('request_log_model:*'),
          client.keys('request_log_errors:*'),
          client.keys('request_log_time:*')
        ])

        // åˆå¹¶æ‰€æœ‰ç´¢å¼•é”®ï¼Œä»ä¸­æå–ä¸»æ—¥å¿—é”®
        const allIndexKeys = [...indexKeys, ...statusKeys, ...modelKeys, ...errorKeys, ...timeKeys]
        logger.info('ğŸ” DEBUGGING: Found index keys:', {
          indexKeys: indexKeys.length,
          statusKeys: statusKeys.length,
          modelKeys: modelKeys.length,
          errorKeys: errorKeys.length,
          timeKeys: timeKeys.length,
          totalIndexKeys: allIndexKeys.length
        })

        // ä»ç´¢å¼•é”®ä¸­æå–å®é™…çš„æ—¥å¿—é”®
        const extractedLogKeys = new Set()
        for (const indexKey of allIndexKeys) {
          try {
            // å¯¹äºé›†åˆç´¢å¼•ï¼Œè·å–æˆå‘˜
            if (
              indexKey.includes('request_log_index:') ||
              indexKey.includes('request_log_status:') ||
              indexKey.includes('request_log_model:') ||
              indexKey.includes('request_log_errors:')
            ) {
              const members = await client.smembers(indexKey)
              members.forEach((member) => extractedLogKeys.add(member))
            }
            // å¯¹äºæ—¶é—´ç´¢å¼•ï¼Œè·å–æˆå‘˜
            else if (indexKey.includes('request_log_time:')) {
              const members = await client.smembers(indexKey)
              members.forEach((member) => extractedLogKeys.add(member))
            }
          } catch (error) {
            logger.debug(`Failed to extract from index ${indexKey}:`, error.message)
          }
        }

        matchingLogs = Array.from(extractedLogKeys)
        logger.info('ğŸ” DEBUGGING: Extracted log keys:', {
          extractedCount: matchingLogs.length,
          sampleKeys: matchingLogs.slice(0, 5)
        })

        // æŒ‰æ—¶é—´æˆ³æ’åºå¹¶æˆªå–æœ€è¿‘çš„è®°å½•
        matchingLogs = matchingLogs
          .filter((key) => key && key.includes(':')) // ç¡®ä¿é”®æ ¼å¼æ­£ç¡®
          .sort((a, b) => {
            const timestampA = parseInt(a.split(':')[2]) || 0
            const timestampB = parseInt(b.split(':')[2]) || 0
            return sortOrder === 'desc' ? timestampB - timestampA : timestampA - timestampB
          })
          .slice(0, Math.min(1000, offset + limit * 5)) // é™åˆ¶æœ€å¤§æ‰«æé‡
      }

      // é™åˆ¶æ–‡æœ¬æœç´¢çš„æ‰«æèŒƒå›´ï¼Œé¿å…æ€§èƒ½é—®é¢˜
      if (query.search && matchingLogs.length > 2000) {
        logger.warn(`æ–‡æœ¬æœç´¢çš„ç»“æœé›†è¿‡å¤§ (${matchingLogs.length})ï¼Œé™åˆ¶åˆ° 2000 æ¡`)
        matchingLogs = matchingLogs.slice(0, 2000)
      }

      // åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
      if (Object.keys(query).length > 0) {
        matchingLogs = await this._filterLogsByQuery(client, matchingLogs, query)
      }

      // æ’åºï¼ˆå¦‚æœè¿˜æœªæ’åºï¼‰
      if (!query.keyId || Object.keys(query).length > 1) {
        matchingLogs.sort((a, b) => {
          const timestampA = parseInt(a.split(':')[2]) || 0
          const timestampB = parseInt(b.split(':')[2]) || 0
          return sortOrder === 'desc' ? timestampB - timestampA : timestampA - timestampB
        })
      }

      // åˆ†é¡µ
      const paginatedLogs = matchingLogs.slice(offset, offset + limit)
      logger.info('ğŸ” DEBUGGING: About to fetch log data:', {
        totalMatching: matchingLogs.length,
        paginatedCount: paginatedLogs.length,
        samplePaginatedKeys: paginatedLogs.slice(0, 3)
      })

      // æ‰¹é‡è·å–æ—¥å¿—è¯¦æƒ…
      const pipeline = client.pipeline()
      paginatedLogs.forEach((logKey) => pipeline.hgetall(logKey))

      const results = await pipeline.exec()
      logger.info('ğŸ” DEBUGGING: Pipeline results:', {
        resultsCount: results.length,
        sampleResults: results.slice(0, 2).map(([err, data]) => ({
          error: err?.message,
          dataKeys: data ? Object.keys(data) : null,
          hasData: data && Object.keys(data).length > 0
        }))
      })

      const logs = results
        .map(([err, logData], index) => {
          if (err || !logData || Object.keys(logData).length === 0) {
            return null
          }

          // ååºåˆ—åŒ–JSONå­—ç¬¦ä¸²å­—æ®µ
          const processedLogData = { ...logData }

          // é€šç”¨çš„JSONååºåˆ—åŒ–å‡½æ•°
          const safeJSONParse = (fieldName, value) => {
            if (!value || typeof value !== 'string') {
              return null
            }

            try {
              return JSON.parse(value)
            } catch (e) {
              logger.debug(
                `Failed to parse ${fieldName} for log ${paginatedLogs[index]}:`,
                e.message
              )
              return null
            }
          }

          // æ•°æ®è§£å‹ç¼©å’Œååºåˆ—åŒ–
          const jsonFields = ['requestHeaders', 'responseHeaders', 'tokenDetails', 'costDetails']
          jsonFields.forEach((field) => {
            if (processedLogData[field]) {
              processedLogData[field] = safeJSONParse(field, processedLogData[field])
            }
          })

          // æ•°å€¼ç±»å‹è½¬æ¢
          const numericFields = {
            timestamp: 'int',
            duration: 'int',
            responseTime: 'float',
            inputTokens: 'int',
            outputTokens: 'int',
            totalTokens: 'int',
            cost: 'float',
            status: 'int',
            tokens: 'int'
          }

          Object.entries(numericFields).forEach(([field, type]) => {
            if (processedLogData[field] !== undefined && processedLogData[field] !== '') {
              if (type === 'int') {
                processedLogData[field] = parseInt(processedLogData[field]) || 0
              } else if (type === 'float') {
                processedLogData[field] = parseFloat(processedLogData[field]) || 0
              }
            }
          })

          // è®¡ç®—å¢å¼ºç»Ÿè®¡ä¿¡æ¯
          const enhancedLog = {
            ...processedLogData,
            logId: paginatedLogs[index],
            timestamp: processedLogData.timestamp
          }

          // æ·»åŠ tokenSummaryï¼ˆæ€»æ˜¯åŒ…å«ï¼‰
          enhancedLog.tokenSummary = {
            totalTokens: enhancedLog.totalTokens || enhancedLog.tokens || 0,
            inputTokens: enhancedLog.inputTokens || 0,
            outputTokens: enhancedLog.outputTokens || 0,
            cost: enhancedLog.cost || 0
          }

          // æ·»åŠ æ ‡å¿—ä¿¡æ¯ï¼ˆæ€»æ˜¯åŒ…å«ï¼‰
          enhancedLog.hasHeaders = !!(
            (enhancedLog.requestHeaders &&
              Object.keys(enhancedLog.requestHeaders || {}).length > 0) ||
            (enhancedLog.responseHeaders &&
              Object.keys(enhancedLog.responseHeaders || {}).length > 0)
          )

          enhancedLog.hasBody = !!(
            (enhancedLog.requestBody && enhancedLog.requestBody.trim().length > 0) ||
            (enhancedLog.responseBody && enhancedLog.responseBody.trim().length > 0)
          )

          enhancedLog.isError = (enhancedLog.status || 0) >= 400
          enhancedLog.dateTime = enhancedLog.timestamp
            ? new Date(enhancedLog.timestamp).toISOString()
            : null

          // å¦‚æœå¯ç”¨äº†å¢å¼ºç»Ÿè®¡ï¼Œæ·»åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯
          if (includeEnhancedStats) {
            enhancedLog.metadata = {
              hasRequestHeaders: !!(
                enhancedLog.requestHeaders && Object.keys(enhancedLog.requestHeaders).length > 0
              ),
              hasResponseHeaders: !!(
                enhancedLog.responseHeaders && Object.keys(enhancedLog.responseHeaders).length > 0
              ),
              hasTokenDetails: !!(
                enhancedLog.tokenDetails && Object.keys(enhancedLog.tokenDetails || {}).length > 0
              ),
              hasCostDetails: !!(
                enhancedLog.costDetails && Object.keys(enhancedLog.costDetails || {}).length > 0
              ),
              processedAt: new Date().toISOString()
            }
          }

          return enhancedLog
        })
        .filter(Boolean)

      logger.info('ğŸ” DEBUGGING: Final processed logs:', {
        processedCount: logs.length,
        includeEnhancedStats,
        sampleLogData: logs.slice(0, 2).map((log) => ({
          logId: log.logId,
          keyId: log.keyId,
          timestamp: log.timestamp,
          hasHeaders: log.hasHeaders,
          hasBody: log.hasBody,
          tokenSummary: log.tokenSummary,
          fieldsCount: Object.keys(log).length
        }))
      })

      const endTime = Date.now()
      const searchTime = endTime - startTime

      // è®°å½•æœç´¢ç»“æœå’Œæ€§èƒ½
      if (query.search) {
        logger.debug(`æ–‡æœ¬æœç´¢å®Œæˆ: è€—æ—¶ ${searchTime}ms, æ‰¾åˆ° ${logs.length} æ¡ç»“æœ`)
      }

      return logs
    } catch (error) {
      logger.error('Failed to search logs:', error)
      return []
    }
  }

  /**
   * ç»Ÿè®¡æ—¥å¿—æ•°é‡ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @returns {Promise<number>} åŒ¹é…çš„æ—¥å¿—æ•°é‡
   */
  async countLogs(query = {}) {
    try {
      const client = this.getClientSafe()
      let matchingLogs = []

      // ä½¿ç”¨ä¸ searchLogs ç›¸åŒçš„ä¼˜åŒ–ç­–ç•¥
      if (query.status && query.dateRange) {
        matchingLogs = await this._searchLogsByStatusAndDate(client, query.status, query.dateRange)
      } else if (query.model && query.dateRange) {
        matchingLogs = await this._searchLogsByModelAndDate(client, query.model, query.dateRange)
      } else if (query.hasError && query.dateRange) {
        matchingLogs = await this._searchErrorLogsByDate(client, query.dateRange)
      } else if (query.keyId && query.dateRange) {
        matchingLogs = await this._searchLogsByKeyIdAndDate(client, query.keyId, query.dateRange)
      } else if (query.keyId) {
        const pattern = `request_log:${query.keyId}:*`
        matchingLogs = await client.keys(pattern)
      } else if (query.dateRange) {
        matchingLogs = await this._searchLogsByDateRange(client, query.dateRange)
      } else if (query.status) {
        const today = getDateStringInTimezone()
        const statusIndex = `request_log_status:${query.status}:${today}`
        try {
          matchingLogs = await client.smembers(statusIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else if (query.model) {
        const today = getDateStringInTimezone()
        const modelIndex = `request_log_model:${query.model}:${today}`
        try {
          matchingLogs = await client.smembers(modelIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else {
        // å…¨é‡æ‰«ææ—¶ï¼Œå¯ä»¥ç›´æ¥è¿”å›é”®æ•°é‡è€Œä¸éœ€è¦è·å–å†…å®¹
        matchingLogs = await client.keys('request_log:*')
      }

      // åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
      if (Object.keys(query).length > 0 && !(query.keyId && Object.keys(query).length === 1)) {
        matchingLogs = await this._filterLogsByQuery(client, matchingLogs, query)
      }

      return matchingLogs.length
    } catch (error) {
      logger.error('Failed to count logs:', error)
      return 0
    }
  }

  /**
   * èšåˆæ—¥å¿—ç»Ÿè®¡
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @returns {Promise<Object>} èšåˆç»Ÿè®¡ç»“æœ
   */
  async aggregateLogs(query = {}) {
    try {
      const client = this.getClientSafe()
      let matchingLogs = []

      // ä½¿ç”¨ä¸ searchLogs ç›¸åŒçš„ä¼˜åŒ–ç­–ç•¥
      if (query.status && query.dateRange) {
        matchingLogs = await this._searchLogsByStatusAndDate(client, query.status, query.dateRange)
      } else if (query.model && query.dateRange) {
        matchingLogs = await this._searchLogsByModelAndDate(client, query.model, query.dateRange)
      } else if (query.hasError && query.dateRange) {
        matchingLogs = await this._searchErrorLogsByDate(client, query.dateRange)
      } else if (query.keyId && query.dateRange) {
        matchingLogs = await this._searchLogsByKeyIdAndDate(client, query.keyId, query.dateRange)
      } else if (query.keyId) {
        const pattern = `request_log:${query.keyId}:*`
        matchingLogs = await client.keys(pattern)
      } else if (query.dateRange) {
        matchingLogs = await this._searchLogsByDateRange(client, query.dateRange)
      } else {
        matchingLogs = await client.keys('request_log:*')
      }

      // åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
      if (Object.keys(query).length > 0) {
        matchingLogs = await this._filterLogsByQuery(client, matchingLogs, query)
      }

      const pipeline = client.pipeline()
      matchingLogs.forEach((logKey) => pipeline.hgetall(logKey))

      const results = await pipeline.exec()

      const stats = {
        totalRequests: 0,
        totalTokens: 0,
        totalResponseTime: 0,
        statusCodes: {},
        models: {},
        apiKeys: {}
      }

      results.forEach(([err, logData]) => {
        if (err || !logData) {
          return
        }

        stats.totalRequests++
        stats.totalTokens += parseInt(logData.tokens) || 0
        stats.totalResponseTime += parseFloat(logData.responseTime) || 0

        // çŠ¶æ€ç ç»Ÿè®¡
        const status = logData.status || 'unknown'
        stats.statusCodes[status] = (stats.statusCodes[status] || 0) + 1

        // æ¨¡å‹ç»Ÿè®¡
        const model = logData.model || 'unknown'
        stats.models[model] = (stats.models[model] || 0) + 1

        // API Keyç»Ÿè®¡
        const keyId = logData.keyId || 'unknown'
        stats.apiKeys[keyId] = (stats.apiKeys[keyId] || 0) + 1
      })

      return stats
    } catch (error) {
      logger.error('Failed to aggregate logs:', error)
      return {}
    }
  }

  /**
   * é€šè¿‡ keyId å’Œæ—¥æœŸèŒƒå›´æœç´¢æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {string} keyId API Key ID
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´ {start, end}
   * @returns {Promise<Array>} åŒ¹é…çš„æ—¥å¿—é”®æ•°ç»„
   */
  async _searchLogsByKeyIdAndDate(client, keyId, dateRange) {
    const { start, end } = dateRange
    const startTimestamp = new Date(start).getTime()
    const endTimestamp = new Date(end).getTime()

    // ä½¿ç”¨æ›´ç²¾ç¡®çš„æ¨¡å¼åŒ¹é…
    const pattern = `request_log:${keyId}:*`
    const logs = await client.keys(pattern)

    // è¿‡æ»¤æ—¶é—´èŒƒå›´
    return logs.filter((logKey) => {
      const timestamp = parseInt(logKey.split(':')[2]) || 0
      return timestamp >= startTimestamp && timestamp <= endTimestamp
    })
  }

  /**
   * é€šè¿‡æ—¥æœŸèŒƒå›´æœç´¢æ—¥å¿—ï¼ˆç´¢å¼•ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´ {start, end}
   * @returns {Promise<Array>} åŒ¹é…çš„æ—¥å¿—é”®æ•°ç»„
   */
  async _searchLogsByDateRange(client, dateRange) {
    const { start, end } = dateRange
    const startTimestamp = new Date(start).getTime()
    const endTimestamp = new Date(end).getTime()

    // ä¼˜åŒ–ç­–ç•¥ï¼šä½¿ç”¨æ—¶é—´ç´¢å¼•è€Œä¸æ˜¯å…¨é‡æ‰«æ
    const startHour = Math.floor(startTimestamp / 3600000)
    const endHour = Math.floor(endTimestamp / 3600000)

    const allLogs = new Set()

    // å¦‚æœæ—¶é—´èŒƒå›´è·¨åº¦ä¸å¤§ï¼ˆå°‘äº24å°æ—¶ï¼‰ï¼Œä½¿ç”¨å°æ—¶ç´¢å¼•
    if (endHour - startHour <= 24) {
      for (let hour = startHour; hour <= endHour; hour++) {
        const hourKey = `request_log_time:${hour}`
        try {
          const hourLogs = await client.smembers(hourKey)
          hourLogs.forEach((logKey) => allLogs.add(logKey))
        } catch (error) {
          // ç´¢å¼•ä¸å­˜åœ¨æ—¶å¿½ç•¥é”™è¯¯
        }
      }

      // è½¬æ¢ä¸ºæ•°ç»„å¹¶è¿›è¡Œç²¾ç¡®æ—¶é—´è¿‡æ»¤
      return Array.from(allLogs).filter((logKey) => {
        const timestamp = parseInt(logKey.split(':')[2]) || 0
        return timestamp >= startTimestamp && timestamp <= endTimestamp
      })
    } else {
      // é•¿æ—¶é—´èŒƒå›´é™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•
      const allLogKeys = await client.keys('request_log:*')
      return allLogKeys.filter((logKey) => {
        const timestamp = parseInt(logKey.split(':')[2]) || 0
        return timestamp >= startTimestamp && timestamp <= endTimestamp
      })
    }
  }

  /**
   * é€šè¿‡çŠ¶æ€ç å’Œæ—¥æœŸèŒƒå›´æœç´¢æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {string} status çŠ¶æ€ç 
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´
   * @returns {Promise<Array>} åŒ¹é…çš„æ—¥å¿—é”®æ•°ç»„
   */
  async _searchLogsByStatusAndDate(client, status, dateRange) {
    const { start, end } = dateRange
    const startDate = new Date(start)
    const endDate = new Date(end)
    const results = new Set()

    // éå†æ—¥æœŸèŒƒå›´å†…çš„æ¯ä¸€å¤©
    for (let d = new Date(startDate); d <= endDate; d.setDate(d.getDate() + 1)) {
      const dateStr = getDateStringInTimezone(d)
      const statusIndex = `request_log_status:${status}:${dateStr}`

      try {
        const dayLogs = await client.smembers(statusIndex)
        dayLogs.forEach((logKey) => results.add(logKey))
      } catch (error) {
        // ç´¢å¼•ä¸å­˜åœ¨æ—¶å¿½ç•¥
      }
    }

    return Array.from(results)
  }

  /**
   * é€šè¿‡æ¨¡å‹å’Œæ—¥æœŸèŒƒå›´æœç´¢æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {string} model æ¨¡å‹åç§°
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´
   * @returns {Promise<Array>} åŒ¹é…çš„æ—¥å¿—é”®æ•°ç»„
   */
  async _searchLogsByModelAndDate(client, model, dateRange) {
    const { start, end } = dateRange
    const startDate = new Date(start)
    const endDate = new Date(end)
    const results = new Set()

    // éå†æ—¥æœŸèŒƒå›´å†…çš„æ¯ä¸€å¤©
    for (let d = new Date(startDate); d <= endDate; d.setDate(d.getDate() + 1)) {
      const dateStr = getDateStringInTimezone(d)
      const modelIndex = `request_log_model:${model}:${dateStr}`

      try {
        const dayLogs = await client.smembers(modelIndex)
        dayLogs.forEach((logKey) => results.add(logKey))
      } catch (error) {
        // ç´¢å¼•ä¸å­˜åœ¨æ—¶å¿½ç•¥
      }
    }

    return Array.from(results)
  }

  /**
   * é€šè¿‡æ—¥æœŸèŒƒå›´æœç´¢é”™è¯¯æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´
   * @returns {Promise<Array>} åŒ¹é…çš„é”™è¯¯æ—¥å¿—é”®æ•°ç»„
   */
  async _searchErrorLogsByDate(client, dateRange) {
    const { start, end } = dateRange
    const startDate = new Date(start)
    const endDate = new Date(end)
    const results = new Set()

    // éå†æ—¥æœŸèŒƒå›´å†…çš„æ¯ä¸€å¤©
    for (let d = new Date(startDate); d <= endDate; d.setDate(d.getDate() + 1)) {
      const dateStr = getDateStringInTimezone(d)
      const errorIndex = `request_log_errors:${dateStr}`

      try {
        const dayLogs = await client.smembers(errorIndex)
        dayLogs.forEach((logKey) => results.add(logKey))
      } catch (error) {
        // ç´¢å¼•ä¸å­˜åœ¨æ—¶å¿½ç•¥
      }
    }

    return Array.from(results)
  }

  /**
   * é€šè¿‡æŸ¥è¯¢æ¡ä»¶è¿‡æ»¤æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {Array} logKeys è¦è¿‡æ»¤çš„æ—¥å¿—é”®æ•°ç»„
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @returns {Promise<Array>} è¿‡æ»¤åçš„æ—¥å¿—é”®æ•°ç»„
   */
  async _filterLogsByQuery(client, logKeys, query) {
    if (logKeys.length === 0) {
      return []
    }

    // æ‰¹é‡è·å–æ—¥å¿—æ•°æ®ä»¥æ”¯æŒå¤æ‚è¿‡æ»¤
    const pipeline = client.pipeline()
    logKeys.forEach((logKey) => pipeline.hgetall(logKey))

    const results = await pipeline.exec()
    const filteredKeys = []

    // å¦‚æœæœ‰æ–‡æœ¬æœç´¢ï¼Œéœ€è¦é¢„åŠ è½½API Keyä¿¡æ¯
    let apiKeyCache = {}
    if (query.search) {
      try {
        logger.debug(`é¢„åŠ è½½API Keyä¿¡æ¯ä»¥æ”¯æŒæ–‡æœ¬æœç´¢: ${query.search}`)
        const allApiKeys = await this.getAllApiKeys()
        apiKeyCache = allApiKeys.reduce((cache, key) => {
          cache[key.id] = key
          return cache
        }, {})
        logger.debug(`å·²åŠ è½½ ${Object.keys(apiKeyCache).length} ä¸ªAPI Keyä¿¡æ¯`)
      } catch (error) {
        logger.warn('åŠ è½½API Keyä¿¡æ¯å¤±è´¥ï¼Œæ–‡æœ¬æœç´¢å¯èƒ½ä¸å®Œæ•´:', error.message)
      }
    }

    results.forEach(([err, logData], index) => {
      if (err || !logData) {
        return
      }

      const logKey = logKeys[index]
      let matches = true

      // åº”ç”¨å„ç§è¿‡æ»¤æ¡ä»¶
      for (const [key, value] of Object.entries(query)) {
        if (key === 'search') {
          // ç‰¹æ®Šå¤„ç†æ–‡æœ¬æœç´¢
          if (!this._performTextSearch(logData, logKey, value, apiKeyCache)) {
            matches = false
            break
          }
        } else if (!this._checkLogFieldMatch(logData, logKey, key, value)) {
          matches = false
          break
        }
      }

      if (matches) {
        filteredKeys.push(logKey)
      }
    })

    return filteredKeys
  }

  /**
   * æ£€æŸ¥æ—¥å¿—å­—æ®µæ˜¯å¦åŒ¹é…æŸ¥è¯¢æ¡ä»¶ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
   * @private
   * @param {Object} logData æ—¥å¿—æ•°æ®
   * @param {string} logKey æ—¥å¿—é”®
   * @param {string} fieldName å­—æ®µå
   * @param {*} value æœŸæœ›å€¼
   * @returns {boolean} æ˜¯å¦åŒ¹é…
   */
  _checkLogFieldMatch(logData, logKey, fieldName, value) {
    switch (fieldName) {
      case 'keyId':
        return logKey.includes(`:${value}:`) || logData.keyId === value

      case 'status':
        return logData.status === String(value)

      case 'method':
        return logData.method === value

      case 'path':
        return logData.path && logData.path.includes(value)

      case 'model':
        return logData.model === value

      case 'search':
        // æ–‡æœ¬æœç´¢åœ¨ä¸Šå±‚å¤„ç†ï¼Œè¿™é‡Œç›´æ¥è¿”å›true
        return true

      case 'dateRange':
        // æ—¥æœŸèŒƒå›´å·²åœ¨ä¸Šå±‚æ–¹æ³•ä¸­å¤„ç†
        return true

      case 'minTokens':
        return parseInt(logData.tokens) >= parseInt(value)

      case 'maxTokens':
        return parseInt(logData.tokens) <= parseInt(value)

      case 'minResponseTime':
        return parseFloat(logData.responseTime) >= parseFloat(value)

      case 'maxResponseTime':
        return parseFloat(logData.responseTime) <= parseFloat(value)

      case 'hasError':
        return value
          ? logData.error && logData.error !== 'null'
          : !logData.error || logData.error === 'null'

      default:
        // é€šç”¨å­—æ®µåŒ¹é…
        return logData[fieldName] === value
    }
  }

  /**
   * æ‰§è¡Œæ–‡æœ¬æœç´¢ï¼ˆå¤šå­—æ®µæ¨¡ç³ŠåŒ¹é…ï¼‰
   * @private
   * @param {Object} logData æ—¥å¿—æ•°æ®
   * @param {string} logKey æ—¥å¿—é”®
   * @param {string} searchText æœç´¢æ–‡æœ¬
   * @param {Object} apiKeyCache API Keyç¼“å­˜å¯¹è±¡
   * @returns {boolean} æ˜¯å¦åŒ¹é…
   */
  _performTextSearch(logData, logKey, searchText, apiKeyCache = {}) {
    if (!searchText || typeof searchText !== 'string') {
      return true
    }

    // é™åˆ¶æœç´¢è¯é•¿åº¦ï¼Œé¿å…è¿‡åº¦å¤æ‚æŸ¥è¯¢
    if (searchText.length > 100) {
      logger.warn(`æœç´¢è¯è¿‡é•¿ï¼Œæˆªæ–­åˆ°100å­—ç¬¦: ${searchText.substring(0, 100)}...`)
      searchText = searchText.substring(0, 100)
    }

    // ä¸åŒºåˆ†å¤§å°å†™çš„æœç´¢
    const searchLower = searchText.toLowerCase().trim()
    if (!searchLower) {
      return true
    }

    // æ”¯æŒå¤šè¯æœç´¢ï¼ˆç©ºæ ¼åˆ†å‰²ï¼‰
    const searchTerms = searchLower.split(/\s+/).filter((term) => term.length > 0)
    if (searchTerms.length === 0) {
      return true
    }

    // è·å–API Keyåç§°ï¼ˆä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½ï¼‰
    let apiKeyName = ''
    if (logData.keyId && apiKeyCache[logData.keyId]) {
      apiKeyName = (apiKeyCache[logData.keyId].name || '').toLowerCase()
    }

    // æ„å»ºæœç´¢å­—æ®µæ•°ç»„ï¼ˆä½¿ç”¨å®é™…çš„å­—æ®µåï¼‰
    const searchFields = [
      apiKeyName, // API Key åç§°
      (logData.path || '').toLowerCase(), // è¯·æ±‚è·¯å¾„
      (logData.ipAddress || '').toLowerCase(), // IP åœ°å€
      (logData.userAgent || '').toLowerCase(), // User Agent
      (logData.error || '').toLowerCase(), // é”™è¯¯ä¿¡æ¯
      (logData.method || '').toLowerCase(), // HTTPæ–¹æ³•
      (logData.model || '').toLowerCase(), // æ¨¡å‹åç§°
      (logData.keyId || '').toLowerCase(), // API Key ID
      (logData.statusCode || '').toString().toLowerCase() // çŠ¶æ€ç 
    ].filter((field) => field.length > 0)

    // åˆå¹¶æ‰€æœ‰æœç´¢å­—æ®µä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
    const searchableText = searchFields.join(' ')

    // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æœç´¢è¯éƒ½èƒ½åœ¨æœç´¢æ–‡æœ¬ä¸­æ‰¾åˆ°
    return searchTerms.every((term) => searchableText.includes(term))
  }

  /**
   * å¯¼å‡ºæ—¥å¿—åˆ°æ–‡ä»¶
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @param {string} format å¯¼å‡ºæ ¼å¼ï¼ˆcsv/jsonï¼‰
   * @param {string} filename å¯¼å‡ºæ–‡ä»¶å
   * @returns {Promise<string>} å¯¼å‡ºæ–‡ä»¶è·¯å¾„
   */
  async exportLogs(query = {}, format = 'csv', filename) {
    const path = require('path')
    const fs = require('fs')

    try {
      // æœç´¢æ—¥å¿—
      const logs = await this.searchLogs(query)

      // ç¡®å®šå¯¼å‡ºç›®å½•
      const exportDir = path.join(__dirname, '../../../logs/exports')
      fs.mkdirSync(exportDir, { recursive: true })

      const exportPath = path.join(exportDir, filename)

      if (format === 'json') {
        fs.writeFileSync(exportPath, JSON.stringify(logs, null, 2))
      } else {
        // CSVå¯¼å‡º
        const csvHeader = [
          'logId',
          'timestamp',
          'keyId',
          'path',
          'method',
          'status',
          'model',
          'tokens',
          'responseTime',
          'error'
        ]
        const csvContent = [
          csvHeader.join(','),
          ...logs.map((log) =>
            csvHeader
              .map((header) => `"${String(log[header] || '').replace(/"/g, '""')}"`)
              .join(',')
          )
        ].join('\n')

        fs.writeFileSync(exportPath, csvContent)
      }

      return exportPath
    } catch (error) {
      logger.error('Failed to export logs:', error)
      throw error
    }
  }

  /**
   * åˆ é™¤æŒ‡å®šæ¡ä»¶çš„æ—¥å¿—ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @returns {Promise<number>} åˆ é™¤çš„æ—¥å¿—æ•°é‡
   */
  async deleteLogs(query = {}) {
    try {
      const client = this.getClientSafe()
      let matchingLogs = []

      // ä½¿ç”¨ä¼˜åŒ–çš„æœç´¢ç­–ç•¥
      if (query.status && query.dateRange) {
        matchingLogs = await this._searchLogsByStatusAndDate(client, query.status, query.dateRange)
      } else if (query.model && query.dateRange) {
        matchingLogs = await this._searchLogsByModelAndDate(client, query.model, query.dateRange)
      } else if (query.hasError && query.dateRange) {
        matchingLogs = await this._searchErrorLogsByDate(client, query.dateRange)
      } else if (query.keyId && query.dateRange) {
        matchingLogs = await this._searchLogsByKeyIdAndDate(client, query.keyId, query.dateRange)
      } else if (query.keyId) {
        const pattern = `request_log:${query.keyId}:*`
        matchingLogs = await client.keys(pattern)
      } else if (query.dateRange) {
        matchingLogs = await this._searchLogsByDateRange(client, query.dateRange)
      } else if (query.status) {
        const today = getDateStringInTimezone()
        const statusIndex = `request_log_status:${query.status}:${today}`
        try {
          matchingLogs = await client.smembers(statusIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else if (query.model) {
        const today = getDateStringInTimezone()
        const modelIndex = `request_log_model:${query.model}:${today}`
        try {
          matchingLogs = await client.smembers(modelIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else {
        matchingLogs = await client.keys('request_log:*')
      }

      // åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
      if (Object.keys(query).length > 0 && !(query.keyId && Object.keys(query).length === 1)) {
        matchingLogs = await this._filterLogsByQuery(client, matchingLogs, query)
      }

      // åˆ†æ‰¹åˆ é™¤ä»¥é¿å…Rediså‘½ä»¤è¿‡é•¿
      let totalDeleted = 0
      const batchSize = 100 // æ¯æ‰¹åˆ é™¤100ä¸ªkey

      for (let i = 0; i < matchingLogs.length; i += batchSize) {
        const batch = matchingLogs.slice(i, i + batchSize)
        if (batch.length > 0) {
          await client.del(...batch)
          totalDeleted += batch.length
        }
      }

      // åŒæ—¶æ¸…ç†ç›¸å…³ç´¢å¼•
      await this._cleanupLogIndexes(client, matchingLogs)

      logger.info(`æˆåŠŸåˆ é™¤ ${totalDeleted} æ¡æ—¥å¿—è®°å½•`)
      return totalDeleted
    } catch (error) {
      logger.error('Failed to delete logs:', error)
      return 0
    }
  }

  /**
   * åˆ é™¤è¿‡æœŸçš„æ—¥å¿—è®°å½•ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @param {string} cutoffDate æˆªæ­¢æ—¥æœŸï¼ˆISOå­—ç¬¦ä¸²ï¼‰
   * @returns {Promise<number>} åˆ é™¤çš„æ—¥å¿—æ•°é‡
   */
  async deleteExpiredLogs(cutoffDate) {
    try {
      const client = this.getClientSafe()
      const cutoffTimestamp = new Date(cutoffDate).getTime()

      logger.info(`å¼€å§‹æ¸…ç† ${cutoffDate} ä¹‹å‰çš„è¿‡æœŸæ—¥å¿—`)

      // è·å–æ‰€æœ‰è¯·æ±‚æ—¥å¿—é”®
      const allLogKeys = await client.keys('request_log:*')
      logger.info(`å‘ç° ${allLogKeys.length} ä¸ªæ—¥å¿—æ–‡ä»¶`)

      // åˆ†æ‰¹å¤„ç†ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
      const batchSize = 500
      const expiredLogs = []

      for (let i = 0; i < allLogKeys.length; i += batchSize) {
        const batch = allLogKeys.slice(i, i + batchSize)

        // é¦–å…ˆä»keyä¸­æå–æ—¶é—´æˆ³è¿›è¡Œå¿«é€Ÿç­›é€‰
        const potentialExpired = batch.filter((logKey) => {
          const keyTimestamp = parseInt(logKey.split(':')[2]) || 0
          return keyTimestamp > 0 && keyTimestamp < cutoffTimestamp
        })

        // å¯¹äºå¯èƒ½è¿‡æœŸçš„æ—¥å¿—ï¼Œæ‰¹é‡è·å–è¯¦ç»†ä¿¡æ¯ç¡®è®¤
        if (potentialExpired.length > 0) {
          const pipeline = client.pipeline()
          potentialExpired.forEach((logKey) => pipeline.hget(logKey, 'timestamp'))

          const results = await pipeline.exec()

          results.forEach(([err, timestamp], index) => {
            if (!err && timestamp && parseInt(timestamp) < cutoffTimestamp) {
              expiredLogs.push(potentialExpired[index])
            }
          })
        }

        // è¿›åº¦æŠ¥å‘Š
        if (i + batchSize < allLogKeys.length) {
          logger.debug(
            `å·²å¤„ç† ${Math.min(i + batchSize, allLogKeys.length)}/${allLogKeys.length} ä¸ªæ—¥å¿—ï¼Œå‘ç° ${expiredLogs.length} ä¸ªè¿‡æœŸæ—¥å¿—`
          )
        }
      }

      // åˆ†æ‰¹åˆ é™¤è¿‡æœŸæ—¥å¿—
      let totalDeleted = 0
      const deleteBatchSize = 100

      for (let i = 0; i < expiredLogs.length; i += deleteBatchSize) {
        const batch = expiredLogs.slice(i, i + deleteBatchSize)
        if (batch.length > 0) {
          await client.del(...batch)
          totalDeleted += batch.length
        }
      }

      // æ¸…ç†ç›¸å…³ç´¢å¼•
      await this._cleanupLogIndexes(client, expiredLogs)

      logger.info(`æ¸…ç†è¿‡æœŸæ—¥å¿—å®Œæˆ: åˆ é™¤ ${totalDeleted} æ¡è®°å½•`)
      return totalDeleted
    } catch (error) {
      logger.error('Failed to delete expired logs:', error)
      return 0
    }
  }

  /**
   * æ¸…ç†æ—¥å¿—ç´¢å¼•
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {Array} deletedLogKeys å·²åˆ é™¤çš„æ—¥å¿—é”®æ•°ç»„
   * @returns {Promise<void>}
   */
  async _cleanupLogIndexes(client, deletedLogKeys) {
    if (deletedLogKeys.length === 0) {
      return
    }

    try {
      // è·å–æ‰€æœ‰ç´¢å¼•é”®
      const indexKeys = await client.keys('request_log_index:*')

      if (indexKeys.length > 0) {
        const pipeline = client.pipeline()

        // æ‰¹é‡æ¸…ç†ç´¢å¼•
        indexKeys.forEach((indexKey) => {
          deletedLogKeys.forEach((logKey) => {
            pipeline.srem(indexKey, logKey)
          })
        })

        await pipeline.exec()
        logger.debug(`æ¸…ç†äº† ${indexKeys.length} ä¸ªç´¢å¼•ä¸­çš„ ${deletedLogKeys.length} æ¡è®°å½•`)
      }
    } catch (error) {
      logger.warn('ç´¢å¼•æ¸…ç†å¤±è´¥ï¼Œä½†ä¸å½±å“æ—¥å¿—åˆ é™¤:', error.message)
    }
  }

  /**
   * è·å–è¯·æ±‚æ—¥å¿—é…ç½®
   * @returns {Promise<Object>} æ—¥å¿—é…ç½®å¯¹è±¡
   */
  async getRequestLogsConfig() {
    try {
      const configStr = await this.get('request_logs_config')
      return configStr ? JSON.parse(configStr) : null
    } catch (error) {
      logger.error('Failed to get request logs config:', error)
      return null
    }
  }

  /**
   * è®¾ç½®è¯·æ±‚æ—¥å¿—é…ç½®
   * @param {Object} config é…ç½®å¯¹è±¡
   * @returns {Promise<void>}
   */
  async setRequestLogsConfig(requestLogsConfig) {
    try {
      await this.set('request_logs_config', JSON.stringify(requestLogsConfig))
      logger.info('è¯·æ±‚æ—¥å¿—é…ç½®å·²æ›´æ–°')
    } catch (error) {
      logger.error('Failed to set request logs config:', error)
      throw error
    }
  }

  /**
   * è·å–å•ä¸ªè¯·æ±‚æ—¥å¿—çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
   * @param {string} logId æ—¥å¿—ID (å®Œæ•´çš„Redis keyæˆ–ç®€åŒ–çš„ID)
   * @returns {Promise<Object|null>} æ—¥å¿—è¯¦ç»†ä¿¡æ¯å¯¹è±¡æˆ–null
   */
  async getRequestLogDetails(logId) {
    try {
      const client = this.getClientSafe()
      let actualLogKey = logId
      const startTime = Date.now()

      // å‚æ•°éªŒè¯å’Œæ¸…ç†
      if (!logId || typeof logId !== 'string') {
        logger.warn('è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥: æ— æ•ˆçš„æ—¥å¿—IDå‚æ•°', { logId, type: typeof logId })
        return null
      }

      // æ¸…ç†å’Œæ ‡å‡†åŒ–logId
      const cleanLogId = logId.trim().replace(/^["']|["']$/g, '') // ç§»é™¤å¯èƒ½çš„å¼•å·
      if (!cleanLogId) {
        logger.warn('è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥: æ¸…ç†åçš„æ—¥å¿—IDä¸ºç©º', { originalLogId: logId })
        return null
      }

      // æ™ºèƒ½è¯†åˆ«å’Œæ„é€ å®Œæ•´çš„Redis key
      if (!cleanLogId.startsWith('request_log:')) {
        // å¦‚æœæ˜¯ç®€åŒ–çš„IDæ ¼å¼ï¼ˆå¦‚ keyId:timestampï¼‰ï¼Œæ„é€ å®Œæ•´key
        if (cleanLogId.includes(':')) {
          const parts = cleanLogId.split(':')
          if (parts.length === 2 && parts[0] && parts[1]) {
            actualLogKey = `request_log:${parts[0]}:${parts[1]}`
          } else if (parts.length === 3 && parts[0] === 'request_log') {
            actualLogKey = cleanLogId // å·²ç»æ˜¯å®Œæ•´æ ¼å¼
          } else {
            logger.warn('è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥: æ— æ³•è§£ææ—¥å¿—IDæ ¼å¼', {
              cleanLogId,
              parts,
              expectedFormat: 'keyId:timestamp æˆ– request_log:keyId:timestamp'
            })
            return null
          }
        } else {
          // å¦‚æœåªæ˜¯timestampï¼Œå°è¯•é€šè¿‡æ¨¡å¼åŒ¹é…æŸ¥æ‰¾ï¼ˆæ€§èƒ½è¾ƒä½ï¼Œè°¨æ…ä½¿ç”¨ï¼‰
          logger.debug('å°è¯•é€šè¿‡timestampæŸ¥æ‰¾æ—¥å¿—', { timestamp: cleanLogId })
          const pattern = `request_log:*:${cleanLogId}`
          const matchingKeys = await client.keys(pattern)
          if (matchingKeys.length > 0) {
            actualLogKey = matchingKeys[0] // å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„key
            logger.debug('é€šè¿‡æ¨¡å¼åŒ¹é…æ‰¾åˆ°æ—¥å¿—', { pattern, matchingKey: actualLogKey })
          } else {
            logger.warn('è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥: æœªæ‰¾åˆ°åŒ¹é…çš„æ—¥å¿—key', { pattern })
            return null
          }
        }
      } else {
        actualLogKey = cleanLogId
      }

      logger.debug(`è·å–æ—¥å¿—è¯¦æƒ…: ${logId} -> ${actualLogKey}`)

      // è·å–å®Œæ•´çš„hashæ•°æ®
      const logData = await client.hgetall(actualLogKey)

      // æ£€æŸ¥æ—¥å¿—æ˜¯å¦å­˜åœ¨
      if (!logData || Object.keys(logData).length === 0) {
        logger.warn(`æ—¥å¿—ä¸å­˜åœ¨: ${actualLogKey}`)
        return null
      }

      // å¤„ç†å’Œååºåˆ—åŒ–å¤æ‚å¯¹è±¡å­—æ®µ
      const processedLogData = { ...logData }

      // æ”¹è¿›çš„JSONååºåˆ—åŒ–å‡½æ•°ï¼Œæ”¯æŒå‹ç¼©æ•°æ®
      const safeJSONParse = (fieldName, value) => {
        if (!value || typeof value !== 'string') {
          return null
        }

        try {
          // å°è¯•ç›´æ¥JSONè§£æ
          return JSON.parse(value)
        } catch (e) {
          // å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å…¶ä»–æ ¼å¼
          logger.debug(`è§£æ${fieldName}å¤±è´¥ for log ${actualLogKey}:`, e.message)

          // æ£€æŸ¥æ˜¯å¦æ˜¯è¢«è½¬ä¹‰çš„JSONå­—ç¬¦ä¸²
          if (value.startsWith('\\"') || value.includes('\\"')) {
            try {
              const unescaped = value.replace(/\\"/g, '"')
              return JSON.parse(unescaped)
            } catch (unescapeError) {
              logger.debug(`åè½¬ä¹‰åè§£æ${fieldName}ä»ç„¶å¤±è´¥:`, unescapeError.message)
            }
          }

          return null
        }
      }

      // æ‰©å±•çš„æ•°æ®è§£å‹ç¼©å’Œååºåˆ—åŒ–å­—æ®µ
      const jsonFields = [
        'requestHeaders',
        'responseHeaders',
        'tokenDetails',
        'costDetails',
        'metadata'
      ]
      jsonFields.forEach((field) => {
        if (processedLogData[field]) {
          processedLogData[field] = safeJSONParse(field, processedLogData[field])
        }
      })

      // æ‰©å±•çš„æ•°å€¼ç±»å‹å­—æ®µè½¬æ¢ï¼ˆæ”¯æŒæ›´å¤šç¼“å­˜tokenç±»å‹ï¼‰
      const numericFields = {
        timestamp: 'int',
        duration: 'int',
        responseTime: 'float',
        inputTokens: 'int',
        outputTokens: 'int',
        totalTokens: 'int',
        cacheCreateTokens: 'int', // æ–°å¢ç¼“å­˜token
        cacheReadTokens: 'int', // æ–°å¢ç¼“å­˜token
        cost: 'float',
        status: 'int',
        tokens: 'int'
      }

      Object.entries(numericFields).forEach(([field, type]) => {
        if (processedLogData[field] !== undefined && processedLogData[field] !== '') {
          if (type === 'int') {
            processedLogData[field] = parseInt(processedLogData[field]) || 0
          } else if (type === 'float') {
            processedLogData[field] = parseFloat(processedLogData[field]) || 0
          }
        }
      })

      // æ·»åŠ æ—¥å¿—IDä¿¡æ¯
      processedLogData.logId = actualLogKey
      processedLogData.shortLogId = cleanLogId
      processedLogData.originalLogId = logId

      // å¢å¼ºçš„è®¡ç®—å­—æ®µå’Œå…ƒæ•°æ®
      processedLogData.hasHeaders = !!(
        (processedLogData.requestHeaders &&
          Object.keys(processedLogData.requestHeaders).length > 0) ||
        (processedLogData.responseHeaders &&
          Object.keys(processedLogData.responseHeaders).length > 0)
      )

      processedLogData.hasBody = !!(
        (processedLogData.requestBody && processedLogData.requestBody.trim().length > 0) ||
        (processedLogData.responseBody && processedLogData.responseBody.trim().length > 0)
      )

      processedLogData.isError = (processedLogData.status || 0) >= 400
      processedLogData.dateTime = processedLogData.timestamp
        ? new Date(processedLogData.timestamp).toISOString()
        : null

      // è¯¦ç»†çš„çŠ¶æ€åˆ†ç±»
      const statusCode = processedLogData.status || 0
      processedLogData.statusCategory =
        statusCode >= 500
          ? 'server_error'
          : statusCode >= 400
            ? 'client_error'
            : statusCode >= 300
              ? 'redirect'
              : statusCode >= 200
                ? 'success'
                : 'unknown'

      // å¢å¼ºçš„Tokenæ±‡æ€»ä¿¡æ¯ï¼ˆæ”¯æŒç¼“å­˜tokenï¼‰
      processedLogData.tokenSummary = {
        totalTokens: processedLogData.totalTokens || processedLogData.tokens || 0,
        inputTokens: processedLogData.inputTokens || 0,
        outputTokens: processedLogData.outputTokens || 0,
        cacheCreateTokens: processedLogData.cacheCreateTokens || 0, // æ–°å¢
        cacheReadTokens: processedLogData.cacheReadTokens || 0, // æ–°å¢
        cost: processedLogData.cost || 0,
        costBreakdown: processedLogData.costDetails || null,
        efficiency: 0
      }

      // è®¡ç®—tokenä½¿ç”¨æ•ˆç‡
      if (processedLogData.tokenSummary.totalTokens > 0) {
        processedLogData.tokenSummary.efficiency = parseFloat(
          (
            (processedLogData.tokenSummary.outputTokens /
              processedLogData.tokenSummary.totalTokens) *
            100
          ).toFixed(2)
        )
      }

      // æ€§èƒ½åˆ†æ
      const responseTime = processedLogData.duration || processedLogData.responseTime || 0
      processedLogData.performanceAnalysis = {
        responseTimeMs: responseTime,
        isSlowRequest: responseTime > 5000, // è¶…è¿‡5ç§’
        performanceLevel:
          responseTime > 10000
            ? 'very_slow'
            : responseTime > 5000
              ? 'slow'
              : responseTime > 1000
                ? 'normal'
                : 'fast',
        tokenEfficiency: processedLogData.tokenSummary.efficiency,
        errorCategory: processedLogData.statusCategory
      }

      // å¢å¼ºçš„è¯¦ç»†å…ƒæ•°æ®æ ‡å¿—
      processedLogData.metadata = {
        // åŸºæœ¬æ£€ç´¢ä¿¡æ¯
        retrievedAt: new Date().toISOString(),
        processingTimeMs: Date.now() - startTime,

        // æ•°æ®å¯ç”¨æ€§æ ‡å¿—
        hasRequestHeaders: !!(
          processedLogData.requestHeaders && Object.keys(processedLogData.requestHeaders).length > 0
        ),
        hasResponseHeaders: !!(
          processedLogData.responseHeaders &&
          Object.keys(processedLogData.responseHeaders).length > 0
        ),
        hasRequestBody: !!(
          processedLogData.requestBody && processedLogData.requestBody.trim().length > 0
        ),
        hasResponseBody: !!(
          processedLogData.responseBody && processedLogData.responseBody.trim().length > 0
        ),
        hasTokenDetails: !!(
          processedLogData.tokenDetails &&
          Object.keys(processedLogData.tokenDetails || {}).length > 0
        ),
        hasCostDetails: !!(
          processedLogData.costDetails && Object.keys(processedLogData.costDetails || {}).length > 0
        ),

        // æ•°æ®å®Œæ•´æ€§æ ‡å¿—
        isComplete: !!(
          processedLogData.requestHeaders &&
          processedLogData.responseHeaders &&
          processedLogData.tokenSummary
        ),
        hasError: processedLogData.isError,

        // æ•°æ®å¤§å°ä¿¡æ¯
        dataSize: {
          requestBodySize: processedLogData.requestBody ? processedLogData.requestBody.length : 0,
          responseBodySize: processedLogData.responseBody
            ? processedLogData.responseBody.length
            : 0,
          requestHeadersSize: processedLogData.requestHeaders
            ? JSON.stringify(processedLogData.requestHeaders).length
            : 0,
          responseHeadersSize: processedLogData.responseHeaders
            ? JSON.stringify(processedLogData.responseHeaders).length
            : 0,
          totalSize: 0
        },

        // Headeråˆ†æ
        headerAnalysis: {
          requestCount: processedLogData.requestHeaders
            ? Object.keys(processedLogData.requestHeaders).length
            : 0,
          responseCount: processedLogData.responseHeaders
            ? Object.keys(processedLogData.responseHeaders).length
            : 0,
          hasUserAgent: !!(
            processedLogData.requestHeaders?.['user-agent'] ||
            processedLogData.requestHeaders?.['User-Agent']
          ),
          hasContentType: !!(
            processedLogData.requestHeaders?.['content-type'] ||
            processedLogData.requestHeaders?.['Content-Type'] ||
            processedLogData.responseHeaders?.['content-type'] ||
            processedLogData.responseHeaders?.['Content-Type']
          )
        }
      }

      // è®¡ç®—æ€»æ•°æ®å¤§å°
      processedLogData.metadata.dataSize.totalSize =
        processedLogData.metadata.dataSize.requestBodySize +
        processedLogData.metadata.dataSize.responseBodySize +
        processedLogData.metadata.dataSize.requestHeadersSize +
        processedLogData.metadata.dataSize.responseHeadersSize

      const endTime = Date.now()
      logger.debug(
        `æˆåŠŸè·å–æ—¥å¿—è¯¦æƒ…: ${actualLogKey}, è€—æ—¶: ${endTime - startTime}ms, å­—æ®µæ•°: ${Object.keys(processedLogData).length}, hasHeaders: ${processedLogData.hasHeaders}, hasBody: ${processedLogData.hasBody}, tokens: ${processedLogData.tokenSummary.totalTokens}`
      )

      return processedLogData
    } catch (error) {
      logger.error(`è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥ ${logId}:`, {
        error: error.message,
        stack: error.stack,
        logId,
        timestamp: new Date().toISOString()
      })
      return null
    }
  }

  /**
   * ==========================================
   * æŠ½è±¡æ—¥å¿—å­˜å‚¨æ¥å£ (Abstract Log Storage Interface)
   * ==========================================
   *
   * ä»¥ä¸‹æ–¹æ³•æä¾›æ•°æ®åº“æ— å…³çš„æ—¥å¿—å­˜å‚¨æŠ½è±¡æ¥å£
   * æ”¯æŒä¸åŒæ•°æ®åº“åç«¯çš„æ‰©å±• (Redis, MongoDB, PostgreSQLç­‰)
   */

  /**
   * æ‰¹é‡å†™å…¥æ—¥å¿—æ¡ç›®
   * @param {Array} logEntries æ—¥å¿—æ¡ç›®æ•°ç»„
   * @param {Object} options é…ç½®é€‰é¡¹
   * @param {number} options.retentionMaxAge æ•°æ®ä¿ç•™æ—¶é—´ (æ¯«ç§’)
   * @returns {Promise<Object>} å†™å…¥ç»“æœ {success: boolean, results: Array, errors: Array}
   */
  async batchWriteLogs(logEntries, options = {}) {
    const client = this.getClientSafe()
    const pipeline = client.pipeline()
    const results = { success: true, results: [], errors: [] }

    try {
      for (const logEntry of logEntries) {
        const logKey = this._generateLogKey(logEntry)
        const indexKey = this._generateIndexKey(logEntry)

        // å¤„ç†hashæ•°æ®
        const dataEntries = Object.entries(logEntry.data).flat()
        if (dataEntries.length > 0 && dataEntries.length % 2 === 0) {
          // æ¸…ç†null/undefinedå€¼
          const sanitizedEntries = dataEntries.map((entry) =>
            entry === null || entry === undefined ? '' : String(entry)
          )

          // æ‰¹é‡å†™å…¥æ“ä½œ
          pipeline.hmset(logKey, ...sanitizedEntries)
          pipeline.expire(logKey, Math.floor(options.retentionMaxAge / 1000))

          // æ›´æ–°ç´¢å¼•
          pipeline.sadd(indexKey, logKey)
          pipeline.expire(indexKey, Math.floor(options.retentionMaxAge / 1000))

          results.results.push({ logKey, indexKey, status: 'queued' })
        } else {
          const error = `Invalid data structure for log entry: ${logKey}`
          results.errors.push({ logKey, error })
          logger.warn(`âš ï¸ ${error}`)
        }
      }

      // æ‰§è¡Œæ‰¹é‡æ“ä½œ
      const pipelineResults = await pipeline.exec()

      // å¤„ç†æ‰§è¡Œç»“æœ
      if (pipelineResults) {
        const errorResults = pipelineResults.filter(([err]) => err !== null)
        if (errorResults.length > 0) {
          results.success = false
          results.errors.push(
            ...errorResults.map(([err, res]) => ({
              error: err?.message || err,
              result: res
            }))
          )
        }
      }

      logger.debug(
        `ğŸ“Š Batch write completed: ${logEntries.length} logs, ${results.errors.length} errors`
      )
      return results
    } catch (error) {
      logger.error('âŒ Batch write logs failed:', error)
      results.success = false
      results.errors.push({ error: error.message })
      return results
    }
  }

  /**
   * éªŒè¯æ—¥å¿—å†™å…¥ç»“æœ
   * @param {string} logKey æ—¥å¿—é”®
   * @returns {Promise<Object>} éªŒè¯ç»“æœ {success: boolean, data: Object|null}
   */
  async verifyLogWrite(logKey) {
    try {
      const client = this.getClientSafe()
      const data = await client.hgetall(logKey)

      return {
        success: data && Object.keys(data).length > 0,
        data: data || null,
        fieldsCount: data ? Object.keys(data).length : 0
      }
    } catch (error) {
      logger.error(`âŒ Log write verification failed for ${logKey}:`, error)
      return {
        success: false,
        data: null,
        error: error.message
      }
    }
  }

  /**
   * ç”Ÿæˆæ—¥å¿—é”®
   * @private
   * @param {Object} logEntry æ—¥å¿—æ¡ç›®
   * @returns {string} æ—¥å¿—é”®
   */
  _generateLogKey(logEntry) {
    return `request_log:${logEntry.keyId}:${logEntry.timestamp}`
  }

  /**
   * ç”Ÿæˆç´¢å¼•é”®
   * @private
   * @param {Object} logEntry æ—¥å¿—æ¡ç›®
   * @returns {string} ç´¢å¼•é”®
   */
  _generateIndexKey(logEntry) {
    // ä½¿ç”¨æ—¶åŒºè½¬æ¢çš„æ—¥æœŸ
    const date = getDateStringInTimezone(new Date(logEntry.timestamp))
    return `request_log_index:${logEntry.keyId}:${date}`
  }

  // ==================== æ™ºèƒ½æ—¥å¿—åˆå¹¶åŠŸèƒ½ ====================

  /**
   * æ£€æµ‹å’ŒæŸ¥æ‰¾é‡å¤çš„æ—¥å¿—æ¡ç›®
   * @param {string} keyId API Key ID
   * @param {Object} logData å¾…æ£€æµ‹çš„æ—¥å¿—æ•°æ®
   * @param {number} windowMs æ£€æµ‹æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰
   * @returns {Promise<Array>} é‡å¤æ—¥å¿—æ¡ç›®æ•°ç»„
   */
  async detectDuplicateLogs(keyId, logData, windowMs = 15000) {
    try {
      const client = this.getClientSafe()
      const currentTime = logData.timestamp || Date.now()
      const startTime = currentTime - windowMs
      const endTime = currentTime + windowMs

      // æœç´¢æ—¶é—´çª—å£å†…çš„ç›¸å…³æ—¥å¿—
      const pattern = `request_log:${keyId}:*`
      const logKeys = await client.keys(pattern)

      const duplicates = []

      // æ‰¹é‡è·å–æ—¥å¿—è¯¦æƒ…
      if (logKeys.length > 0) {
        const pipeline = client.pipeline()
        logKeys.forEach((key) => pipeline.hgetall(key))
        const results = await pipeline.exec()

        results.forEach(([err, logEntry], index) => {
          if (err || !logEntry) {
            return
          }

          const logTimestamp = parseInt(logEntry.timestamp)
          if (logTimestamp < startTime || logTimestamp > endTime) {
            return
          }

          // è®¡ç®—ç›¸ä¼¼åº¦
          const similarity = this._calculateLogSimilarity(logData, logEntry)
          if (similarity > 0.8) {
            // 80%ç›¸ä¼¼åº¦é˜ˆå€¼
            duplicates.push({
              logId: logKeys[index],
              timestamp: logTimestamp,
              priority: this._determinePriority(logEntry),
              similarity: Math.round(similarity * 100) / 100,
              data: logEntry
            })
          }
        })
      }

      // æŒ‰ä¼˜å…ˆçº§å’Œæ—¶é—´æ’åº
      duplicates.sort((a, b) => {
        const priorityOrder = { enhanced: 3, basic: 2, unknown: 1 }
        const priorityDiff = (priorityOrder[b.priority] || 1) - (priorityOrder[a.priority] || 1)
        return priorityDiff !== 0 ? priorityDiff : b.timestamp - a.timestamp
      })

      return duplicates
    } catch (error) {
      logger.error('âŒ Failed to detect duplicate logs:', error)
      return []
    }
  }

  /**
   * åˆå¹¶å¤šä¸ªæ—¥å¿—æ¡ç›®
   * @param {string} primaryLogId ä¸»è¦æ—¥å¿—ID
   * @param {Array} duplicateLogIds é‡å¤æ—¥å¿—IDæ•°ç»„
   * @param {Object} mergeStrategy åˆå¹¶ç­–ç•¥é…ç½®
   * @returns {Promise<Object>} åˆå¹¶ç»“æœ
   */
  async mergeLogEntries(primaryLogId, duplicateLogIds, mergeStrategy = {}) {
    try {
      const client = this.getClientSafe()

      // é»˜è®¤åˆå¹¶ç­–ç•¥
      const strategy = {
        priority: mergeStrategy.priority || 'higher',
        preserveHeaders: mergeStrategy.preserveHeaders !== false,
        aggregateTokens: mergeStrategy.aggregateTokens !== false,
        ...mergeStrategy
      }

      // è·å–æ‰€æœ‰è¦åˆå¹¶çš„æ—¥å¿—æ•°æ®
      const allLogIds = [primaryLogId, ...duplicateLogIds]
      const pipeline = client.pipeline()
      allLogIds.forEach((logId) => pipeline.hgetall(logId))
      const results = await pipeline.exec()

      const logEntries = results
        .filter(([err, data]) => !err && data && Object.keys(data).length > 0)
        .map(([, data]) => data)

      if (logEntries.length < 2) {
        return { success: false, error: 'Insufficient logs to merge' }
      }

      // æ‰§è¡Œåˆå¹¶
      const mergedData = this._performLogMerge(logEntries, strategy)

      // æ›´æ–°ä¸»æ—¥å¿—
      await client.hmset(primaryLogId, mergedData)

      // åˆ é™¤é‡å¤æ—¥å¿—
      if (duplicateLogIds.length > 0) {
        await client.del(...duplicateLogIds)

        // æ¸…ç†ç›¸å…³ç´¢å¼•
        await this._cleanupLogIndexes(client, duplicateLogIds)
      }

      logger.info(`ğŸ”„ Merged ${duplicateLogIds.length} duplicate logs into ${primaryLogId}`)

      return {
        success: true,
        mergedLogId: primaryLogId,
        details: {
          mergedCount: duplicateLogIds.length,
          strategy: strategy.priority,
          preservedHeaders: strategy.preserveHeaders,
          aggregatedTokens: strategy.aggregateTokens
        }
      }
    } catch (error) {
      logger.error('âŒ Failed to merge log entries:', error)
      return { success: false, error: error.message }
    }
  }

  /**
   * è®¡ç®—æ—¥å¿—ç›¸ä¼¼åº¦
   * @private
   * @param {Object} logA æ—¥å¿—A
   * @param {Object} logB æ—¥å¿—B
   * @returns {number} ç›¸ä¼¼åº¦ (0-1)
   */
  _calculateLogSimilarity(logA, logB) {
    let score = 0
    let factors = 0

    // è·¯å¾„ç›¸ä¼¼åº¦ (æƒé‡: 0.3)
    if (logA.path && logB.path) {
      score += logA.path === logB.path ? 0.3 : 0
      factors += 0.3
    }

    // æ–¹æ³•ç›¸ä¼¼åº¦ (æƒé‡: 0.2)
    if (logA.method && logB.method) {
      score += logA.method === logB.method ? 0.2 : 0
      factors += 0.2
    }

    // æ¨¡å‹ç›¸ä¼¼åº¦ (æƒé‡: 0.2)
    if (logA.model && logB.model) {
      score += logA.model === logB.model ? 0.2 : 0
      factors += 0.2
    }

    // çŠ¶æ€ç ç›¸ä¼¼åº¦ (æƒé‡: 0.15)
    if (logA.status && logB.status) {
      score += logA.status === logB.status ? 0.15 : 0
      factors += 0.15
    }

    // Tokenæ•°é‡ç›¸ä¼¼åº¦ (æƒé‡: 0.15)
    const tokensA = parseInt(logA.tokens || logA.totalTokens || 0)
    const tokensB = parseInt(logB.tokens || logB.totalTokens || 0)
    if (tokensA > 0 && tokensB > 0) {
      const tokenRatio = Math.min(tokensA, tokensB) / Math.max(tokensA, tokensB)
      score += tokenRatio > 0.8 ? 0.15 : 0
      factors += 0.15
    }

    return factors > 0 ? score / factors : 0
  }

  /**
   * ç¡®å®šæ—¥å¿—ä¼˜å…ˆçº§
   * @private
   * @param {Object} logEntry æ—¥å¿—æ¡ç›®
   * @returns {string} ä¼˜å…ˆçº§
   */
  _determinePriority(logEntry) {
    if (logEntry.source === 'unified_service' || logEntry.logVersion?.startsWith('2.')) {
      return 'enhanced'
    }

    if (logEntry.requestHeaders || logEntry.responseHeaders || logEntry.tokenDetails) {
      return 'enhanced'
    }

    if (logEntry.logVersion || logEntry.source) {
      return 'basic'
    }

    return 'unknown'
  }

  /**
   * æ‰§è¡Œæ—¥å¿—æ•°æ®åˆå¹¶
   * @private
   * @param {Array} logEntries æ—¥å¿—æ¡ç›®æ•°ç»„
   * @param {Object} strategy åˆå¹¶ç­–ç•¥
   * @returns {Object} åˆå¹¶åçš„æ•°æ®
   */
  _performLogMerge(logEntries, strategy) {
    // æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé€‰æ‹©æœ€ä½³æ•°æ®æº
    const sortedEntries = logEntries.sort((a, b) => {
      const priorityOrder = { enhanced: 3, basic: 2, unknown: 1 }
      const aPriority = this._determinePriority(a)
      const bPriority = this._determinePriority(b)
      return (priorityOrder[bPriority] || 1) - (priorityOrder[aPriority] || 1)
    })

    const primary = sortedEntries[0]
    const merged = { ...primary }

    // èšåˆTokenç»Ÿè®¡
    if (strategy.aggregateTokens) {
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let totalCacheCreateTokens = 0
      let totalCacheReadTokens = 0
      let totalRequests = 0

      logEntries.forEach((entry) => {
        totalTokens += parseInt(entry.tokens || entry.totalTokens || 0)
        totalInputTokens += parseInt(entry.inputTokens || 0)
        totalOutputTokens += parseInt(entry.outputTokens || 0)
        totalCacheCreateTokens += parseInt(entry.cacheCreateTokens || 0)
        totalCacheReadTokens += parseInt(entry.cacheReadTokens || 0)
        totalRequests += 1
      })

      merged.tokens = totalTokens
      merged.totalTokens = totalTokens
      merged.inputTokens = totalInputTokens
      merged.outputTokens = totalOutputTokens
      merged.cacheCreateTokens = totalCacheCreateTokens
      merged.cacheReadTokens = totalCacheReadTokens
      merged.mergedRequestCount = totalRequests
    }

    // åˆå¹¶Headersä¿¡æ¯
    if (strategy.preserveHeaders) {
      const allRequestHeaders = {}
      const allResponseHeaders = {}

      logEntries.forEach((entry) => {
        if (entry.requestHeaders) {
          const headers =
            typeof entry.requestHeaders === 'string'
              ? JSON.parse(entry.requestHeaders)
              : entry.requestHeaders
          Object.assign(allRequestHeaders, headers)
        }

        if (entry.responseHeaders) {
          const headers =
            typeof entry.responseHeaders === 'string'
              ? JSON.parse(entry.responseHeaders)
              : entry.responseHeaders
          Object.assign(allResponseHeaders, headers)
        }
      })

      if (Object.keys(allRequestHeaders).length > 0) {
        merged.requestHeaders = JSON.stringify(allRequestHeaders)
      }

      if (Object.keys(allResponseHeaders).length > 0) {
        merged.responseHeaders = JSON.stringify(allResponseHeaders)
      }
    }

    // æ·»åŠ åˆå¹¶å…ƒæ•°æ®
    merged.logVersion = '2.0.0-merged'
    merged.source = 'unified_service'
    merged.mergedAt = new Date().toISOString()
    merged.originalLogCount = logEntries.length

    return merged
  }

  // ==================== è´¦æˆ·è´¹ç”¨ç»Ÿè®¡æ–¹æ³• ====================

  /**
   * è·å–è´¦æˆ·è´¹ç”¨ç»Ÿè®¡
   * @param {string} accountId - è´¦æˆ·ID
   * @param {string} period - æ—¶é—´èŒƒå›´ ('today', 'week', 'month', 'all')
   * @param {string} platform - å¹³å°ç±»å‹ ('claude', 'gemini', 'openai', 'bedrock', 'azure_openai', 'claude-console')
   * @returns {Promise<Object>} è´¦æˆ·è´¹ç”¨ç»Ÿè®¡æ•°æ®
   */
  async getAccountCostStats(accountId, _period = 'all', platform = 'claude') {
    try {
      // å‚æ•°éªŒè¯
      if (!accountId || typeof accountId !== 'string') {
        throw new Error('Invalid accountId: must be a non-empty string')
      }

      const now = new Date()
      const tzDate = getDateInTimezone(now)
      const dateString = getDateStringInTimezone(now)
      const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
      const currentHour = `${dateString}:${String(tzDate.getUTCHours()).padStart(2, '0')}`

      // ç”ŸæˆåŸºäºå¹³å°çš„Redisé”®
      // Claudeä¿æŒå‘åå…¼å®¹ï¼Œå…¶ä»–å¹³å°ä½¿ç”¨å¹³å°å‰ç¼€
      let accountKeyPart
      if (platform === 'claude') {
        // Claudeä¿æŒåŸæœ‰é”®æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        accountKeyPart = `account:${accountId}`
      } else {
        // å…¶ä»–å¹³å°ä½¿ç”¨å¹³å°å‰ç¼€
        accountKeyPart = `account:${platform}:${accountId}`
      }

      const dailyKey = `usage:cost:daily:${accountKeyPart}:${dateString}`
      const monthlyKey = `usage:cost:monthly:${accountKeyPart}:${currentMonth}`
      const hourlyKey = `usage:cost:hourly:${accountKeyPart}:${currentHour}`
      const totalKey = `usage:cost:total:${accountKeyPart}`

      // æ‰¹é‡è·å–è´¹ç”¨æ•°æ®
      const [daily, monthly, hourly, total] = await Promise.all([
        this.client.get(dailyKey),
        this.client.get(monthlyKey),
        this.client.get(hourlyKey),
        this.client.get(totalKey)
      ])

      // è·å–æ¨¡å‹çº§åˆ«çš„è´¹ç”¨ç»Ÿè®¡
      const modelDailyPattern = `usage:cost:daily:${accountKeyPart}:*:${dateString}`
      const modelMonthlyPattern = `usage:cost:monthly:${accountKeyPart}:*:${currentMonth}`

      const [modelDailyKeys, modelMonthlyKeys] = await Promise.all([
        this.client.keys(modelDailyPattern),
        this.client.keys(modelMonthlyPattern)
      ])

      // è·å–æ¨¡å‹è´¹ç”¨è¯¦æƒ…
      const modelStats = {
        daily: {},
        monthly: {}
      }

      if (modelDailyKeys.length > 0) {
        const modelDailyPipeline = this.client.pipeline()
        modelDailyKeys.forEach((key) => modelDailyPipeline.get(key))
        const modelDailyResults = await modelDailyPipeline.exec()

        modelDailyKeys.forEach((key, index) => {
          const model = key.split(':')[6] // æå–æ¨¡å‹å
          const cost = parseFloat(modelDailyResults[index][1]) || 0
          if (cost > 0) {
            modelStats.daily[model] = cost
          }
        })
      }

      if (modelMonthlyKeys.length > 0) {
        const modelMonthlyPipeline = this.client.pipeline()
        modelMonthlyKeys.forEach((key) => modelMonthlyPipeline.get(key))
        const modelMonthlyResults = await modelMonthlyPipeline.exec()

        modelMonthlyKeys.forEach((key, index) => {
          const model = key.split(':')[6] // æå–æ¨¡å‹å
          const cost = parseFloat(modelMonthlyResults[index][1]) || 0
          if (cost > 0) {
            modelStats.monthly[model] = cost
          }
        })
      }

      // ä½¿ç”¨Decimal.jsç¡®ä¿ç²¾åº¦
      const dailyCost = new Decimal(parseFloat(daily) || 0)
      const monthlyCost = new Decimal(parseFloat(monthly) || 0)
      const hourlyCost = new Decimal(parseFloat(hourly) || 0)
      const totalCost = new Decimal(parseFloat(total) || 0)

      const costStats = {
        accountId,
        timestamp: now.toISOString(),
        timezone: config.timezone || 'UTC',
        costs: {
          daily: dailyCost.toNumber(),
          monthly: monthlyCost.toNumber(),
          hourly: hourlyCost.toNumber(),
          total: totalCost.toNumber()
        },
        formatted: {
          daily: CostCalculator.formatCost(dailyCost.toNumber()),
          monthly: CostCalculator.formatCost(monthlyCost.toNumber()),
          hourly: CostCalculator.formatCost(hourlyCost.toNumber()),
          total: CostCalculator.formatCost(totalCost.toNumber())
        },
        modelBreakdown: modelStats,
        period: {
          daily: dateString,
          monthly: currentMonth,
          hourly: `${dateString}:${String(tzDate.getUTCHours()).padStart(2, '0')}`
        },
        averages: {
          // è®¡ç®—æœˆåº¦æ—¥å‡è´¹ç”¨
          dailyAverage: monthlyCost.div(new Date().getDate()).toNumber(),
          // è®¡ç®—å°æ—¶å‡è´¹ç”¨
          hourlyAverage: dailyCost.div(24).toNumber()
        }
      }

      logger.debug(
        `ğŸ’° Retrieved cost stats for account ${accountId}: daily=$${dailyCost.toString()}, monthly=$${monthlyCost.toString()}, total=$${totalCost.toString()}`
      )

      return costStats
    } catch (error) {
      logger.error(`âŒ Failed to get account cost stats for ${accountId}:`, error)
      // é™çº§å¤„ç† - è¿”å›é»˜è®¤ç»Ÿè®¡ç»“æ„
      return {
        accountId,
        timestamp: new Date().toISOString(),
        timezone: config.timezone || 'UTC',
        costs: {
          daily: 0,
          monthly: 0,
          hourly: 0,
          total: 0
        },
        formatted: {
          daily: '$0.000000',
          monthly: '$0.000000',
          hourly: '$0.000000',
          total: '$0.000000'
        },
        modelBreakdown: {
          daily: {},
          monthly: {}
        },
        period: {
          daily: getDateStringInTimezone(),
          monthly: new Date().toISOString().substring(0, 7),
          hourly: `${getDateStringInTimezone()}:${String(getHourInTimezone()).padStart(2, '0')}`
        },
        averages: {
          dailyAverage: 0,
          hourlyAverage: 0
        },
        error: error.message
      }
    }
  }

  // ==================== ç”¨æˆ·ç®¡ç† (8ä¸ªæ–¹æ³•) ====================

  /**
   * åˆ›å»ºç”¨æˆ·
   * @param {Object} userData - ç”¨æˆ·æ•°æ®
   * @param {string} userData.username - ç”¨æˆ·å
   * @param {string} userData.email - é‚®ç®±
   * @param {string} userData.passwordHash - å¯†ç å“ˆå¸Œ
   * @param {string} [userData.role='user'] - ç”¨æˆ·è§’è‰²
   * @param {Array} [userData.permissions=[]] - ç”¨æˆ·æƒé™
   * @param {Array} [userData.groups=[]] - ç”¨æˆ·åˆ†ç»„
   * @returns {Promise<string>} ç”¨æˆ·ID
   */
  async createUser(userData) {
    try {
      const client = this.getClientSafe()
      const userId = require('crypto').randomUUID()
      const now = new Date().toISOString()

      // éªŒè¯å¿…éœ€å­—æ®µ
      if (!userData.username || !userData.passwordHash) {
        throw new Error('Username and passwordHash are required')
      }

      // æ£€æŸ¥ç”¨æˆ·åå”¯ä¸€æ€§
      const existingUser = await client.get(`user_username:${userData.username}`)
      if (existingUser) {
        throw new Error('Username already exists')
      }

      // æ£€æŸ¥é‚®ç®±å”¯ä¸€æ€§ï¼ˆå¦‚æœæä¾›ï¼‰
      if (userData.email) {
        const existingEmail = await client.get(`user_email:${userData.email}`)
        if (existingEmail) {
          throw new Error('Email already exists')
        }
      }

      const user = {
        id: userId,
        username: userData.username,
        email: userData.email || '',
        passwordHash: userData.passwordHash,
        role: userData.role || 'user',
        permissions: JSON.stringify(userData.permissions || []),
        groups: JSON.stringify(userData.groups || []),
        isActive: 'true',
        lastLogin: '',
        createdAt: now,
        updatedAt: now,
        ldapDN: userData.ldapDN || '',
        preferences: JSON.stringify(userData.preferences || {})
      }

      // ä½¿ç”¨äº‹åŠ¡ä¿è¯æ•°æ®ä¸€è‡´æ€§
      const pipeline = client.pipeline()
      pipeline.hset(`user:${userId}`, user)
      pipeline.set(`user_username:${userData.username}`, userId)
      if (userData.email) {
        pipeline.set(`user_email:${userData.email}`, userId)
      }
      await pipeline.exec()

      logger.info(`ğŸ‘¤ Created user: ${userData.username} (${userId})`)
      return userId
    } catch (error) {
      logger.error('âŒ Failed to create user:', error)
      throw error
    }
  }

  /**
   * æ ¹æ®ç”¨æˆ·åè·å–ç”¨æˆ·
   * @param {string} username - ç”¨æˆ·å
   * @returns {Promise<Object|null>} ç”¨æˆ·æ•°æ®
   */
  async getUserByUsername(username) {
    try {
      if (!username) {
        return null
      }

      const client = this.getClientSafe()
      const userId = await client.get(`user_username:${username}`)

      if (!userId) {
        return null
      }

      return await this.getUserById(userId)
    } catch (error) {
      logger.error(`âŒ Failed to get user by username ${username}:`, error)
      return null
    }
  }

  /**
   * æ ¹æ®ç”¨æˆ·IDè·å–ç”¨æˆ·
   * @param {string} userId - ç”¨æˆ·ID
   * @returns {Promise<Object|null>} ç”¨æˆ·æ•°æ®
   */
  async getUserById(userId) {
    try {
      if (!userId) {
        return null
      }

      const client = this.getClientSafe()
      const userData = await client.hgetall(`user:${userId}`)

      if (!userData || Object.keys(userData).length === 0) {
        return null
      }

      // è§£æJSONå­—æ®µ
      return {
        ...userData,
        permissions: JSON.parse(userData.permissions || '[]'),
        groups: JSON.parse(userData.groups || '[]'),
        preferences: JSON.parse(userData.preferences || '{}'),
        isActive: userData.isActive === 'true'
      }
    } catch (error) {
      logger.error(`âŒ Failed to get user by ID ${userId}:`, error)
      return null
    }
  }

  /**
   * æ›´æ–°ç”¨æˆ·ä¿¡æ¯
   * @param {string} userId - ç”¨æˆ·ID
   * @param {Object} updateData - æ›´æ–°æ•°æ®
   * @returns {Promise<boolean>} æ›´æ–°æ˜¯å¦æˆåŠŸ
   */
  async updateUser(userId, updateData) {
    try {
      const client = this.getClientSafe()
      const existingUser = await this.getUserById(userId)

      if (!existingUser) {
        throw new Error('User not found')
      }

      const now = new Date().toISOString()
      const pipeline = client.pipeline()

      // å‡†å¤‡æ›´æ–°æ•°æ®
      const updates = {
        updatedAt: now
      }

      // å¤„ç†å„å­—æ®µçš„æ›´æ–°
      const allowedFields = [
        'email',
        'passwordHash',
        'role',
        'permissions',
        'groups',
        'isActive',
        'ldapDN',
        'preferences'
      ]

      for (const [field, value] of Object.entries(updateData)) {
        if (allowedFields.includes(field)) {
          if (field === 'permissions' || field === 'groups' || field === 'preferences') {
            updates[field] = JSON.stringify(value)
          } else if (field === 'isActive') {
            updates[field] = value ? 'true' : 'false'
          } else {
            updates[field] = value
          }
        }
      }

      // æ£€æŸ¥é‚®ç®±å”¯ä¸€æ€§ï¼ˆå¦‚æœæ›´æ–°é‚®ç®±ï¼‰
      if (updateData.email && updateData.email !== existingUser.email) {
        const existingEmail = await client.get(`user_email:${updateData.email}`)
        if (existingEmail && existingEmail !== userId) {
          throw new Error('Email already exists')
        }

        // æ›´æ–°é‚®ç®±æ˜ å°„
        if (existingUser.email) {
          pipeline.del(`user_email:${existingUser.email}`)
        }
        pipeline.set(`user_email:${updateData.email}`, userId)
      }

      pipeline.hset(`user:${userId}`, updates)
      await pipeline.exec()

      logger.info(`ğŸ‘¤ Updated user: ${existingUser.username} (${userId})`)
      return true
    } catch (error) {
      logger.error(`âŒ Failed to update user ${userId}:`, error)
      throw error
    }
  }

  /**
   * åˆ é™¤ç”¨æˆ·ï¼ˆè½¯åˆ é™¤ï¼‰
   * @param {string} userId - ç”¨æˆ·ID
   * @returns {Promise<boolean>} åˆ é™¤æ˜¯å¦æˆåŠŸ
   */
  async deleteUser(userId) {
    try {
      const client = this.getClientSafe()
      const existingUser = await this.getUserById(userId)

      if (!existingUser) {
        return false
      }

      const now = new Date().toISOString()
      const pipeline = client.pipeline()

      // è½¯åˆ é™¤ï¼šæ ‡è®°ä¸ºéæ´»è·ƒå¹¶æ·»åŠ åˆ é™¤æ ‡è®°
      pipeline.hset(`user:${userId}`, {
        isActive: 'false',
        deletedAt: now,
        updatedAt: now
      })

      // æ¸…ç†æ˜ å°„ï¼ˆé˜²æ­¢ç”¨æˆ·å/é‚®ç®±è¢«é‡ç”¨ï¼‰
      pipeline.del(`user_username:${existingUser.username}`)
      if (existingUser.email) {
        pipeline.del(`user_email:${existingUser.email}`)
      }

      // æ¸…ç†ç”¨æˆ·ä¼šè¯
      const sessionKeys = await client.keys(`session:*`)
      for (const sessionKey of sessionKeys) {
        const sessionData = await client.hgetall(sessionKey)
        if (sessionData.userId === userId) {
          pipeline.del(sessionKey)
        }
      }

      await pipeline.exec()

      logger.info(`ğŸ‘¤ Deleted user: ${existingUser.username} (${userId})`)
      return true
    } catch (error) {
      logger.error(`âŒ Failed to delete user ${userId}:`, error)
      throw error
    }
  }

  /**
   * åˆ›å»ºç”¨æˆ·ä¼šè¯
   * @param {string} userId - ç”¨æˆ·ID
   * @param {Object} sessionData - ä¼šè¯æ•°æ®
   * @param {number} [expiresIn=86400] - è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
   * @returns {Promise<string>} ä¼šè¯ä»¤ç‰Œ
   */
  async createSession(userId, sessionData, expiresIn = 86400) {
    try {
      const client = this.getClientSafe()
      const sessionToken = require('crypto').randomBytes(32).toString('hex')
      const now = new Date().toISOString()
      const expiresAt = new Date(Date.now() + expiresIn * 1000).toISOString()

      const session = {
        token: sessionToken,
        userId,
        createdAt: now,
        lastActivity: now,
        expiresAt,
        ipAddress: sessionData.ipAddress || '',
        userAgent: sessionData.userAgent || '',
        isActive: 'true'
      }

      await client.hset(`session:${sessionToken}`, session)
      await client.expire(`session:${sessionToken}`, expiresIn)

      // æ›´æ–°ç”¨æˆ·æœ€åç™»å½•æ—¶é—´
      await client.hset(`user:${userId}`, { lastLogin: now })

      logger.info(`ğŸ”‘ Created session for user ${userId}: ${sessionToken.substring(0, 8)}...`)
      return sessionToken
    } catch (error) {
      logger.error(`âŒ Failed to create session for user ${userId}:`, error)
      throw error
    }
  }

  /**
   * éªŒè¯ç”¨æˆ·ä¼šè¯
   * @param {string} sessionToken - ä¼šè¯ä»¤ç‰Œ
   * @returns {Promise<Object|null>} ä¼šè¯æ•°æ®
   */
  async validateSession(sessionToken) {
    try {
      if (!sessionToken) {
        return null
      }

      const client = this.getClientSafe()
      const sessionData = await client.hgetall(`session:${sessionToken}`)

      if (!sessionData || Object.keys(sessionData).length === 0) {
        return null
      }

      // æ£€æŸ¥ä¼šè¯æ˜¯å¦è¿‡æœŸ
      const now = new Date()
      const expiresAt = new Date(sessionData.expiresAt)

      if (now > expiresAt || sessionData.isActive !== 'true') {
        await this.destroySession(sessionToken)
        return null
      }

      // è·å–ç”¨æˆ·ä¿¡æ¯
      const user = await this.getUserById(sessionData.userId)
      if (!user || !user.isActive) {
        await this.destroySession(sessionToken)
        return null
      }

      // æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
      await client.hset(`session:${sessionToken}`, { lastActivity: now.toISOString() })

      return {
        ...sessionData,
        user
      }
    } catch (error) {
      logger.error(`âŒ Failed to validate session ${sessionToken}:`, error)
      return null
    }
  }

  /**
   * é”€æ¯ç”¨æˆ·ä¼šè¯
   * @param {string} sessionToken - ä¼šè¯ä»¤ç‰Œ
   * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸ
   */
  async destroySession(sessionToken) {
    try {
      if (!sessionToken) {
        return false
      }

      const client = this.getClientSafe()
      const result = await client.del(`session:${sessionToken}`)

      if (result > 0) {
        logger.info(`ğŸ”‘ Destroyed session: ${sessionToken.substring(0, 8)}...`)
      }

      return result > 0
    } catch (error) {
      logger.error(`âŒ Failed to destroy session ${sessionToken}:`, error)
      return false
    }
  }

  // ==================== åˆ†ç»„ç®¡ç† (6ä¸ªæ–¹æ³•) ====================

  /**
   * åˆ›å»ºåˆ†ç»„
   * @param {Object} groupData - åˆ†ç»„æ•°æ®
   * @returns {Promise<string>} åˆ†ç»„ID
   */
  async createGroup(groupData) {
    try {
      const client = this.getClientSafe()
      const groupId = require('crypto').randomUUID()
      const now = new Date().toISOString()

      // éªŒè¯å¿…éœ€å­—æ®µ
      if (!groupData.name) {
        throw new Error('Group name is required')
      }

      // æ£€æŸ¥åˆ†ç»„åå”¯ä¸€æ€§
      const existingGroup = await client.get(`group_name:${groupData.name}`)
      if (existingGroup) {
        throw new Error('Group name already exists')
      }

      const group = {
        id: groupId,
        name: groupData.name,
        description: groupData.description || '',
        permissions: JSON.stringify(groupData.permissions || []),
        assignedAccounts: JSON.stringify(
          groupData.assignedAccounts || {
            claudeAccounts: [],
            geminiAccounts: [],
            openaiAccounts: []
          }
        ),
        scheduling: JSON.stringify(
          groupData.scheduling || {
            strategy: 'random',
            weights: {}
          }
        ),
        isActive: 'true',
        createdAt: now,
        updatedAt: now
      }

      // ä½¿ç”¨äº‹åŠ¡ä¿è¯æ•°æ®ä¸€è‡´æ€§
      const pipeline = client.pipeline()
      pipeline.hset(`group:${groupId}`, group)
      pipeline.set(`group_name:${groupData.name}`, groupId)
      await pipeline.exec()

      logger.info(`ğŸ‘¥ Created group: ${groupData.name} (${groupId})`)
      return groupId
    } catch (error) {
      logger.error('âŒ Failed to create group:', error)
      throw error
    }
  }

  /**
   * å°†ç”¨æˆ·åˆ†é…åˆ°åˆ†ç»„
   * @param {string} userId - ç”¨æˆ·ID
   * @param {string} groupId - åˆ†ç»„ID
   * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸ
   */
  async assignUserToGroup(userId, groupId) {
    try {
      const client = this.getClientSafe()

      // éªŒè¯ç”¨æˆ·å’Œåˆ†ç»„å­˜åœ¨
      const user = await this.getUserById(userId)
      const group = await client.hgetall(`group:${groupId}`)

      if (!user) {
        throw new Error('User not found')
      }

      if (!group || Object.keys(group).length === 0) {
        throw new Error('Group not found')
      }

      // æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²åœ¨åˆ†ç»„ä¸­
      if (user.groups.includes(groupId)) {
        return true // å·²ç»åœ¨åˆ†ç»„ä¸­
      }

      // æ›´æ–°ç”¨æˆ·çš„åˆ†ç»„åˆ—è¡¨
      const updatedGroups = [...user.groups, groupId]
      await this.updateUser(userId, { groups: updatedGroups })

      logger.info(`ğŸ‘¥ Assigned user ${user.username} to group ${group.name}`)
      return true
    } catch (error) {
      logger.error(`âŒ Failed to assign user ${userId} to group ${groupId}:`, error)
      throw error
    }
  }

  /**
   * è·å–ç”¨æˆ·çš„åˆ†ç»„
   * @param {string} userId - ç”¨æˆ·ID
   * @returns {Promise<Array>} ç”¨æˆ·åˆ†ç»„åˆ—è¡¨
   */
  async getUserGroups(userId) {
    try {
      const user = await this.getUserById(userId)

      if (!user || !user.groups.length) {
        return []
      }

      const client = this.getClientSafe()
      const groupDetails = []

      for (const groupId of user.groups) {
        const groupData = await client.hgetall(`group:${groupId}`)
        if (groupData && Object.keys(groupData).length > 0) {
          groupDetails.push({
            ...groupData,
            permissions: JSON.parse(groupData.permissions || '[]'),
            assignedAccounts: JSON.parse(groupData.assignedAccounts || '{}'),
            scheduling: JSON.parse(groupData.scheduling || '{}'),
            isActive: groupData.isActive === 'true'
          })
        }
      }

      return groupDetails
    } catch (error) {
      logger.error(`âŒ Failed to get user groups for ${userId}:`, error)
      return []
    }
  }

  /**
   * è·å–åˆ†ç»„çš„åˆ†é…è´¦æˆ·
   * @param {string} groupId - åˆ†ç»„ID
   * @returns {Promise<Object>} åˆ†é…çš„è´¦æˆ·
   */
  async getGroupAccounts(groupId) {
    try {
      const client = this.getClientSafe()
      const groupData = await client.hgetall(`group:${groupId}`)

      if (!groupData || Object.keys(groupData).length === 0) {
        return {}
      }

      return JSON.parse(groupData.assignedAccounts || '{}')
    } catch (error) {
      logger.error(`âŒ Failed to get group accounts for ${groupId}:`, error)
      return {}
    }
  }

  /**
   * æ›´æ–°åˆ†ç»„ä¿¡æ¯
   * @param {string} groupId - åˆ†ç»„ID
   * @param {Object} updateData - æ›´æ–°æ•°æ®
   * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸ
   */
  async updateGroup(groupId, updateData) {
    try {
      const client = this.getClientSafe()
      const existingGroup = await client.hgetall(`group:${groupId}`)

      if (!existingGroup || Object.keys(existingGroup).length === 0) {
        throw new Error('Group not found')
      }

      const now = new Date().toISOString()
      const pipeline = client.pipeline()

      // å‡†å¤‡æ›´æ–°æ•°æ®
      const updates = {
        updatedAt: now
      }

      const allowedFields = [
        'description',
        'permissions',
        'assignedAccounts',
        'scheduling',
        'isActive'
      ]

      for (const [field, value] of Object.entries(updateData)) {
        if (allowedFields.includes(field)) {
          if (field === 'permissions' || field === 'assignedAccounts' || field === 'scheduling') {
            updates[field] = JSON.stringify(value)
          } else if (field === 'isActive') {
            updates[field] = value ? 'true' : 'false'
          } else {
            updates[field] = value
          }
        }
      }

      pipeline.hset(`group:${groupId}`, updates)
      await pipeline.exec()

      logger.info(`ğŸ‘¥ Updated group: ${existingGroup.name} (${groupId})`)
      return true
    } catch (error) {
      logger.error(`âŒ Failed to update group ${groupId}:`, error)
      throw error
    }
  }

  /**
   * åˆ é™¤åˆ†ç»„
   * @param {string} groupId - åˆ†ç»„ID
   * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸ
   */
  async deleteGroup(groupId) {
    try {
      const client = this.getClientSafe()
      const existingGroup = await client.hgetall(`group:${groupId}`)

      if (!existingGroup || Object.keys(existingGroup).length === 0) {
        return false
      }

      const pipeline = client.pipeline()

      // ä»æ‰€æœ‰ç”¨æˆ·ä¸­ç§»é™¤æ­¤åˆ†ç»„
      const userKeys = await client.keys('user:*')
      for (const userKey of userKeys) {
        const userData = await client.hgetall(userKey)
        if (userData.groups) {
          const groups = JSON.parse(userData.groups)
          const updatedGroups = groups.filter((id) => id !== groupId)
          if (groups.length !== updatedGroups.length) {
            pipeline.hset(userKey, {
              groups: JSON.stringify(updatedGroups),
              updatedAt: new Date().toISOString()
            })
          }
        }
      }

      // åˆ é™¤åˆ†ç»„æ•°æ®
      pipeline.del(`group:${groupId}`)
      pipeline.del(`group_name:${existingGroup.name}`)

      await pipeline.exec()

      logger.info(`ğŸ‘¥ Deleted group: ${existingGroup.name} (${groupId})`)
      return true
    } catch (error) {
      logger.error(`âŒ Failed to delete group ${groupId}:`, error)
      throw error
    }
  }

  /**
   * è·å–æ‰€æœ‰åˆ†ç»„
   * @returns {Promise<Array>} åˆ†ç»„åˆ—è¡¨
   */
  async getAllGroups() {
    const keys = await this.client.keys('group:*')
    const groups = []

    for (const key of keys) {
      // è·³è¿‡éåˆ†ç»„key (å¦‚group_name:*)
      if (!key.startsWith('group:') || key.includes('group_name:')) {
        continue
      }

      const groupData = await this.client.hgetall(key)
      if (groupData && Object.keys(groupData).length > 0) {
        groups.push({
          id: key.replace('group:', ''),
          ...groupData,
          permissions: JSON.parse(groupData.permissions || '[]'),
          assignedAccounts: JSON.parse(groupData.assignedAccounts || '{}'),
          scheduling: JSON.parse(groupData.scheduling || '{}'),
          isActive: groupData.isActive === 'true',
          createdAt: groupData.createdAt,
          updatedAt: groupData.updatedAt
        })
      }
    }

    return groups
  }

  // ==================== æ™ºèƒ½è´Ÿè½½å‡è¡¡æ”¯æŒæ–¹æ³• ====================

  /**
   * è®°å½•è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡ï¼ˆç”¨äºæ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼‰
   * @param {string} accountId - è´¦æˆ·ID
   * @param {Object} usageData - ä½¿ç”¨æ•°æ®
   * @returns {Promise<boolean>} æ“ä½œæˆåŠŸè¿”å›true
   */
  async recordAccountUsage(accountId, usageData) {
    try {
      await this.ensureConnection()
      const client = this.getClientSafe()

      const now = Date.now()
      const {
        timestamp = now,
        responseTime = null,
        cost = null,
        status = 'success',
        ...extraData
      } = usageData

      // æ„å»ºä½¿ç”¨è®°å½•
      const usageRecord = {
        accountId,
        timestamp,
        responseTime,
        cost,
        status,
        ...extraData
      }

      // ä½¿ç”¨æœ‰åºé›†åˆå­˜å‚¨ä½¿ç”¨è®°å½•ï¼ŒæŒ‰æ—¶é—´æˆ³æ’åº
      const usageKey = `account_usage:${accountId}`
      await client.zadd(usageKey, timestamp, JSON.stringify(usageRecord))

      // è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ7å¤©ï¼‰
      await client.expire(usageKey, 7 * 24 * 60 * 60)

      // æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆä¿ç•™æœ€è¿‘7å¤©ï¼‰
      const sevenDaysAgo = now - 7 * 24 * 60 * 60 * 1000
      await client.zremrangebyscore(usageKey, '-inf', sevenDaysAgo)

      logger.debug(`ğŸ“ˆ Recorded usage for account ${accountId}`, { responseTime, cost, status })
      return true
    } catch (error) {
      logger.error(`âŒ Failed to record account usage for ${accountId}:`, error)
      throw error
    }
  }

  /**
   * è·å–æŒ‡å®šæ—¶é—´çª—å£å†…çš„è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡
   * @param {string} accountId - è´¦æˆ·ID
   * @param {number} startTime - å¼€å§‹æ—¶é—´æˆ³
   * @param {number} endTime - ç»“æŸæ—¶é—´æˆ³
   * @returns {Promise<Array>} ä½¿ç”¨ç»Ÿè®¡æ•°ç»„
   */
  async getAccountUsageInTimeWindow(accountId, startTime, endTime) {
    try {
      await this.ensureConnection()
      const client = this.getClientSafe()

      const usageKey = `account_usage:${accountId}`

      // ä»æœ‰åºé›†åˆä¸­è·å–æŒ‡å®šæ—¶é—´çª—å£çš„æ•°æ®
      const usageRecords = await client.zrangebyscore(usageKey, startTime, endTime)

      const parsedRecords = usageRecords
        .map((record) => {
          try {
            return JSON.parse(record)
          } catch (parseError) {
            logger.warn(`âš ï¸ Failed to parse usage record for account ${accountId}:`, parseError)
            return null
          }
        })
        .filter((record) => record !== null)

      logger.debug(
        `ğŸ“Š Retrieved ${parsedRecords.length} usage records for account ${accountId} in time window`
      )
      return parsedRecords
    } catch (error) {
      logger.error(`âŒ Failed to get account usage for ${accountId}:`, error)
      // è¿”å›ç©ºæ•°ç»„è€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯ï¼Œä»¥ä¾¿è´Ÿè½½å‡è¡¡å™¨å¯ä»¥ç»§ç»­å·¥ä½œ
      return []
    }
  }

  /**
   * è·å–è´¦æˆ·æ€§èƒ½æ‘˜è¦ç»Ÿè®¡
   * @param {string} accountId - è´¦æˆ·ID
   * @param {number} timeWindow - æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤5åˆ†é’Ÿ
   * @returns {Promise<Object>} æ€§èƒ½ç»Ÿè®¡æ‘˜è¦
   */
  async getAccountPerformanceSummary(accountId, timeWindow = 300000) {
    try {
      const now = Date.now()
      const windowStart = now - timeWindow

      const usageRecords = await this.getAccountUsageInTimeWindow(accountId, windowStart, now)

      if (usageRecords.length === 0) {
        return {
          accountId,
          timeWindow,
          totalRequests: 0,
          errorCount: 0,
          avgResponseTime: 0,
          avgCost: 0,
          successRate: 1.0,
          lastUsedAt: null
        }
      }

      const totalRequests = usageRecords.length
      const errorCount = usageRecords.filter((record) => record.status === 'error').length
      const successfulRequests = usageRecords.filter((record) => record.status === 'success')

      // è®¡ç®—å¹³å‡å“åº”æ—¶é—´ï¼ˆä»…æˆåŠŸè¯·æ±‚ï¼‰
      const responseTimeSamples = successfulRequests
        .filter((record) => record.responseTime && record.responseTime > 0)
        .map((record) => record.responseTime)

      const avgResponseTime =
        responseTimeSamples.length > 0
          ? responseTimeSamples.reduce((sum, time) => sum + time, 0) / responseTimeSamples.length
          : 0

      // è®¡ç®—å¹³å‡æˆæœ¬ï¼ˆä»…æˆåŠŸè¯·æ±‚ï¼‰
      const costSamples = successfulRequests
        .filter((record) => record.cost && record.cost > 0)
        .map((record) => record.cost)

      const avgCost =
        costSamples.length > 0
          ? costSamples.reduce((sum, cost) => sum + cost, 0) / costSamples.length
          : 0

      // è®¡ç®—æˆåŠŸç‡
      const successRate = totalRequests > 0 ? (totalRequests - errorCount) / totalRequests : 1.0

      // æœ€åä½¿ç”¨æ—¶é—´
      const lastUsedAt = Math.max(...usageRecords.map((record) => record.timestamp))

      const summary = {
        accountId,
        timeWindow,
        totalRequests,
        errorCount,
        avgResponseTime: Math.round(avgResponseTime),
        avgCost: parseFloat(avgCost.toFixed(6)),
        successRate: parseFloat(successRate.toFixed(4)),
        lastUsedAt: new Date(lastUsedAt).toISOString()
      }

      logger.debug(`ğŸ“Š Performance summary for account ${accountId}:`, summary)
      return summary
    } catch (error) {
      logger.error(`âŒ Failed to get performance summary for ${accountId}:`, error)
      // è¿”å›é»˜è®¤ç»Ÿè®¡ä¿¡æ¯
      return {
        accountId,
        timeWindow,
        totalRequests: 0,
        errorCount: 0,
        avgResponseTime: 0,
        avgCost: 0,
        successRate: 1.0,
        lastUsedAt: null
      }
    }
  }

  /**
   * æ‰¹é‡è·å–å¤šä¸ªè´¦æˆ·çš„æ€§èƒ½æ‘˜è¦
   * @param {Array<string>} accountIds - è´¦æˆ·IDåˆ—è¡¨
   * @param {number} timeWindow - æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰
   * @returns {Promise<Object>} è´¦æˆ·IDåˆ°æ€§èƒ½æ‘˜è¦çš„æ˜ å°„
   */
  async getMultipleAccountPerformanceSummaries(accountIds, timeWindow = 300000) {
    try {
      const summaries = {}

      // å¹¶è¡Œè·å–æ‰€æœ‰è´¦æˆ·çš„æ€§èƒ½æ‘˜è¦
      const promises = accountIds.map(async (accountId) => {
        try {
          const summary = await this.getAccountPerformanceSummary(accountId, timeWindow)
          return { accountId, summary }
        } catch (error) {
          logger.warn(`âš ï¸ Failed to get performance summary for account ${accountId}:`, error)
          return {
            accountId,
            summary: {
              accountId,
              timeWindow,
              totalRequests: 0,
              errorCount: 0,
              avgResponseTime: 0,
              avgCost: 0,
              successRate: 1.0,
              lastUsedAt: null
            }
          }
        }
      })

      const results = await Promise.all(promises)

      results.forEach(({ accountId, summary }) => {
        summaries[accountId] = summary
      })

      logger.debug(`ğŸ“Š Retrieved performance summaries for ${accountIds.length} accounts`)
      return summaries
    } catch (error) {
      logger.error('âŒ Failed to get multiple account performance summaries:', error)
      // è¿”å›ç©ºå¯¹è±¡è€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
      return {}
    }
  }

  /**
   * æ¸…ç†è¿‡æœŸçš„è´¦æˆ·ä½¿ç”¨æ•°æ®
   * @param {number} maxAge - æœ€å¤§ä¿å­˜æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤7å¤©
   * @returns {Promise<number>} æ¸…ç†çš„è®°å½•æ•°
   */
  async cleanupAccountUsageData(maxAge = 7 * 24 * 60 * 60 * 1000) {
    try {
      await this.ensureConnection()
      const client = this.getClientSafe()

      const cutoffTime = Date.now() - maxAge
      const usageKeys = await client.keys('account_usage:*')

      let totalCleaned = 0
      for (const key of usageKeys) {
        const cleaned = await client.zremrangebyscore(key, '-inf', cutoffTime)
        totalCleaned += cleaned

        // å¦‚æœé”®ä¸ºç©ºï¼Œåˆ é™¤å®ƒ
        const remainingCount = await client.zcard(key)
        if (remainingCount === 0) {
          await client.del(key)
        }
      }

      logger.info(
        `ğŸ§¹ Cleaned up ${totalCleaned} expired usage records from ${usageKeys.length} accounts`
      )
      return totalCleaned
    } catch (error) {
      logger.error('âŒ Failed to cleanup account usage data:', error)
      return 0
    }
  }
}

// å¯¼å‡ºæ—¶åŒºè¾…åŠ©å‡½æ•°
RedisAdapter.getDateInTimezone = getDateInTimezone
RedisAdapter.getDateStringInTimezone = getDateStringInTimezone
RedisAdapter.getHourInTimezone = getHourInTimezone

module.exports = RedisAdapter
