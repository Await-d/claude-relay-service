/**
 * @fileoverview Redisæ•°æ®åº“é€‚é…å™¨å®ç°
 *
 * ç»§æ‰¿DatabaseAdapteræŠ½è±¡åŸºç±»ï¼Œå®ç°Redisç‰¹å®šçš„æ•°æ®åº“æ“ä½œ
 * ä»ç°æœ‰redis.jsè¿ç§»æ–¹æ³•ï¼Œä¿æŒå®Œå…¨çš„å‘åå…¼å®¹æ€§
 *
 * @author Claude Code
 * @version 1.0.0
 */

const Redis = require('ioredis')
const config = require('../../../config/config')
const logger = require('../../utils/logger')
const DatabaseAdapter = require('./DatabaseAdapter')

// æ—¶åŒºè¾…åŠ©å‡½æ•°
// æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°çš„ç›®çš„æ˜¯è·å–æŸä¸ªæ—¶é—´ç‚¹åœ¨ç›®æ ‡æ—¶åŒºçš„"æœ¬åœ°"è¡¨ç¤º
// ä¾‹å¦‚ï¼šUTCæ—¶é—´ 2025-07-30 01:00:00 åœ¨ UTC+8 æ—¶åŒºè¡¨ç¤ºä¸º 2025-07-30 09:00:00
function getDateInTimezone(date = new Date()) {
  const offset = config.system.timezoneOffset || 8 // é»˜è®¤UTC+8

  // æ–¹æ³•ï¼šåˆ›å»ºä¸€ä¸ªåç§»åçš„Dateå¯¹è±¡ï¼Œä½¿å…¶getUTCXXXæ–¹æ³•è¿”å›ç›®æ ‡æ—¶åŒºçš„å€¼
  // è¿™æ ·æˆ‘ä»¬å¯ä»¥ç”¨getUTCFullYear()ç­‰æ–¹æ³•è·å–ç›®æ ‡æ—¶åŒºçš„å¹´æœˆæ—¥æ—¶åˆ†ç§’
  const offsetMs = offset * 3600000 // æ—¶åŒºåç§»çš„æ¯«ç§’æ•°
  const adjustedTime = new Date(date.getTime() + offsetMs)

  return adjustedTime
}

// è·å–é…ç½®æ—¶åŒºçš„æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
function getDateStringInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)
  // ä½¿ç”¨UTCæ–¹æ³•è·å–åç§»åçš„ï¿½ï¿½æœŸéƒ¨åˆ†
  return `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}-${String(tzDate.getUTCDate()).padStart(2, '0')}`
}

// è·å–é…ç½®æ—¶åŒºçš„å°æ—¶ (0-23)
function getHourInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)
  return tzDate.getUTCHours()
}

/**
 * Redisæ•°æ®åº“é€‚é…å™¨
 *
 * å®ç°DatabaseAdapteræ¥å£ï¼Œæä¾›Redisç‰¹å®šçš„æ•°æ®åº“æ“ä½œ
 *
 * ç‰¹æ€§:
 * - å®Œå…¨ç»§æ‰¿è‡ªDatabaseAdapteråŸºç±»
 * - ä»redis.jsè¿ç§»æ‰€æœ‰æ–¹æ³•é€»è¾‘ï¼Œä¿æŒ100%å…¼å®¹æ€§
 * - ä¿ç•™ç°æœ‰çš„è¿æ¥ç®¡ç†å’Œé”™è¯¯å¤„ç†æœºåˆ¶
 * - ç»´æŒæ‰€æœ‰ç°æœ‰çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
 */
class RedisAdapter extends DatabaseAdapter {
  constructor() {
    super()
    this.client = null
    this._reconnecting = false // é‡è¿é”æ ‡å¿—
  }

  // ==================== è¿æ¥ç®¡ç† (4ä¸ªæ–¹æ³•) ====================

  /**
   * è¿æ¥åˆ°Redisæ•°æ®åº“
   * @returns {Promise<any>} Rediså®¢æˆ·ç«¯å®ä¾‹
   * @throws {Error} è¿æ¥å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async connect() {
    try {
      // å¦‚æœå·²ç»è¿æ¥ä¸”è¿æ¥çŠ¶æ€æ­£å¸¸ï¼Œåˆ™ç›´æ¥è¿”å›
      if (this.client && this.isConnected && this.client.status === 'ready') {
        return this.client
      }

      // å¦‚æœæœ‰æ—§çš„clientï¼Œå…ˆæ¸…ç†
      if (this.client) {
        try {
          // ç§»é™¤æ‰€æœ‰äº‹ä»¶ç›‘å¬å™¨ï¼Œé¿å…é‡å¤ç»‘å®š
          this.client.removeAllListeners()
          // å®‰å…¨æ–­å¼€è¿æ¥
          if (this.client.status !== 'end') {
            await this.client.quit()
          }
        } catch (error) {
          // å¿½ç•¥quité”™è¯¯
          logger.debug('Failed to quit old Redis client:', error)
        }
      }

      this.client = new Redis({
        host: config.redis.host,
        port: config.redis.port,
        password: config.redis.password,
        db: config.redis.db,
        retryDelayOnFailover: config.redis.retryDelayOnFailover,
        maxRetriesPerRequest: config.redis.maxRetriesPerRequest,
        lazyConnect: config.redis.lazyConnect,
        tls: config.redis.enableTLS ? {} : false,
        // æ·»åŠ è¿æ¥ä¿æ´»å’Œé‡è¿é…ç½®
        keepAlive: 30000, // 30ç§’ä¿æ´»
        connectTimeout: 10000, // 10ç§’è¿æ¥è¶…æ—¶
        commandTimeout: 5000, // 5ç§’å‘½ä»¤è¶…æ—¶
        retryDelayOnClusterDown: 300 // é›†ç¾¤æ•…éšœé‡è¯•å»¶è¿Ÿ
      })

      // ä½¿ç”¨onceè€Œä¸æ˜¯onï¼Œé¿å…é‡å¤ç»‘å®šäº‹ä»¶ç›‘å¬å™¨
      this.client.once('connect', () => {
        this.isConnected = true
        logger.info('ğŸ”— Redis connected successfully')
      })

      this.client.on('error', (err) => {
        // é¿å…é¢‘ç¹çš„é”™è¯¯æ—¥å¿—
        if (this.isConnected) {
          this.isConnected = false
          logger.error('âŒ Redis connection error:', err)
        }
      })

      this.client.on('close', () => {
        // åªåœ¨è¿æ¥çŠ¶æ€æ”¹å˜æ—¶è®°å½•æ—¥å¿—
        if (this.isConnected) {
          this.isConnected = false
          logger.warn('âš ï¸ Redis connection closed')
        }
      })

      // æ·»åŠ é‡è¿æˆåŠŸç›‘å¬å™¨
      this.client.on('ready', () => {
        if (!this.isConnected) {
          this.isConnected = true
          logger.info('ğŸ”„ Redis reconnected successfully')
        }
      })

      await this.client.connect()
      return this.client
    } catch (error) {
      logger.error('ğŸ’¥ Failed to connect to Redis:', error)
      throw error
    }
  }

  /**
   * æ–­å¼€Redisè¿æ¥
   * @returns {Promise<void>}
   */
  async disconnect() {
    if (this.client) {
      await this.client.quit()
      this.isConnected = false
      logger.info('ğŸ‘‹ Redis disconnected')
    }
  }

  /**
   * è·å–Rediså®¢æˆ·ç«¯å®ä¾‹ï¼ˆå¯èƒ½ä¸ºnullï¼‰
   * @returns {any|null} Rediså®¢æˆ·ç«¯å®ä¾‹æˆ–null
   */
  getClient() {
    // æ£€æŸ¥å®¢æˆ·ç«¯å­˜åœ¨æ€§å’Œè¿æ¥çŠ¶æ€
    if (!this.client || !this.isConnected || this.client.status !== 'ready') {
      // é¿å…é¢‘ç¹çš„è­¦å‘Šæ—¥å¿—ï¼Œåªåœ¨çŠ¶æ€çœŸæ­£æ”¹å˜æ—¶è®°å½•
      if (this.isConnected && this.client && this.client.status !== 'ready') {
        logger.warn('âš ï¸ Redis client status is not ready:', this.client.status)
      } else if (!this.client) {
        logger.warn('âš ï¸ Redis client is not initialized')
      }
      return null
    }
    return this.client
  }

  /**
   * å®‰å…¨è·å–Rediså®¢æˆ·ç«¯ï¼ˆå¿…é¡»å­˜åœ¨ï¼‰
   * @returns {any} Rediså®¢æˆ·ç«¯å®ä¾‹
   * @throws {Error} å®¢æˆ·ç«¯ä¸å­˜åœ¨æ—¶æŠ›å‡ºé”™è¯¯
   */
  getClientSafe() {
    const client = this.getClient()
    if (!client) {
      throw new Error('Redis client is not available')
    }
    return client
  }

  /**
   * è‡ªåŠ¨é‡è¿å¹¶è·å–å®¢æˆ·ç«¯ï¼ˆæ–°å¢ï¼‰
   * @returns {Promise<any>} Rediså®¢æˆ·ç«¯å®ä¾‹
   * @throws {Error} é‡è¿å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async getClientWithReconnect() {
    // å¦‚æœè¿æ¥æ­£å¸¸ä¸”çŠ¶æ€ä¸ºreadyï¼Œç›´æ¥è¿”å›
    if (this.client && this.isConnected && this.client.status === 'ready') {
      return this.client
    }

    // é¿å…å¹¶å‘é‡è¿ï¼Œä½¿ç”¨ç®€å•çš„é”æœºåˆ¶
    if (this._reconnecting) {
      logger.debug('â³ Reconnection already in progress, waiting...')
      // ç­‰å¾…é‡è¿å®Œæˆ
      let attempts = 0
      while (this._reconnecting && attempts < 50) {
        // æœ€å¤šç­‰å¾…5ç§’
        await new Promise((resolve) => setTimeout(resolve, 100))
        attempts++
      }

      if (this.client && this.isConnected && this.client.status === 'ready') {
        return this.client
      }
    }

    this._reconnecting = true
    logger.warn('âš ï¸ Redis connection lost, attempting to reconnect...')

    try {
      // å°è¯•é‡è¿
      await this.connect()
      this._reconnecting = false
      return this.client
    } catch (error) {
      this._reconnecting = false
      logger.error('ğŸ’¥ Failed to reconnect to Redis:', error)
      throw new Error(`Redis reconnection failed: ${error.message}`)
    }
  }

  /**
   * Ping RedisæœåŠ¡å™¨æ£€æŸ¥è¿æ¥çŠ¶æ€
   * @returns {Promise<string>} è¿”å›'PONG'è¡¨ç¤ºè¿æ¥æ­£å¸¸
   * @throws {Error} è¿æ¥å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async ping() {
    try {
      const client = this.getClientSafe()
      const result = await client.ping()
      return result
    } catch (error) {
      logger.error('ğŸ’¥ Redis ping failed:', error)
      throw error
    }
  }

  // Redisç‰ˆæœ¬å…¼å®¹çš„hsetæ–¹æ³•ï¼ˆæ”¯æŒå¤šå­—æ®µè®¾ç½®ï¼‰
  async hsetCompat(key, ...args) {
    const client = await this.getClientWithReconnect()

    // å¦‚æœå‚æ•°æ˜¯å¯¹è±¡å½¢å¼ hset(key, {field1: value1, field2: value2})
    if (args.length === 1 && typeof args[0] === 'object' && args[0] !== null) {
      const obj = args[0]
      const fields = Object.keys(obj)

      // å¯¹äºä½ç‰ˆæœ¬Redisï¼Œä½¿ç”¨pipelineé€ä¸€è®¾ç½®å­—æ®µ
      const pipeline = client.pipeline()
      for (const field of fields) {
        pipeline.hset(key, field, obj[field])
      }
      return await pipeline.exec()
    }

    // å…¶ä»–æƒ…å†µç›´æ¥è°ƒç”¨åŸç”Ÿhset
    return await client.hset(key, ...args)
  }

  // ==================== RedisåŸºç¡€æ“ä½œæ–¹æ³• ====================

  /**
   * Redis keyså‘½ä»¤ - è·å–åŒ¹é…æ¨¡å¼çš„æ‰€æœ‰é”®
   * @param {string} pattern åŒ¹é…æ¨¡å¼
   * @returns {Promise<Array>} é”®æ•°ç»„
   */
  async keys(pattern) {
    const client = this.getClientSafe()
    return await client.keys(pattern)
  }

  /**
   * Redis getå‘½ä»¤ - è·å–å­—ç¬¦ä¸²å€¼
   * @param {string} key é”®å
   * @returns {Promise<string>} å€¼
   */
  async get(key) {
    const client = this.getClientSafe()
    return await client.get(key)
  }

  /**
   * Redis setå‘½ä»¤ - è®¾ç½®å­—ç¬¦ä¸²å€¼
   * @param {string} key é”®å
   * @param {string} value å€¼
   * @param {string} mode è®¾ç½®æ¨¡å¼ (EX, PXç­‰)
   * @param {number} time è¿‡æœŸæ—¶é—´
   * @returns {Promise<string>} ç»“æœ
   */
  async set(key, value, ...args) {
    const client = this.getClientSafe()
    return await client.set(key, value, ...args)
  }

  /**
   * Redis delå‘½ä»¤ - åˆ é™¤é”®
   * @param {...string} keys è¦åˆ é™¤çš„é”®
   * @returns {Promise<number>} åˆ é™¤çš„é”®æ•°é‡
   */
  async del(...keys) {
    const client = this.getClientSafe()
    return await client.del(...keys)
  }

  /**
   * Redis hgetå‘½ä»¤ - è·å–å“ˆå¸Œå­—æ®µå€¼
   * @param {string} key é”®å
   * @param {string} field å­—æ®µå
   * @returns {Promise<string>} å­—æ®µå€¼
   */
  async hget(key, field) {
    const client = this.getClientSafe()
    return await client.hget(key, field)
  }

  /**
   * Redis hsetå‘½ä»¤ - è®¾ç½®å“ˆå¸Œå­—æ®µå€¼
   * @param {string} key é”®å
   * @param {...any} args å­—æ®µå’Œå€¼
   * @returns {Promise<number>} è®¾ç½®çš„å­—æ®µæ•°é‡
   */
  async hset(key, ...args) {
    const client = this.getClientSafe()
    return await client.hset(key, ...args)
  }

  /**
   * Redis hgetallå‘½ä»¤ - è·å–æ‰€æœ‰å“ˆå¸Œå­—æ®µå’Œå€¼
   * @param {string} key é”®å
   * @returns {Promise<Object>} å“ˆå¸Œå¯¹è±¡
   */
  async hgetall(key) {
    const client = this.getClientSafe()
    return await client.hgetall(key)
  }

  /**
   * Redis hdelå‘½ä»¤ - åˆ é™¤å“ˆå¸Œå­—æ®µ
   * @param {string} key é”®å
   * @param {...string} fields å­—æ®µå
   * @returns {Promise<number>} åˆ é™¤çš„å­—æ®µæ•°é‡
   */
  async hdel(key, ...fields) {
    const client = this.getClientSafe()
    return await client.hdel(key, ...fields)
  }

  /**
   * Redis hmsetå‘½ä»¤ - è®¾ç½®å¤šä¸ªå“ˆå¸Œå­—æ®µ (ä¸ºäº†å…¼å®¹æ€§)
   * @param {string} key é”®å
   * @param {Object|Array} hash å“ˆå¸Œæ•°æ®
   * @returns {Promise<string>} ç»“æœ
   */
  async hmset(key, hash) {
    const client = this.getClientSafe()
    return await client.hmset(key, hash)
  }

  /**
   * Redis expireå‘½ä»¤ - è®¾ç½®é”®è¿‡æœŸæ—¶é—´
   * @param {string} key é”®å
   * @param {number} seconds è¿‡æœŸç§’æ•°
   * @returns {Promise<number>} ç»“æœ
   */
  async expire(key, seconds) {
    const client = this.getClientSafe()
    return await client.expire(key, seconds)
  }

  /**
   * Redis incrå‘½ä»¤ - é€’å¢æ•°å€¼
   * @param {string} key é”®å
   * @returns {Promise<number>} é€’å¢åçš„å€¼
   */
  async incr(key) {
    const client = this.getClientSafe()
    return await client.incr(key)
  }

  /**
   * Redis decrå‘½ä»¤ - é€’å‡æ•°å€¼
   * @param {string} key é”®å
   * @returns {Promise<number>} é€’å‡åçš„å€¼
   */
  async decr(key) {
    const client = this.getClientSafe()
    return await client.decr(key)
  }

  /**
   * Redis typeå‘½ä»¤ - è·å–é”®çš„æ•°æ®ç±»å‹
   * @param {string} key é”®å
   * @returns {Promise<string>} æ•°æ®ç±»å‹
   */
  async type(key) {
    const client = this.getClientSafe()
    return await client.type(key)
  }

  // ==================== API Key æ“ä½œ (5ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®API Keyæ•°æ®
   * @param {string} keyId API Key ID
   * @param {Object} keyData API Keyæ•°æ®å¯¹è±¡
   * @param {string|null} hashedKey å“ˆå¸Œåçš„Keyå€¼ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾
   * @returns {Promise<void>}
   */
  async setApiKey(keyId, keyData, hashedKey = null) {
    const key = `apikey:${keyId}`
    const client = this.getClientSafe()

    // ç»´æŠ¤å“ˆå¸Œæ˜ å°„è¡¨ï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
    // hashedKeyå‚æ•°æ˜¯å®é™…çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»ºç«‹æ˜ å°„
    if (hashedKey) {
      await client.hset('apikey:hash_map', hashedKey, keyId)
    }

    await this.hsetCompat(key, keyData)
    await client.expire(key, 86400 * 365) // 1å¹´è¿‡æœŸ
  }

  /**
   * è·å–API Keyæ•°æ®
   * @param {string} keyId API Key ID
   * @returns {Promise<Object>} API Keyæ•°æ®å¯¹è±¡
   */
  async getApiKey(keyId) {
    const key = `apikey:${keyId}`
    return await this.client.hgetall(key)
  }

  /**
   * åˆ é™¤API Key
   * @param {string} keyId API Key ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteApiKey(keyId) {
    const key = `apikey:${keyId}`

    // è·å–è¦åˆ é™¤çš„API Keyå“ˆå¸Œå€¼ï¼Œä»¥ä¾¿ä»æ˜ å°„è¡¨ä¸­ç§»é™¤
    const keyData = await this.client.hgetall(key)
    if (keyData && keyData.apiKey) {
      // keyData.apiKeyç°åœ¨å­˜å‚¨çš„æ˜¯å“ˆå¸Œå€¼ï¼Œç›´æ¥ä»æ˜ å°„è¡¨åˆ é™¤
      await this.client.hdel('apikey:hash_map', keyData.apiKey)
    }

    return await this.client.del(key)
  }

  /**
   * è·å–æ‰€æœ‰API Keys
   * @returns {Promise<Array>} API Keyåˆ—è¡¨
   */
  async getAllApiKeys() {
    const keys = await this.client.keys('apikey:*')
    const apiKeys = []
    for (const key of keys) {
      // è¿‡æ»¤æ‰hash_mapï¼Œå®ƒä¸æ˜¯çœŸæ­£çš„API Key
      if (key === 'apikey:hash_map') {
        continue
      }

      const keyData = await this.client.hgetall(key)
      if (keyData && Object.keys(keyData).length > 0) {
        apiKeys.push({ id: key.replace('apikey:', ''), ...keyData })
      }
    }
    return apiKeys
  }

  /**
   * é€šè¿‡å“ˆå¸Œå€¼æŸ¥æ‰¾API Keyï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
   * @param {string} hashedKey å“ˆå¸Œåçš„Keyå€¼
   * @returns {Promise<Object|null>} API Keyæ•°æ®å¯¹è±¡æˆ–null
   */
  async findApiKeyByHash(hashedKey) {
    // ä½¿ç”¨åå‘æ˜ å°„è¡¨ï¼šhash -> keyId
    const keyId = await this.client.hget('apikey:hash_map', hashedKey)
    if (!keyId) {
      return null
    }

    const keyData = await this.client.hgetall(`apikey:${keyId}`)
    if (keyData && Object.keys(keyData).length > 0) {
      return { id: keyId, ...keyData }
    }

    // å¦‚æœæ•°æ®ä¸å­˜åœ¨ï¼Œæ¸…ç†æ˜ å°„è¡¨
    await this.client.hdel('apikey:hash_map', hashedKey)
    return null
  }

  // ==================== ä½¿ç”¨ç»Ÿè®¡æ“ä½œ (9ä¸ªæ–¹æ³•) ====================

  /**
   * æ ‡å‡†åŒ–æ¨¡å‹åç§°ï¼Œç”¨äºç»Ÿè®¡èšåˆ
   * @param {string} model åŸå§‹æ¨¡å‹åç§°
   * @returns {string} æ ‡å‡†åŒ–åçš„æ¨¡å‹åç§°
   * @private
   */
  _normalizeModelName(model) {
    if (!model || model === 'unknown') {
      return model
    }

    // å¯¹äºBedrockæ¨¡å‹ï¼Œå»æ‰åŒºåŸŸå‰ç¼€è¿›è¡Œç»Ÿä¸€
    if (model.includes('.anthropic.') || model.includes('.claude')) {
      // åŒ¹é…æ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼šregion.anthropic.model-name-v1:0 -> claude-model-name
      // æ”¯æŒæ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼Œå¦‚ï¼šus-east-1, eu-west-1, ap-southeast-1, ca-central-1ç­‰
      let normalized = model.replace(/^[a-z0-9-]+\./, '') // å»æ‰ä»»ä½•åŒºåŸŸå‰ç¼€ï¼ˆæ›´é€šç”¨ï¼‰
      normalized = normalized.replace('anthropic.', '') // å»æ‰anthropicå‰ç¼€
      normalized = normalized.replace(/-v\d+:\d+$/, '') // å»æ‰ç‰ˆæœ¬åç¼€ï¼ˆå¦‚-v1:0, -v2:1ç­‰ï¼‰
      return normalized
    }

    // å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œå»æ‰å¸¸è§çš„ç‰ˆæœ¬åç¼€
    return model.replace(/-v\d+:\d+$|:latest$|\[\d+[a-zA-Z]*\]$/, '')
  }

  /**
   * å¢åŠ Tokenä½¿ç”¨ç»Ÿè®¡ï¼ˆæ”¯æŒå¤šç§ç¼“å­˜Tokenç±»å‹ï¼‰
   * @param {string} keyId API Key ID
   * @param {number} tokens æ€»Tokenæ•°
   * @param {number} inputTokens è¾“å…¥Tokenæ•°
   * @param {number} outputTokens è¾“å‡ºTokenæ•°
   * @param {number} cacheCreateTokens ç¼“å­˜åˆ›å»ºTokenæ•°
   * @param {number} cacheReadTokens ç¼“å­˜è¯»å–Tokenæ•°
   * @param {string} model æ¨¡å‹åç§°
   * @param {number} ephemeral5mTokens 5åˆ†é’Ÿç¼“å­˜Tokenæ•°
   * @param {number} ephemeral1hTokens 1å°æ—¶ç¼“å­˜Tokenæ•°
   * @returns {Promise<void>}
   */
  async incrementTokenUsage(
    keyId,
    tokens,
    inputTokens = 0,
    outputTokens = 0,
    cacheCreateTokens = 0,
    cacheReadTokens = 0,
    model = 'unknown',
    ephemeral5mTokens = 0, // æ–°å¢ï¼š5åˆ†é’Ÿç¼“å­˜ tokens
    ephemeral1hTokens = 0 // æ–°å¢ï¼š1å°æ—¶ç¼“å­˜ tokens
  ) {
    const key = `usage:${keyId}`
    const now = new Date()
    const today = getDateStringInTimezone(now)
    const tzDate = getDateInTimezone(now)
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const currentHour = `${today}:${String(getHourInTimezone(now)).padStart(2, '0')}` // æ–°å¢å°æ—¶çº§åˆ«

    const daily = `usage:daily:${keyId}:${today}`
    const monthly = `usage:monthly:${keyId}:${currentMonth}`
    const hourly = `usage:hourly:${keyId}:${currentHour}` // æ–°å¢å°æ—¶çº§åˆ«key

    // æ ‡å‡†åŒ–æ¨¡å‹åç”¨äºç»Ÿè®¡èšåˆ
    const normalizedModel = this._normalizeModelName(model)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡çš„é”®
    const modelDaily = `usage:model:daily:${normalizedModel}:${today}`
    const modelMonthly = `usage:model:monthly:${normalizedModel}:${currentMonth}`
    const modelHourly = `usage:model:hourly:${normalizedModel}:${currentHour}` // æ–°å¢æ¨¡å‹å°æ—¶çº§åˆ«

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡
    const keyModelDaily = `usage:${keyId}:model:daily:${normalizedModel}:${today}`
    const keyModelMonthly = `usage:${keyId}:model:monthly:${normalizedModel}:${currentMonth}`
    const keyModelHourly = `usage:${keyId}:model:hourly:${normalizedModel}:${currentHour}` // æ–°å¢API Keyæ¨¡å‹å°æ—¶çº§åˆ«

    // æ–°å¢ï¼šç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡
    const minuteTimestamp = Math.floor(now.getTime() / 60000)
    const systemMinuteKey = `system:metrics:minute:${minuteTimestamp}`

    // æ™ºèƒ½å¤„ç†è¾“å…¥è¾“å‡ºtokenåˆ†é…
    const finalInputTokens = inputTokens || 0
    const finalOutputTokens = outputTokens || (finalInputTokens > 0 ? 0 : tokens)
    const finalCacheCreateTokens = cacheCreateTokens || 0
    const finalCacheReadTokens = cacheReadTokens || 0

    // é‡æ–°è®¡ç®—çœŸå®çš„æ€»tokenæ•°ï¼ˆåŒ…æ‹¬ç¼“å­˜tokenï¼‰
    const totalTokens =
      finalInputTokens + finalOutputTokens + finalCacheCreateTokens + finalCacheReadTokens
    // æ ¸å¿ƒtokenï¼ˆä¸åŒ…æ‹¬ç¼“å­˜ï¼‰- ç”¨äºä¸å†å²æ•°æ®å…¼å®¹
    const coreTokens = finalInputTokens + finalOutputTokens

    // ä½¿ç”¨Pipelineä¼˜åŒ–æ€§èƒ½
    const pipeline = this.client.pipeline()

    // ç°æœ‰çš„ç»Ÿè®¡ä¿æŒä¸å˜
    // æ ¸å¿ƒtokenç»Ÿè®¡ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    pipeline.hincrby(key, 'totalTokens', coreTokens)
    pipeline.hincrby(key, 'totalInputTokens', finalInputTokens)
    pipeline.hincrby(key, 'totalOutputTokens', finalOutputTokens)
    // ç¼“å­˜tokenç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
    pipeline.hincrby(key, 'totalCacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(key, 'totalCacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(key, 'totalAllTokens', totalTokens) // åŒ…å«æ‰€æœ‰ç±»å‹çš„æ€»token
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
    pipeline.hincrby(key, 'totalEphemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(key, 'totalEphemeral1hTokens', ephemeral1hTokens)
    // è¯·æ±‚è®¡æ•°
    pipeline.hincrby(key, 'totalRequests', 1)

    // æ¯æ—¥ç»Ÿè®¡
    pipeline.hincrby(daily, 'tokens', coreTokens)
    pipeline.hincrby(daily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(daily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(daily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(daily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(daily, 'allTokens', totalTokens)
    pipeline.hincrby(daily, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(daily, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(daily, 'ephemeral1hTokens', ephemeral1hTokens)

    // æ¯æœˆç»Ÿè®¡
    pipeline.hincrby(monthly, 'tokens', coreTokens)
    pipeline.hincrby(monthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(monthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(monthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(monthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(monthly, 'allTokens', totalTokens)
    pipeline.hincrby(monthly, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(monthly, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(monthly, 'ephemeral1hTokens', ephemeral1hTokens)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
    pipeline.hincrby(modelDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelDaily, 'allTokens', totalTokens)
    pipeline.hincrby(modelDaily, 'requests', 1)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
    pipeline.hincrby(modelMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelMonthly, 'allTokens', totalTokens)
    pipeline.hincrby(modelMonthly, 'requests', 1)

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
    pipeline.hincrby(keyModelDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelDaily, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelDaily, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(keyModelDaily, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(keyModelDaily, 'ephemeral1hTokens', ephemeral1hTokens)

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
    pipeline.hincrby(keyModelMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelMonthly, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelMonthly, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(keyModelMonthly, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(keyModelMonthly, 'ephemeral1hTokens', ephemeral1hTokens)

    // å°æ—¶çº§åˆ«ç»Ÿè®¡
    pipeline.hincrby(hourly, 'tokens', coreTokens)
    pipeline.hincrby(hourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(hourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(hourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(hourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(hourly, 'allTokens', totalTokens)
    pipeline.hincrby(hourly, 'requests', 1)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
    pipeline.hincrby(modelHourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelHourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelHourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelHourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelHourly, 'allTokens', totalTokens)
    pipeline.hincrby(modelHourly, 'requests', 1)

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
    pipeline.hincrby(keyModelHourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelHourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelHourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelHourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelHourly, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelHourly, 'requests', 1)

    // æ–°å¢ï¼šç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡
    pipeline.hincrby(systemMinuteKey, 'requests', 1)
    pipeline.hincrby(systemMinuteKey, 'totalTokens', totalTokens)
    pipeline.hincrby(systemMinuteKey, 'inputTokens', finalInputTokens)
    pipeline.hincrby(systemMinuteKey, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(systemMinuteKey, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(systemMinuteKey, 'cacheReadTokens', finalCacheReadTokens)

    // è®¾ç½®è¿‡æœŸæ—¶é—´
    pipeline.expire(daily, 86400 * 32) // 32å¤©è¿‡æœŸ
    pipeline.expire(monthly, 86400 * 365) // 1å¹´è¿‡æœŸ
    pipeline.expire(hourly, 86400 * 7) // å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ
    pipeline.expire(modelDaily, 86400 * 32) // æ¨¡å‹æ¯æ—¥ç»Ÿè®¡32å¤©è¿‡æœŸ
    pipeline.expire(modelMonthly, 86400 * 365) // æ¨¡å‹æ¯æœˆç»Ÿè®¡1å¹´è¿‡æœŸ
    pipeline.expire(modelHourly, 86400 * 7) // æ¨¡å‹å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ
    pipeline.expire(keyModelDaily, 86400 * 32) // API Keyæ¨¡å‹æ¯æ—¥ç»Ÿè®¡32å¤©è¿‡æœŸ
    pipeline.expire(keyModelMonthly, 86400 * 365) // API Keyæ¨¡å‹æ¯æœˆç»Ÿè®¡1å¹´è¿‡æœŸ
    pipeline.expire(keyModelHourly, 86400 * 7) // API Keyæ¨¡å‹å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ

    // ç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡çš„è¿‡æœŸæ—¶é—´ï¼ˆçª—å£æ—¶é—´çš„2å€ï¼‰
    const configLocal = require('../../../config/config')
    const { metricsWindow } = configLocal.system
    pipeline.expire(systemMinuteKey, metricsWindow * 60 * 2)

    // æ‰§è¡ŒPipeline
    await pipeline.exec()
  }

  /**
   * è®°å½•è´¦æˆ·çº§åˆ«çš„ä½¿ç”¨ç»Ÿè®¡
   * @param {string} accountId è´¦æˆ·ID
   * @param {number} totalTokens æ€»Tokenæ•°
   * @param {number} inputTokens è¾“å…¥Tokenæ•°
   * @param {number} outputTokens è¾“å‡ºTokenæ•°
   * @param {number} cacheCreateTokens ç¼“å­˜åˆ›å»ºTokenæ•°
   * @param {number} cacheReadTokens ç¼“å­˜è¯»å–Tokenæ•°
   * @param {string} model æ¨¡å‹åç§°
   * @returns {Promise<void>}
   */
  async incrementAccountUsage(
    accountId,
    totalTokens,
    inputTokens = 0,
    outputTokens = 0,
    cacheCreateTokens = 0,
    cacheReadTokens = 0,
    model = 'unknown'
  ) {
    const now = new Date()
    const today = getDateStringInTimezone(now)
    const tzDate = getDateInTimezone(now)
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const currentHour = `${today}:${String(getHourInTimezone(now)).padStart(2, '0')}`

    // è´¦æˆ·çº§åˆ«ç»Ÿè®¡çš„é”®
    const accountKey = `account_usage:${accountId}`
    const accountDaily = `account_usage:daily:${accountId}:${today}`
    const accountMonthly = `account_usage:monthly:${accountId}:${currentMonth}`
    const accountHourly = `account_usage:hourly:${accountId}:${currentHour}`

    // æ ‡å‡†åŒ–æ¨¡å‹åç”¨äºç»Ÿè®¡èšåˆ
    const normalizedModel = this._normalizeModelName(model)

    // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡çš„é”®
    const accountModelDaily = `account_usage:model:daily:${accountId}:${normalizedModel}:${today}`
    const accountModelMonthly = `account_usage:model:monthly:${accountId}:${normalizedModel}:${currentMonth}`
    const accountModelHourly = `account_usage:model:hourly:${accountId}:${normalizedModel}:${currentHour}`

    // å¤„ç†tokenåˆ†é…
    const finalInputTokens = inputTokens || 0
    const finalOutputTokens = outputTokens || 0
    const finalCacheCreateTokens = cacheCreateTokens || 0
    const finalCacheReadTokens = cacheReadTokens || 0
    const actualTotalTokens =
      finalInputTokens + finalOutputTokens + finalCacheCreateTokens + finalCacheReadTokens
    const coreTokens = finalInputTokens + finalOutputTokens

    await Promise.all([
      // è´¦æˆ·æ€»ä½“ç»Ÿè®¡
      this.client.hincrby(accountKey, 'totalTokens', coreTokens),
      this.client.hincrby(accountKey, 'totalInputTokens', finalInputTokens),
      this.client.hincrby(accountKey, 'totalOutputTokens', finalOutputTokens),
      this.client.hincrby(accountKey, 'totalCacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountKey, 'totalCacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountKey, 'totalAllTokens', actualTotalTokens),
      this.client.hincrby(accountKey, 'totalRequests', 1),

      // è´¦æˆ·æ¯æ—¥ç»Ÿè®¡
      this.client.hincrby(accountDaily, 'tokens', coreTokens),
      this.client.hincrby(accountDaily, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountDaily, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountDaily, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountDaily, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountDaily, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountDaily, 'requests', 1),

      // è´¦æˆ·æ¯æœˆç»Ÿè®¡
      this.client.hincrby(accountMonthly, 'tokens', coreTokens),
      this.client.hincrby(accountMonthly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountMonthly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountMonthly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountMonthly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountMonthly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountMonthly, 'requests', 1),

      // è´¦æˆ·æ¯å°æ—¶ç»Ÿè®¡
      this.client.hincrby(accountHourly, 'tokens', coreTokens),
      this.client.hincrby(accountHourly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountHourly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountHourly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountHourly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountHourly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountHourly, 'requests', 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
      this.client.hincrby(accountModelDaily, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelDaily, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelDaily, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelDaily, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelDaily, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelDaily, 'requests', 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
      this.client.hincrby(accountModelMonthly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelMonthly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelMonthly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelMonthly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelMonthly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelMonthly, 'requests', 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
      this.client.hincrby(accountModelHourly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelHourly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelHourly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelHourly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelHourly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelHourly, 'requests', 1),

      // è®¾ç½®è¿‡æœŸæ—¶é—´
      this.client.expire(accountDaily, 86400 * 32), // 32å¤©è¿‡æœŸ
      this.client.expire(accountMonthly, 86400 * 365), // 1å¹´è¿‡æœŸ
      this.client.expire(accountHourly, 86400 * 7), // 7å¤©è¿‡æœŸ
      this.client.expire(accountModelDaily, 86400 * 32), // 32å¤©è¿‡æœŸ
      this.client.expire(accountModelMonthly, 86400 * 365), // 1å¹´è¿‡æœŸ
      this.client.expire(accountModelHourly, 86400 * 7) // 7å¤©è¿‡æœŸ
    ])
  }

  /**
   * è·å–API Keyä½¿ç”¨ç»Ÿè®¡ï¼ˆåŒ…æ‹¬å…¼å®¹æ€§å¤„ç†ï¼‰
   * @param {string} keyId API Key ID
   * @returns {Promise<Object>} ä½¿ç”¨ç»Ÿè®¡å¯¹è±¡
   */
  async getUsageStats(keyId) {
    const totalKey = `usage:${keyId}`
    const today = getDateStringInTimezone()
    const dailyKey = `usage:daily:${keyId}:${today}`
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const monthlyKey = `usage:monthly:${keyId}:${currentMonth}`

    const [total, daily, monthly] = await Promise.all([
      this.client.hgetall(totalKey),
      this.client.hgetall(dailyKey),
      this.client.hgetall(monthlyKey)
    ])

    // è·å–API Keyçš„åˆ›å»ºæ—¶é—´æ¥è®¡ç®—å¹³å‡å€¼
    const keyData = await this.client.hgetall(`apikey:${keyId}`)
    const createdAt = keyData.createdAt ? new Date(keyData.createdAt) : new Date()
    const now = new Date()
    const daysSinceCreated = Math.max(1, Math.ceil((now - createdAt) / (1000 * 60 * 60 * 24)))

    const totalTokens = parseInt(total.totalTokens) || 0
    const totalRequests = parseInt(total.totalRequests) || 0

    // è®¡ç®—å¹³å‡RPM (requests per minute) å’Œ TPM (tokens per minute)
    const totalMinutes = Math.max(1, daysSinceCreated * 24 * 60)
    const avgRPM = totalRequests / totalMinutes
    const avgTPM = totalTokens / totalMinutes

    // å¤„ç†æ—§æ•°æ®å…¼å®¹æ€§ï¼ˆæ”¯æŒç¼“å­˜tokenï¼‰
    const handleLegacyData = (data) => {
      // ä¼˜å…ˆä½¿ç”¨total*å­—æ®µï¼ˆå­˜å‚¨æ—¶ä½¿ç”¨çš„å­—æ®µï¼‰
      const tokens = parseInt(data.totalTokens) || parseInt(data.tokens) || 0
      const inputTokens = parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
      const outputTokens = parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
      const requests = parseInt(data.totalRequests) || parseInt(data.requests) || 0

      // æ–°å¢ç¼“å­˜tokenå­—æ®µ
      const cacheCreateTokens =
        parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
      const cacheReadTokens =
        parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
      const allTokens = parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0

      const totalFromSeparate = inputTokens + outputTokens
      // è®¡ç®—å®é™…çš„æ€»tokensï¼ˆåŒ…å«æ‰€æœ‰ç±»å‹ï¼‰
      const actualAllTokens =
        allTokens || inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

      if (totalFromSeparate === 0 && tokens > 0) {
        // æ—§æ•°æ®ï¼šæ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»
        return {
          tokens, // ä¿æŒå…¼å®¹æ€§ï¼Œä½†ç»Ÿä¸€ä½¿ç”¨allTokens
          inputTokens: Math.round(tokens * 0.3), // å‡è®¾30%ä¸ºè¾“å…¥
          outputTokens: Math.round(tokens * 0.7), // å‡è®¾70%ä¸ºè¾“å‡º
          cacheCreateTokens: 0, // æ—§æ•°æ®æ²¡æœ‰ç¼“å­˜token
          cacheReadTokens: 0,
          allTokens: tokens, // å¯¹äºæ—§æ•°æ®ï¼ŒallTokensç­‰äºtokens
          requests
        }
      } else {
        // æ–°æ•°æ®æˆ–æ— æ•°æ® - ç»Ÿä¸€ä½¿ç”¨allTokensä½œä¸ºtokensçš„å€¼
        return {
          tokens: actualAllTokens, // ç»Ÿä¸€ä½¿ç”¨allTokensä½œä¸ºæ€»æ•°
          inputTokens,
          outputTokens,
          cacheCreateTokens,
          cacheReadTokens,
          allTokens: actualAllTokens,
          requests
        }
      }
    }

    const totalData = handleLegacyData(total)
    const dailyData = handleLegacyData(daily)
    const monthlyData = handleLegacyData(monthly)

    return {
      total: totalData,
      daily: dailyData,
      monthly: monthlyData,
      averages: {
        rpm: Math.round(avgRPM * 100) / 100, // ä¿ç•™2ä½å°æ•°
        tpm: Math.round(avgTPM * 100) / 100,
        dailyRequests: Math.round((totalRequests / daysSinceCreated) * 100) / 100,
        dailyTokens: Math.round((totalTokens / daysSinceCreated) * 100) / 100
      }
    }
  }

  /**
   * è·å–å½“æ—¥è´¹ç”¨
   * @param {string} keyId API Key ID
   * @returns {Promise<number>} å½“æ—¥è´¹ç”¨
   */
  async getDailyCost(keyId) {
    const today = getDateStringInTimezone()
    const costKey = `usage:cost:daily:${keyId}:${today}`
    const cost = await this.client.get(costKey)
    const result = parseFloat(cost || 0)
    logger.debug(
      `ğŸ’° Getting daily cost for ${keyId}, date: ${today}, key: ${costKey}, value: ${cost}, result: ${result}`
    )
    return result
  }

  /**
   * å¢åŠ å½“æ—¥è´¹ç”¨
   * @param {string} keyId API Key ID
   * @param {number} amount è´¹ç”¨é‡‘é¢
   * @returns {Promise<void>}
   */
  async incrementDailyCost(keyId, amount) {
    const today = getDateStringInTimezone()
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

    const dailyKey = `usage:cost:daily:${keyId}:${today}`
    const monthlyKey = `usage:cost:monthly:${keyId}:${currentMonth}`
    const hourlyKey = `usage:cost:hourly:${keyId}:${currentHour}`
    const totalKey = `usage:cost:total:${keyId}`

    logger.debug(
      `ğŸ’° Incrementing cost for ${keyId}, amount: $${amount}, date: ${today}, dailyKey: ${dailyKey}`
    )

    const results = await Promise.all([
      this.client.incrbyfloat(dailyKey, amount),
      this.client.incrbyfloat(monthlyKey, amount),
      this.client.incrbyfloat(hourlyKey, amount),
      this.client.incrbyfloat(totalKey, amount),
      // è®¾ç½®è¿‡æœŸæ—¶é—´
      this.client.expire(dailyKey, 86400 * 30), // 30å¤©
      this.client.expire(monthlyKey, 86400 * 90), // 90å¤©
      this.client.expire(hourlyKey, 86400 * 7) // 7å¤©
    ])

    logger.debug(`ğŸ’° Cost incremented successfully, new daily total: $${results[0]}`)
  }

  /**
   * è·å–è´¹ç”¨ç»Ÿè®¡
   * @param {string} keyId API Key ID
   * @returns {Promise<Object>} è´¹ç”¨ç»Ÿè®¡å¯¹è±¡
   */
  async getCostStats(keyId) {
    const today = getDateStringInTimezone()
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

    const [daily, monthly, hourly, total] = await Promise.all([
      this.client.get(`usage:cost:daily:${keyId}:${today}`),
      this.client.get(`usage:cost:monthly:${keyId}:${currentMonth}`),
      this.client.get(`usage:cost:hourly:${keyId}:${currentHour}`),
      this.client.get(`usage:cost:total:${keyId}`)
    ])

    return {
      daily: parseFloat(daily || 0),
      monthly: parseFloat(monthly || 0),
      hourly: parseFloat(hourly || 0),
      total: parseFloat(total || 0)
    }
  }

  /**
   * è·å–è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<Object>} è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡å¯¹è±¡
   */
  async getAccountUsageStats(accountId) {
    const accountKey = `account_usage:${accountId}`
    const today = getDateStringInTimezone()
    const accountDailyKey = `account_usage:daily:${accountId}:${today}`
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
    const accountMonthlyKey = `account_usage:monthly:${accountId}:${currentMonth}`

    const [total, daily, monthly] = await Promise.all([
      this.client.hgetall(accountKey),
      this.client.hgetall(accountDailyKey),
      this.client.hgetall(accountMonthlyKey)
    ])

    // è·å–è´¦æˆ·åˆ›å»ºæ—¶é—´æ¥è®¡ç®—å¹³å‡å€¼ï¼ˆä¿®å¤é”®åä¸ä¸€è‡´é—®é¢˜ï¼‰
    const accountData = await this.client.hgetall(`claude:account:${accountId}`)
    const createdAt = accountData.createdAt ? new Date(accountData.createdAt) : new Date()
    const now = new Date()
    const daysSinceCreated = Math.max(1, Math.ceil((now - createdAt) / (1000 * 60 * 60 * 24)))

    const totalTokens = parseInt(total.totalTokens) || 0
    const totalRequests = parseInt(total.totalRequests) || 0

    // è®¡ç®—å¹³å‡RPMå’ŒTPM
    const totalMinutes = Math.max(1, daysSinceCreated * 24 * 60)
    const avgRPM = totalRequests / totalMinutes
    const avgTPM = totalTokens / totalMinutes

    // å¤„ç†è´¦æˆ·ç»Ÿè®¡æ•°æ®
    const handleAccountData = (data) => {
      const tokens = parseInt(data.totalTokens) || parseInt(data.tokens) || 0
      const inputTokens = parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
      const outputTokens = parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
      const requests = parseInt(data.totalRequests) || parseInt(data.requests) || 0
      const cacheCreateTokens =
        parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
      const cacheReadTokens =
        parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
      const allTokens = parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0

      const actualAllTokens =
        allTokens || inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

      return {
        tokens,
        inputTokens,
        outputTokens,
        cacheCreateTokens,
        cacheReadTokens,
        allTokens: actualAllTokens,
        requests
      }
    }

    const totalData = handleAccountData(total)
    const dailyData = handleAccountData(daily)
    const monthlyData = handleAccountData(monthly)

    return {
      accountId,
      total: totalData,
      daily: dailyData,
      monthly: monthlyData,
      averages: {
        rpm: Math.round(avgRPM * 100) / 100,
        tpm: Math.round(avgTPM * 100) / 100,
        dailyRequests: Math.round((totalRequests / daysSinceCreated) * 100) / 100,
        dailyTokens: Math.round((totalTokens / daysSinceCreated) * 100) / 100
      }
    }
  }

  /**
   * è·å–æ‰€æœ‰è´¦æˆ·çš„ä½¿ç”¨ç»Ÿè®¡
   * @returns {Promise<Array>} æ‰€æœ‰è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡æ•°ç»„
   */
  async getAllAccountsUsageStats() {
    try {
      const accountStats = []

      // è·å–æ‰€æœ‰Claudeè´¦æˆ·ï¼ˆä¿®å¤é”®åä¸ä¸€è‡´é—®é¢˜ï¼‰
      const claudeAccountKeys = await this.client.keys('claude:account:*')

      for (const accountKey of claudeAccountKeys) {
        const accountId = accountKey.replace('claude:account:', '')
        const accountData = await this.client.hgetall(accountKey)

        if (accountData.name) {
          const stats = await this.getAccountUsageStats(accountId)
          accountStats.push({
            id: accountId,
            name: accountData.name,
            email: accountData.email || '',
            status: accountData.status || 'unknown',
            isActive: accountData.isActive === 'true',
            accountType: 'claude',
            ...stats
          })
        }
      }

      // è·å–æ‰€æœ‰Claude Consoleè´¦æˆ·
      const claudeConsoleAccountKeys = await this.client.keys('claude_console_account:*')

      for (const accountKey of claudeConsoleAccountKeys) {
        const accountId = accountKey.replace('claude_console_account:', '')
        const accountData = await this.client.hgetall(accountKey)

        if (accountData.name || accountData.email) {
          const stats = await this.getAccountUsageStats(accountId)
          accountStats.push({
            id: accountId,
            name: accountData.name || accountData.email || accountId,
            email: accountData.email || '',
            status: accountData.status || 'unknown',
            isActive: accountData.isActive === 'true',
            accountType: 'claude_console',
            ...stats
          })
        }
      }

      // æŒ‰å½“æ—¥tokenä½¿ç”¨é‡æ’åº
      accountStats.sort((a, b) => (b.daily.allTokens || 0) - (a.daily.allTokens || 0))

      return accountStats
    } catch (error) {
      logger.error('âŒ Failed to get all accounts usage stats:', error)
      return []
    }
  }

  /**
   * æ¸…ç©ºæ‰€æœ‰API Keyçš„ä½¿ç”¨ç»Ÿè®¡æ•°æ®
   * @returns {Promise<Object>} æ¸…ç†ç»Ÿè®¡ç»“æœ
   */
  async resetAllUsageStats() {
    const client = this.getClientSafe()
    const stats = {
      deletedKeys: 0,
      deletedDailyKeys: 0,
      deletedMonthlyKeys: 0,
      resetApiKeys: 0
    }

    try {
      // è·å–æ‰€æœ‰API Key ID
      const apiKeyIds = []
      const apiKeyKeys = await client.keys('apikey:*')

      for (const key of apiKeyKeys) {
        if (key === 'apikey:hash_map') {
          continue
        } // è·³è¿‡å“ˆå¸Œæ˜ å°„è¡¨
        const keyId = key.replace('apikey:', '')
        apiKeyIds.push(keyId)
      }

      // æ¸…ç©ºæ¯ä¸ªAPI Keyçš„ä½¿ç”¨ç»Ÿè®¡
      for (const keyId of apiKeyIds) {
        // åˆ é™¤æ€»ä½“ä½¿ç”¨ç»Ÿè®¡
        const usageKey = `usage:${keyId}`
        const deleted = await client.del(usageKey)
        if (deleted > 0) {
          stats.deletedKeys++
        }

        // åˆ é™¤è¯¥API Keyçš„æ¯æ—¥ç»Ÿè®¡ï¼ˆä½¿ç”¨ç²¾ç¡®çš„keyIdåŒ¹é…ï¼‰
        const dailyKeys = await client.keys(`usage:daily:${keyId}:*`)
        if (dailyKeys.length > 0) {
          await client.del(...dailyKeys)
          stats.deletedDailyKeys += dailyKeys.length
        }

        // åˆ é™¤è¯¥API Keyçš„æ¯æœˆç»Ÿè®¡ï¼ˆä½¿ç”¨ç²¾ç¡®çš„keyIdåŒ¹é…ï¼‰
        const monthlyKeys = await client.keys(`usage:monthly:${keyId}:*`)
        if (monthlyKeys.length > 0) {
          await client.del(...monthlyKeys)
          stats.deletedMonthlyKeys += monthlyKeys.length
        }

        // é‡ç½®API Keyçš„lastUsedAtå­—æ®µ
        const keyData = await client.hgetall(`apikey:${keyId}`)
        if (keyData && Object.keys(keyData).length > 0) {
          keyData.lastUsedAt = ''
          await client.hmset(`apikey:${keyId}`, keyData)
          stats.resetApiKeys++
        }
      }

      // é¢å¤–æ¸…ç†ï¼šåˆ é™¤æ‰€æœ‰å¯èƒ½é—æ¼çš„usageç›¸å…³é”®
      const allUsageKeys = await client.keys('usage:*')
      if (allUsageKeys.length > 0) {
        await client.del(...allUsageKeys)
        stats.deletedKeys += allUsageKeys.length
      }

      return stats
    } catch (error) {
      throw new Error(`Failed to reset usage stats: ${error.message}`)
    }
  }

  // ==================== ç³»ç»Ÿç»Ÿè®¡ (4ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–åŸºç¡€ç³»ç»Ÿç»Ÿè®¡æ•°æ®
   * @returns {Promise<Object>} ç³»ç»Ÿç»Ÿè®¡å¯¹è±¡ï¼ŒåŒ…å«API Keyã€Claudeè´¦æˆ·å’Œä½¿ç”¨è®°å½•çš„æ€»æ•°
   */
  async getSystemStats() {
    const keys = await Promise.all([
      this.client.keys('apikey:*'),
      this.client.keys('claude:account:*'),
      this.client.keys('usage:*')
    ])

    return {
      totalApiKeys: keys[0].length,
      totalClaudeAccounts: keys[1].length,
      totalUsageRecords: keys[2].length
    }
  }

  /**
   * è·å–å½“æ—¥ç³»ç»Ÿç»Ÿè®¡æ•°æ®ï¼ˆå¤æ‚çš„æ‰¹é‡Pipelineæ“ä½œå’Œå…¼å®¹æ€§å¤„ç†ï¼‰
   * @returns {Promise<Object>} å½“æ—¥ç»Ÿè®¡å¯¹è±¡ï¼ŒåŒ…å«è¯·æ±‚æ•°ã€Tokenæ•°å’ŒAPI Keyåˆ›å»ºæ•°
   */
  async getTodayStats() {
    try {
      const today = getDateStringInTimezone()
      const dailyKeys = await this.client.keys(`usage:daily:*:${today}`)

      let totalRequestsToday = 0
      let totalTokensToday = 0
      let totalInputTokensToday = 0
      let totalOutputTokensToday = 0
      let totalCacheCreateTokensToday = 0
      let totalCacheReadTokensToday = 0

      // æ‰¹é‡è·å–æ‰€æœ‰ä»Šæ—¥æ•°æ®ï¼Œæé«˜æ€§èƒ½
      if (dailyKeys.length > 0) {
        const pipeline = this.client.pipeline()
        dailyKeys.forEach((key) => pipeline.hgetall(key))
        const results = await pipeline.exec()

        for (const [error, dailyData] of results) {
          if (error || !dailyData) {
            continue
          }

          totalRequestsToday += parseInt(dailyData.requests) || 0
          const currentDayTokens = parseInt(dailyData.tokens) || 0
          totalTokensToday += currentDayTokens

          // å¤„ç†æ—§æ•°æ®å…¼å®¹æ€§ï¼šå¦‚æœæœ‰æ€»tokenä½†æ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»ï¼Œåˆ™ä½¿ç”¨æ€»tokenä½œä¸ºè¾“å‡ºtoken
          const inputTokens = parseInt(dailyData.inputTokens) || 0
          const outputTokens = parseInt(dailyData.outputTokens) || 0
          const cacheCreateTokens = parseInt(dailyData.cacheCreateTokens) || 0
          const cacheReadTokens = parseInt(dailyData.cacheReadTokens) || 0
          const totalTokensFromSeparate = inputTokens + outputTokens

          if (totalTokensFromSeparate === 0 && currentDayTokens > 0) {
            // æ—§æ•°æ®ï¼šæ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»ï¼Œå‡è®¾70%ä¸ºè¾“å‡ºï¼Œ30%ä¸ºè¾“å…¥ï¼ˆåŸºäºä¸€èˆ¬å¯¹è¯æ¯”ä¾‹ï¼‰
            totalOutputTokensToday += Math.round(currentDayTokens * 0.7)
            totalInputTokensToday += Math.round(currentDayTokens * 0.3)
          } else {
            // æ–°æ•°æ®ï¼šä½¿ç”¨å®é™…çš„è¾“å…¥è¾“å‡ºåˆ†ç¦»
            totalInputTokensToday += inputTokens
            totalOutputTokensToday += outputTokens
          }

          // æ·»åŠ cache tokenç»Ÿè®¡
          totalCacheCreateTokensToday += cacheCreateTokens
          totalCacheReadTokensToday += cacheReadTokens
        }
      }

      // è·å–ä»Šæ—¥åˆ›å»ºçš„API Keyæ•°é‡ï¼ˆæ‰¹é‡ä¼˜åŒ–ï¼‰
      const allApiKeys = await this.client.keys('apikey:*')
      let apiKeysCreatedToday = 0

      if (allApiKeys.length > 0) {
        const pipeline = this.client.pipeline()
        allApiKeys.forEach((key) => pipeline.hget(key, 'createdAt'))
        const results = await pipeline.exec()

        for (const [error, createdAt] of results) {
          if (!error && createdAt && createdAt.startsWith(today)) {
            apiKeysCreatedToday++
          }
        }
      }

      return {
        requestsToday: totalRequestsToday,
        tokensToday: totalTokensToday,
        inputTokensToday: totalInputTokensToday,
        outputTokensToday: totalOutputTokensToday,
        cacheCreateTokensToday: totalCacheCreateTokensToday,
        cacheReadTokensToday: totalCacheReadTokensToday,
        apiKeysCreatedToday
      }
    } catch (error) {
      logger.error('Error getting today stats:', error)
      return {
        requestsToday: 0,
        tokensToday: 0,
        inputTokensToday: 0,
        outputTokensToday: 0,
        cacheCreateTokensToday: 0,
        cacheReadTokensToday: 0,
        apiKeysCreatedToday: 0
      }
    }
  }

  /**
   * è·å–ç³»ç»Ÿçº§å¹³å‡RPM/TPMè®¡ç®—ï¼ˆå¤æ‚çš„æ‰¹é‡æ•°æ®å¤„ç†ï¼‰
   * @returns {Promise<Object>} ç³»ç»Ÿå¹³å‡å€¼å¯¹è±¡ï¼ŒåŒ…å«RPMã€TPMå’ŒTokenåˆ†å¸ƒæ•°æ®
   */
  async getSystemAverages() {
    try {
      const allApiKeys = await this.client.keys('apikey:*')
      let totalRequests = 0
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let oldestCreatedAt = new Date()

      // æ‰¹é‡è·å–æ‰€æœ‰usageæ•°æ®å’Œkeyæ•°æ®ï¼Œæé«˜æ€§èƒ½
      const usageKeys = allApiKeys.map((key) => `usage:${key.replace('apikey:', '')}`)
      const pipeline = this.client.pipeline()

      // æ·»åŠ æ‰€æœ‰usageæŸ¥è¯¢
      usageKeys.forEach((key) => pipeline.hgetall(key))
      // æ·»åŠ æ‰€æœ‰keyæ•°æ®æŸ¥è¯¢
      allApiKeys.forEach((key) => pipeline.hgetall(key))

      const results = await pipeline.exec()
      const usageResults = results.slice(0, usageKeys.length)
      const keyResults = results.slice(usageKeys.length)

      for (let i = 0; i < allApiKeys.length; i++) {
        const totalData = usageResults[i][1] || {}
        const keyData = keyResults[i][1] || {}

        totalRequests += parseInt(totalData.totalRequests) || 0
        totalTokens += parseInt(totalData.totalTokens) || 0
        totalInputTokens += parseInt(totalData.totalInputTokens) || 0
        totalOutputTokens += parseInt(totalData.totalOutputTokens) || 0

        const createdAt = keyData.createdAt ? new Date(keyData.createdAt) : new Date()
        if (createdAt < oldestCreatedAt) {
          oldestCreatedAt = createdAt
        }
      }

      const now = new Date()
      // ä¿æŒä¸ä¸ªäººAPI Keyè®¡ç®—ä¸€è‡´çš„ç®—æ³•ï¼šæŒ‰å¤©è®¡ç®—ç„¶åè½¬æ¢ä¸ºåˆ†é’Ÿ
      const daysSinceOldest = Math.max(
        1,
        Math.ceil((now - oldestCreatedAt) / (1000 * 60 * 60 * 24))
      )
      const totalMinutes = daysSinceOldest * 24 * 60

      return {
        systemRPM: Math.round((totalRequests / totalMinutes) * 100) / 100,
        systemTPM: Math.round((totalTokens / totalMinutes) * 100) / 100,
        totalInputTokens,
        totalOutputTokens,
        totalTokens
      }
    } catch (error) {
      logger.error('Error getting system averages:', error)
      return {
        systemRPM: 0,
        systemTPM: 0,
        totalInputTokens: 0,
        totalOutputTokens: 0,
        totalTokens: 0
      }
    }
  }

  /**
   * è·å–å®æ—¶ç³»ç»ŸæŒ‡æ ‡ï¼ˆåŸºäºæ»‘åŠ¨çª—å£çš„å¤æ‚è®¡ç®—é€»è¾‘ï¼‰
   * @returns {Promise<Object>} å®æ—¶ç³»ç»ŸæŒ‡æ ‡å¯¹è±¡ï¼ŒåŒ…å«å®æ—¶RPM/TPMå’Œçª—å£å†…è¯¦ç»†ç»Ÿè®¡
   */
  async getRealtimeSystemMetrics() {
    try {
      const configLocal = require('../../../config/config')
      const windowMinutes = configLocal.system.metricsWindow || 5

      const now = new Date()
      const currentMinute = Math.floor(now.getTime() / 60000)

      // è°ƒè¯•ï¼šæ‰“å°å½“å‰æ—¶é—´å’Œåˆ†é’Ÿæ—¶é—´æˆ³
      logger.debug(
        `ğŸ” Realtime metrics - Current time: ${now.toISOString()}, Minute timestamp: ${currentMinute}`
      )

      // ä½¿ç”¨Pipelineæ‰¹é‡è·å–çª—å£å†…çš„æ‰€æœ‰åˆ†é’Ÿæ•°æ®
      const pipeline = this.client.pipeline()
      const minuteKeys = []
      for (let i = 0; i < windowMinutes; i++) {
        const minuteKey = `system:metrics:minute:${currentMinute - i}`
        minuteKeys.push(minuteKey)
        pipeline.hgetall(minuteKey)
      }

      logger.debug(`ğŸ” Realtime metrics - Checking keys: ${minuteKeys.join(', ')}`)

      const results = await pipeline.exec()

      // èšåˆè®¡ç®—
      let totalRequests = 0
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let totalCacheCreateTokens = 0
      let totalCacheReadTokens = 0
      let validDataCount = 0

      results.forEach(([err, data], index) => {
        if (!err && data && Object.keys(data).length > 0) {
          validDataCount++
          totalRequests += parseInt(data.requests || 0)
          totalTokens += parseInt(data.totalTokens || 0)
          totalInputTokens += parseInt(data.inputTokens || 0)
          totalOutputTokens += parseInt(data.outputTokens || 0)
          totalCacheCreateTokens += parseInt(data.cacheCreateTokens || 0)
          totalCacheReadTokens += parseInt(data.cacheReadTokens || 0)

          logger.debug(`ğŸ” Realtime metrics - Key ${minuteKeys[index]} data:`, {
            requests: data.requests,
            totalTokens: data.totalTokens
          })
        }
      })

      logger.debug(
        `ğŸ” Realtime metrics - Valid data count: ${validDataCount}/${windowMinutes}, Total requests: ${totalRequests}, Total tokens: ${totalTokens}`
      )

      // è®¡ç®—å¹³å‡å€¼ï¼ˆæ¯åˆ†é’Ÿï¼‰
      const realtimeRPM =
        windowMinutes > 0 ? Math.round((totalRequests / windowMinutes) * 100) / 100 : 0
      const realtimeTPM =
        windowMinutes > 0 ? Math.round((totalTokens / windowMinutes) * 100) / 100 : 0

      const result = {
        realtimeRPM,
        realtimeTPM,
        windowMinutes,
        totalRequests,
        totalTokens,
        totalInputTokens,
        totalOutputTokens,
        totalCacheCreateTokens,
        totalCacheReadTokens
      }

      logger.debug('ğŸ” Realtime metrics - Final result:', result)

      return result
    } catch (error) {
      logger.error('Error getting realtime system metrics:', error)
      // å¦‚æœå‡ºé”™ï¼Œè¿”å›å†å²å¹³å‡å€¼ä½œä¸ºé™çº§æ–¹æ¡ˆ
      const historicalMetrics = await this.getSystemAverages()
      return {
        realtimeRPM: historicalMetrics.systemRPM,
        realtimeTPM: historicalMetrics.systemTPM,
        windowMinutes: 0, // æ ‡è¯†ä½¿ç”¨äº†å†å²æ•°æ®
        totalRequests: 0,
        totalTokens: historicalMetrics.totalTokens,
        totalInputTokens: historicalMetrics.totalInputTokens,
        totalOutputTokens: historicalMetrics.totalOutputTokens,
        totalCacheCreateTokens: 0,
        totalCacheReadTokens: 0
      }
    }
  }

  // ==================== Claude è´¦æˆ·ç®¡ç† (6ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®Claudeè´¦æˆ·æ•°æ®ï¼ˆåŒ…å«è°ƒåº¦ç­–ç•¥å­—æ®µï¼‰
   * @param {string} accountId è´¦æˆ·ID
   * @param {Object} accountData è´¦æˆ·æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   */
  async setClaudeAccount(accountId, accountData) {
    const key = `claude:account:${accountId}`

    // ç¡®ä¿æ–°çš„è°ƒåº¦ç­–ç•¥å­—æ®µæœ‰é»˜è®¤å€¼
    const enrichedAccountData = {
      ...accountData,
      // è°ƒåº¦ç­–ç•¥å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
      schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
      schedulingWeight: accountData.schedulingWeight || '1',
      sequentialOrder: accountData.sequentialOrder || '1',
      roundRobinIndex: accountData.roundRobinIndex || '0',
      usageCount: accountData.usageCount || '0',
      lastScheduledAt: accountData.lastScheduledAt || ''
    }

    await this.client.hmset(key, enrichedAccountData)
  }

  /**
   * è·å–Claudeè´¦æˆ·æ•°æ®ï¼ˆç¡®ä¿è°ƒåº¦å­—æ®µé»˜è®¤å€¼ï¼‰
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<Object>} è´¦æˆ·æ•°æ®å¯¹è±¡
   */
  async getClaudeAccount(accountId) {
    const key = `claude:account:${accountId}`
    const accountData = await this.client.hgetall(key)

    if (!accountData || Object.keys(accountData).length === 0) {
      return accountData
    }

    // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
    return {
      ...accountData,
      schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
      schedulingWeight: accountData.schedulingWeight || '1',
      sequentialOrder: accountData.sequentialOrder || '1',
      roundRobinIndex: accountData.roundRobinIndex || '0',
      usageCount: accountData.usageCount || '0',
      lastScheduledAt: accountData.lastScheduledAt || ''
    }
  }

  /**
   * è·å–æ‰€æœ‰Claudeè´¦æˆ·ï¼ˆæ‰¹é‡é»˜è®¤å€¼å¤„ç†ï¼‰
   * @returns {Promise<Array>} Claudeè´¦æˆ·åˆ—è¡¨
   */
  async getAllClaudeAccounts() {
    const keys = await this.client.keys('claude:account:*')
    const accounts = []
    for (const key of keys) {
      const accountData = await this.client.hgetall(key)
      if (accountData && Object.keys(accountData).length > 0) {
        // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
        const enrichedAccount = {
          id: key.replace('claude:account:', ''),
          ...accountData,
          schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
          schedulingWeight: accountData.schedulingWeight || '1',
          sequentialOrder: accountData.sequentialOrder || '1',
          roundRobinIndex: accountData.roundRobinIndex || '0',
          usageCount: accountData.usageCount || '0',
          lastScheduledAt: accountData.lastScheduledAt || ''
        }
        accounts.push(enrichedAccount)
      }
    }
    return accounts
  }

  /**
   * è·å–æ‰€æœ‰Claude Consoleè´¦æˆ·
   * @returns {Promise<Array>} Claude Consoleè´¦æˆ·æ•°æ®æ•°ç»„
   */
  async getAllClaudeConsoleAccounts() {
    const keys = await this.client.keys('claude_console_account:*')
    const accounts = []
    for (const key of keys) {
      const accountData = await this.client.hgetall(key)
      if (accountData && Object.keys(accountData).length > 0) {
        // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
        const enrichedAccount = {
          id: key.replace('claude_console_account:', ''),
          ...accountData,
          schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
          schedulingWeight: accountData.schedulingWeight || '1',
          sequentialOrder: accountData.sequentialOrder || '1',
          roundRobinIndex: accountData.roundRobinIndex || '0',
          usageCount: accountData.usageCount || '0',
          lastScheduledAt: accountData.lastScheduledAt || ''
        }
        accounts.push(enrichedAccount)
      }
    }
    return accounts
  }

  /**
   * åˆ é™¤Claudeè´¦æˆ·
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteClaudeAccount(accountId) {
    const key = `claude:account:${accountId}`
    return await this.client.del(key)
  }

  /**
   * æ›´æ–°Claudeè´¦æˆ·è°ƒåº¦ç›¸å…³å­—æ®µ
   * @param {string} accountId è´¦æˆ·ID
   * @param {Object} updates æ›´æ–°çš„å­—æ®µå¯¹è±¡
   * @returns {Promise<void>}
   */
  async updateClaudeAccountSchedulingFields(accountId, updates) {
    const key = `claude:account:${accountId}`

    // ä»…æ›´æ–°è°ƒåº¦ç›¸å…³çš„å­—æ®µ
    const schedulingUpdates = {}

    if (updates.usageCount !== undefined) {
      schedulingUpdates.usageCount = updates.usageCount.toString()
    }

    if (updates.lastScheduledAt !== undefined) {
      schedulingUpdates.lastScheduledAt = updates.lastScheduledAt
    }

    if (updates.roundRobinIndex !== undefined) {
      schedulingUpdates.roundRobinIndex = updates.roundRobinIndex.toString()
    }

    if (Object.keys(schedulingUpdates).length > 0) {
      await this.client.hmset(key, schedulingUpdates)
    }
  }

  /**
   * åŸå­æ€§å¢åŠ Claudeè´¦æˆ·ä½¿ç”¨è®¡æ•°
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<number>} å¢åŠ åçš„ä½¿ç”¨è®¡æ•°
   */
  async incrementClaudeAccountUsageCount(accountId) {
    const key = `claude:account:${accountId}`
    return await this.client.hincrby(key, 'usageCount', 1)
  }

  // ==================== ä¼šè¯ç®¡ç† (12ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®ä¼šè¯æ•°æ®
   * @param {string} sessionId ä¼šè¯ID
   * @param {Object} sessionData ä¼šè¯æ•°æ®å¯¹è±¡
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤86400ç§’ï¼ˆ1å¤©ï¼‰
   * @returns {Promise<void>}
   */
  async setSession(sessionId, sessionData, ttl = 86400) {
    try {
      const key = `session:${sessionId}`
      const client = await this.getClientWithReconnect()

      logger.info(`ğŸ”§ Setting session: ${sessionId}`) // ä½¿ç”¨infoçº§åˆ«ç¡®ä¿èƒ½çœ‹åˆ°

      // ä½¿ç”¨hmsetæ–¹æ³•ï¼Œè¿™æ˜¯Rediså…¼å®¹æ€§æœ€å¥½çš„æ–¹å¼
      await client.hmset(key, sessionData)

      // åªæœ‰å½“ttlå¤§äº0æ—¶æ‰è®¾ç½®è¿‡æœŸæ—¶é—´
      if (ttl > 0) {
        await client.expire(key, ttl)
      }

      logger.info(`âœ… Session set successfully: ${sessionId}`)
    } catch (error) {
      logger.error('âŒ Failed to set session:', error)
      throw error
    }
  }

  /**
   * è·å–ä¼šè¯æ•°æ®
   * @param {string} sessionId ä¼šè¯ID
   * @returns {Promise<Object>} ä¼šè¯æ•°æ®å¯¹è±¡
   */
  async getSession(sessionId) {
    try {
      const client = await this.getClientWithReconnect()
      const key = `session:${sessionId}`
      return await client.hgetall(key)
    } catch (error) {
      logger.error('âŒ Failed to get session:', error)
      return {}
    }
  }

  /**
   * åˆ é™¤ä¼šè¯
   * @param {string} sessionId ä¼šè¯ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteSession(sessionId) {
    try {
      const key = `session:${sessionId}`
      const client = await this.getClientWithReconnect()
      return await client.del(key)
    } catch (error) {
      logger.error('âŒ Failed to delete session:', error)
      throw error
    }
  }

  /**
   * è®¾ç½®API Keyå“ˆå¸Œç´¢å¼•
   * @param {string} hashedKey å“ˆå¸Œåçš„Keyå€¼
   * @param {Object} keyData API Keyæ•°æ®
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤0è¡¨ç¤ºä¸è¿‡æœŸ
   * @returns {Promise<void>}
   */
  async setApiKeyHash(hashedKey, keyData, ttl = 0) {
    const key = `apikey_hash:${hashedKey}`
    const client = this.getClientSafe()
    await client.hmset(key, keyData)
    if (ttl > 0) {
      await client.expire(key, ttl)
    }
  }

  /**
   * è·å–API Keyå“ˆå¸Œç´¢å¼•æ•°æ®
   * @param {string} hashedKey å“ˆå¸Œåçš„Keyå€¼
   * @returns {Promise<Object>} API Keyæ•°æ®å¯¹è±¡
   */
  async getApiKeyHash(hashedKey) {
    const key = `apikey_hash:${hashedKey}`
    return await this.client.hgetall(key)
  }

  /**
   * åˆ é™¤API Keyå“ˆå¸Œç´¢å¼•
   * @param {string} hashedKey å“ˆå¸Œåçš„Keyå€¼
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteApiKeyHash(hashedKey) {
    const key = `apikey_hash:${hashedKey}`
    return await this.client.del(key)
  }

  /**
   * è®¾ç½®OAuthä¼šè¯æ•°æ®ï¼ˆåŒ…å«å¤æ‚å¯¹è±¡åºåˆ—åŒ–ï¼‰
   * @param {string} sessionId ä¼šè¯ID
   * @param {Object} sessionData ä¼šè¯æ•°æ®å¯¹è±¡
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰
   * @returns {Promise<void>}
   */
  async setOAuthSession(sessionId, sessionData, ttl = 600) {
    const key = `oauth:${sessionId}`
    const client = this.getClientSafe()

    // åºåˆ—åŒ–å¤æ‚å¯¹è±¡ï¼Œç‰¹åˆ«æ˜¯ proxy é…ç½®
    const serializedData = {}
    for (const [dataKey, value] of Object.entries(sessionData)) {
      if (typeof value === 'object' && value !== null) {
        serializedData[dataKey] = JSON.stringify(value)
      } else {
        serializedData[dataKey] = value
      }
    }

    await client.hmset(key, serializedData)
    await client.expire(key, ttl)
  }

  /**
   * è·å–OAuthä¼šè¯æ•°æ®ï¼ˆåŒ…å«å¤æ‚å¯¹è±¡ååºåˆ—åŒ–ï¼‰
   * @param {string} sessionId ä¼šè¯ID
   * @returns {Promise<Object>} OAuthä¼šè¯æ•°æ®å¯¹è±¡
   */
  async getOAuthSession(sessionId) {
    const key = `oauth:${sessionId}`
    const data = await this.client.hgetall(key)

    // ååºåˆ—åŒ– proxy å­—æ®µ
    if (data.proxy) {
      try {
        data.proxy = JSON.parse(data.proxy)
      } catch (error) {
        // å¦‚æœè§£æå¤±è´¥ï¼Œè®¾ç½®ä¸º null
        data.proxy = null
      }
    }

    return data
  }

  /**
   * åˆ é™¤OAuthä¼šè¯
   * @param {string} sessionId ä¼šè¯ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteOAuthSession(sessionId) {
    const key = `oauth:${sessionId}`
    return await this.client.del(key)
  }

  /**
   * è®¾ç½®ä¼šè¯è´¦æˆ·æ˜ å°„ï¼ˆSticky Sessionï¼‰
   * @param {string} sessionHash ä¼šè¯å“ˆå¸Œ
   * @param {string} accountId è´¦æˆ·ID
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3600ç§’ï¼ˆ1å°æ—¶ï¼‰
   * @returns {Promise<void>}
   */
  async setSessionAccountMapping(sessionHash, accountId, ttl = 3600) {
    const key = `sticky_session:${sessionHash}`
    const client = this.getClientSafe()
    await client.set(key, accountId, 'EX', ttl)
  }

  /**
   * è·å–ä¼šè¯è´¦æˆ·æ˜ å°„ï¼ˆSticky Sessionï¼‰
   * @param {string} sessionHash ä¼šè¯å“ˆå¸Œ
   * @returns {Promise<string|null>} è´¦æˆ·IDæˆ–null
   */
  async getSessionAccountMapping(sessionHash) {
    const key = `sticky_session:${sessionHash}`
    return await this.client.get(key)
  }

  /**
   * åˆ é™¤ä¼šè¯è´¦æˆ·æ˜ å°„ï¼ˆSticky Sessionï¼‰
   * @param {string} sessionHash ä¼šè¯å“ˆå¸Œ
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteSessionAccountMapping(sessionHash) {
    const key = `sticky_session:${sessionHash}`
    return await this.client.del(key)
  }

  // ==================== ç»´æŠ¤åŠŸèƒ½ (4ä¸ªæ–¹æ³•) ====================

  /**
   * ç³»ç»Ÿæ¸…ç†åŠŸèƒ½ï¼ŒåŒ…å«æ‰¹é‡é”®æŸ¥è¯¢å’ŒTTLè®¾ç½®é€»è¾‘
   * ç”¨äºæ¸…ç†è¿‡æœŸæ•°æ®ï¼Œç¡®ä¿æ•°æ®åº“å¥åº·è¿è¡Œ
   * @returns {Promise<void>}
   */
  async cleanup() {
    try {
      const patterns = ['usage:daily:*', 'ratelimit:*', 'session:*', 'sticky_session:*', 'oauth:*']

      for (const pattern of patterns) {
        const keys = await this.client.keys(pattern)
        const pipeline = this.client.pipeline()

        for (const key of keys) {
          const ttl = await this.client.ttl(key)
          if (ttl === -1) {
            // æ²¡æœ‰è®¾ç½®è¿‡æœŸæ—¶é—´çš„é”®
            if (key.startsWith('oauth:')) {
              pipeline.expire(key, 600) // OAuthä¼šè¯è®¾ç½®10åˆ†é’Ÿè¿‡æœŸ
            } else {
              pipeline.expire(key, 86400) // å…¶ä»–è®¾ç½®1å¤©è¿‡æœŸ
            }
          }
        }

        await pipeline.exec()
      }

      logger.info('ğŸ§¹ Redis cleanup completed')
    } catch (error) {
      logger.error('âŒ Redis cleanup failed:', error)
    }
  }

  /**
   * å¢åŠ å¹¶å‘è®¡æ•°ï¼ŒåŒ…å«è¿‡æœŸæ—¶é—´è®¾ç½®
   * ç”¨äºè·Ÿè¸ªAPI Keyçš„å¹¶å‘è¯·æ±‚æ•°é‡
   * @param {string} apiKeyId API Key ID
   * @returns {Promise<number>} å¢åŠ åçš„å¹¶å‘è®¡æ•°
   */
  async incrConcurrency(apiKeyId) {
    try {
      const key = `concurrency:${apiKeyId}`
      const count = await this.client.incr(key)

      // è®¾ç½®è¿‡æœŸæ—¶é—´ä¸º180ç§’ï¼ˆ3åˆ†é’Ÿï¼‰ï¼Œé˜²æ­¢è®¡æ•°å™¨æ°¸è¿œä¸æ¸…é›¶
      // æ­£å¸¸æƒ…å†µä¸‹è¯·æ±‚ä¼šåœ¨å®Œæˆæ—¶ä¸»åŠ¨å‡å°‘è®¡æ•°ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå®‰å…¨ä¿éšœ
      // 180ç§’è¶³å¤Ÿæ”¯æŒè¾ƒé•¿çš„æµå¼è¯·æ±‚
      await this.client.expire(key, 180)

      logger.database(`ğŸ”¢ Incremented concurrency for key ${apiKeyId}: ${count}`)
      return count
    } catch (error) {
      logger.error('âŒ Failed to increment concurrency:', error)
      throw error
    }
  }

  /**
   * å‡å°‘å¹¶å‘è®¡æ•°ï¼Œä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åŸå­æ€§æ“ä½œ
   * é˜²æ­¢è®¡æ•°å™¨å˜æˆè´Ÿæ•°ï¼Œç¡®ä¿å¹¶å‘è®¡æ•°çš„å‡†ç¡®æ€§
   * @param {string} apiKeyId API Key ID
   * @returns {Promise<number>} å‡å°‘åçš„å¹¶å‘è®¡æ•°
   */
  async decrConcurrency(apiKeyId) {
    try {
      const key = `concurrency:${apiKeyId}`

      // ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åŸå­æ€§æ“ä½œï¼Œé˜²æ­¢è®¡æ•°å™¨å˜æˆè´Ÿæ•°
      const luaScript = `
        local key = KEYS[1]
        local current = tonumber(redis.call('get', key) or "0")
        
        if current <= 0 then
          redis.call('del', key)
          return 0
        else
          local new_value = redis.call('decr', key)
          if new_value <= 0 then
            redis.call('del', key)
            return 0
          else
            return new_value
          end
        end
      `

      const count = await this.client.eval(luaScript, 1, key)
      logger.database(`ğŸ”¢ Decremented concurrency for key ${apiKeyId}: ${count}`)
      return count
    } catch (error) {
      logger.error('âŒ Failed to decrement concurrency:', error)
      throw error
    }
  }

  /**
   * è·å–å½“å‰å¹¶å‘æ•°
   * ç”¨äºæ£€æŸ¥API Keyçš„å½“å‰å¹¶å‘è¯·æ±‚æ•°é‡
   * @param {string} apiKeyId API Key ID
   * @returns {Promise<number>} å½“å‰å¹¶å‘æ•°
   */
  async getConcurrency(apiKeyId) {
    try {
      const key = `concurrency:${apiKeyId}`
      const count = await this.client.get(key)
      return parseInt(count || 0)
    } catch (error) {
      logger.error('âŒ Failed to get concurrency:', error)
      return 0
    }
  }

  // ==================== Gemini è´¦æˆ·ç®¡ç† (4ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–æ‰€æœ‰Geminiè´¦æˆ·
   * @returns {Promise<Array>} Geminiè´¦æˆ·æ•°ç»„
   */
  async getAllGeminiAccounts() {
    try {
      const keys = await this.client.keys('gemini:account:*')
      const accounts = []

      for (const key of keys) {
        const accountData = await this.client.hgetall(key)
        if (accountData && Object.keys(accountData).length > 0) {
          // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
          const enrichedAccount = {
            id: key.replace('gemini:account:', ''),
            ...accountData,
            schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
            schedulingWeight: accountData.schedulingWeight || '1',
            sequentialOrder: accountData.sequentialOrder || '1',
            roundRobinIndex: accountData.roundRobinIndex || '0',
            usageCount: accountData.usageCount || '0',
            lastScheduledAt: accountData.lastScheduledAt || ''
          }
          accounts.push(enrichedAccount)
        }
      }

      return accounts
    } catch (error) {
      logger.error('âŒ Failed to get all Gemini accounts:', error)
      throw error
    }
  }

  /**
   * è·å–å•ä¸ªGeminiè´¦æˆ·
   * @param {string} accountId Geminiè´¦æˆ·ID
   * @returns {Promise<Object|null>} Geminiè´¦æˆ·æ•°æ®å¯¹è±¡æˆ–null
   */
  async getGeminiAccount(accountId) {
    try {
      const key = `gemini:account:${accountId}`
      const accountData = await this.client.hgetall(key)

      if (!accountData || Object.keys(accountData).length === 0) {
        return null
      }

      // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
      return {
        id: accountId,
        ...accountData,
        schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
        schedulingWeight: accountData.schedulingWeight || '1',
        sequentialOrder: accountData.sequentialOrder || '1',
        roundRobinIndex: accountData.roundRobinIndex || '0',
        usageCount: accountData.usageCount || '0',
        lastScheduledAt: accountData.lastScheduledAt || ''
      }
    } catch (error) {
      logger.error(`âŒ Failed to get Gemini account ${accountId}:`, error)
      throw error
    }
  }

  /**
   * è®¾ç½®Geminiè´¦æˆ·æ•°æ®
   * @param {string} accountId Geminiè´¦æˆ·ID
   * @param {Object} accountData Geminiè´¦æˆ·æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} è´¦æˆ·æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setGeminiAccount(accountId, accountData) {
    try {
      const key = `gemini:account:${accountId}`
      const client = this.getClientSafe()

      // éªŒè¯è´¦æˆ·æ•°æ®
      if (
        !accountData ||
        typeof accountData !== 'object' ||
        Object.keys(accountData).length === 0
      ) {
        throw new Error('Invalid Gemini account data provided')
      }

      // ç¡®ä¿æ–°çš„è°ƒåº¦ç­–ç•¥å­—æ®µæœ‰é»˜è®¤å€¼
      const enrichedAccountData = {
        ...accountData,
        // è°ƒåº¦ç­–ç•¥å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
        schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
        schedulingWeight: accountData.schedulingWeight || '1',
        sequentialOrder: accountData.sequentialOrder || '1',
        roundRobinIndex: accountData.roundRobinIndex || '0',
        usageCount: accountData.usageCount || '0',
        lastScheduledAt: accountData.lastScheduledAt || ''
      }

      await client.hmset(key, enrichedAccountData)
      logger.info(`ğŸ¤– Gemini account ${accountId} data updated`)
    } catch (error) {
      logger.error(`âŒ Failed to set Gemini account ${accountId}:`, error)
      throw error
    }
  }

  /**
   * åˆ é™¤Geminiè´¦æˆ·
   * @param {string} accountId Geminiè´¦æˆ·ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteGeminiAccount(accountId) {
    try {
      const key = `gemini:account:${accountId}`
      const result = await this.client.del(key)
      logger.info(`ğŸ—‘ï¸ Gemini account ${accountId} deleted`)
      return result
    } catch (error) {
      logger.error(`âŒ Failed to delete Gemini account ${accountId}:`, error)
      throw error
    }
  }

  // ==================== OpenAI è´¦æˆ·ç®¡ç† (4ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®OpenAIè´¦æˆ·æ•°æ®
   * @param {string} accountId è´¦æˆ·ID
   * @param {Object} accountData è´¦æˆ·æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   */
  async setOpenAiAccount(accountId, accountData) {
    const key = `openai:account:${accountId}`

    // ç¡®ä¿æ–°çš„è°ƒåº¦ç­–ç•¥å­—æ®µæœ‰é»˜è®¤å€¼
    const enrichedAccountData = {
      ...accountData,
      // è°ƒåº¦ç­–ç•¥å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
      schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
      schedulingWeight: accountData.schedulingWeight || '1',
      sequentialOrder: accountData.sequentialOrder || '1',
      roundRobinIndex: accountData.roundRobinIndex || '0',
      usageCount: accountData.usageCount || '0',
      lastScheduledAt: accountData.lastScheduledAt || ''
    }

    await this.client.hmset(key, enrichedAccountData)
  }

  /**
   * è·å–OpenAIè´¦æˆ·æ•°æ®
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<Object>} è´¦æˆ·æ•°æ®å¯¹è±¡
   */
  async getOpenAiAccount(accountId) {
    const key = `openai:account:${accountId}`
    const accountData = await this.client.hgetall(key)

    if (!accountData || Object.keys(accountData).length === 0) {
      return accountData
    }

    // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
    return {
      ...accountData,
      schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
      schedulingWeight: accountData.schedulingWeight || '1',
      sequentialOrder: accountData.sequentialOrder || '1',
      roundRobinIndex: accountData.roundRobinIndex || '0',
      usageCount: accountData.usageCount || '0',
      lastScheduledAt: accountData.lastScheduledAt || ''
    }
  }

  /**
   * åˆ é™¤OpenAIè´¦æˆ·
   * @param {string} accountId è´¦æˆ·ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteOpenAiAccount(accountId) {
    const key = `openai:account:${accountId}`
    return await this.client.del(key)
  }

  /**
   * è·å–æ‰€æœ‰OpenAIè´¦æˆ·
   * @returns {Promise<Array>} OpenAIè´¦æˆ·åˆ—è¡¨
   */
  async getAllOpenAIAccounts() {
    const keys = await this.client.keys('openai:account:*')
    const accounts = []
    for (const key of keys) {
      const accountData = await this.client.hgetall(key)
      if (accountData && Object.keys(accountData).length > 0) {
        // ç¡®ä¿æ‰€æœ‰è°ƒåº¦ç­–ç•¥å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
        const enrichedAccount = {
          id: key.replace('openai:account:', ''),
          ...accountData,
          schedulingStrategy: accountData.schedulingStrategy || 'least_recent',
          schedulingWeight: accountData.schedulingWeight || '1',
          sequentialOrder: accountData.sequentialOrder || '1',
          roundRobinIndex: accountData.roundRobinIndex || '0',
          usageCount: accountData.usageCount || '0',
          lastScheduledAt: accountData.lastScheduledAt || ''
        }
        accounts.push(enrichedAccount)
      }
    }
    return accounts
  }

  // ==================== å“ç‰Œè®¾ç½®ç®¡ç† (3ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–å“ç‰Œé…ç½®
   * @returns {Promise<Object|null>} å“ç‰Œé…ç½®å¯¹è±¡æˆ–null
   */
  async getBrandingConfig() {
    try {
      const key = 'system:branding_config'
      const brandingConfig = await this.client.hgetall(key)

      if (!brandingConfig || Object.keys(brandingConfig).length === 0) {
        return null
      }

      return brandingConfig
    } catch (error) {
      logger.error('âŒ Failed to get branding config:', error)
      throw error
    }
  }

  /**
   * è®¾ç½®å“ç‰Œé…ç½®
   * @param {Object} config å“ç‰Œé…ç½®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setBrandingConfig(brandingConfig) {
    try {
      const key = 'system:branding_config'
      const client = this.getClientSafe()

      // éªŒè¯é…ç½®æ•°æ®
      if (
        !brandingConfig ||
        typeof brandingConfig !== 'object' ||
        Object.keys(brandingConfig).length === 0
      ) {
        throw new Error('Invalid branding configuration data provided')
      }

      // ä½¿ç”¨hsetæ–¹æ³•è®¾ç½®å¤šä¸ªhashå­—æ®µ
      await client.hmset(key, brandingConfig)
      logger.info('ğŸ¨ Branding configuration updated')
    } catch (error) {
      logger.error('âŒ Failed to set branding config:', error)
      throw error
    }
  }

  /**
   * åˆ é™¤å“ç‰Œé…ç½®
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteBrandingConfig() {
    try {
      const key = 'system:branding_config'
      const result = await this.client.del(key)
      logger.info('ğŸ—‘ï¸ Branding configuration deleted')
      return result
    } catch (error) {
      logger.error('âŒ Failed to delete branding config:', error)
      throw error
    }
  }

  // ==================== é€šçŸ¥è®¾ç½®ç®¡ç† (3ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–é€šçŸ¥é…ç½®
   * @returns {Promise<Object|null>} é€šçŸ¥é…ç½®å¯¹è±¡æˆ–null
   */
  async getNotificationConfig() {
    try {
      const key = 'system:notification_config'
      const notificationConfig = await this.client.hgetall(key)

      if (!notificationConfig || Object.keys(notificationConfig).length === 0) {
        return null
      }

      return notificationConfig
    } catch (error) {
      logger.error('âŒ Failed to get notification config:', error)
      throw error
    }
  }

  /**
   * è®¾ç½®é€šçŸ¥é…ç½®
   * @param {Object} config é€šçŸ¥é…ç½®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setNotificationConfig(notificationConfig) {
    try {
      const key = 'system:notification_config'
      const client = this.getClientSafe()

      // éªŒè¯é…ç½®æ•°æ®
      if (
        !notificationConfig ||
        typeof notificationConfig !== 'object' ||
        Object.keys(notificationConfig).length === 0
      ) {
        throw new Error('Invalid notification configuration data provided')
      }

      // ä½¿ç”¨hsetæ–¹æ³•è®¾ç½®å¤šä¸ªhashå­—æ®µ
      await client.hmset(key, notificationConfig)
      logger.info('ğŸ”” Notification configuration updated')
    } catch (error) {
      logger.error('âŒ Failed to set notification config:', error)
      throw error
    }
  }

  /**
   * åˆ é™¤é€šçŸ¥é…ç½®
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteNotificationConfig() {
    try {
      const key = 'system:notification_config'
      const result = await this.client.del(key)
      logger.info('ğŸ—‘ï¸ Notification configuration deleted')
      return result
    } catch (error) {
      logger.error('âŒ Failed to delete notification config:', error)
      throw error
    }
  }

  // ==================== é…ç½®ç®¡ç† (3ä¸ªæ–¹æ³•) ====================

  /**
   * è®¾ç½®ç³»ç»Ÿè°ƒåº¦é…ç½®
   * @param {Object} configData é…ç½®æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setSystemSchedulingConfig(configData) {
    const key = 'system:scheduling_config'
    const client = this.getClientSafe()

    // éªŒè¯é…ç½®æ•°æ®
    if (!configData || typeof configData !== 'object' || Object.keys(configData).length === 0) {
      throw new Error('Invalid configuration data provided')
    }

    // ä½¿ç”¨hsetæ–¹æ³•è®¾ç½®å¤šä¸ªhashå­—æ®µ
    await client.hmset(key, configData)
    logger.info('ğŸ“ System scheduling configuration updated')
  }

  /**
   * è·å–ç³»ç»Ÿè°ƒåº¦é…ç½®ï¼ˆåŒ…å«é»˜è®¤é…ç½®å›é€€é€»è¾‘ï¼‰
   * @returns {Promise<Object>} ç³»ç»Ÿè°ƒåº¦é…ç½®å¯¹è±¡
   */
  async getSystemSchedulingConfig() {
    const key = 'system:scheduling_config'
    const schedulingConfig = await this.client.hgetall(key)

    // è¿”å›é»˜è®¤é…ç½®å¦‚æœæ²¡æœ‰å­˜å‚¨çš„é…ç½®
    if (!schedulingConfig || Object.keys(schedulingConfig).length === 0) {
      const defaultConfig = {
        defaultStrategy: 'least_recent',
        enableAccountOverride: 'true',
        enableGroupOverride: 'true'
      }

      // ä¿å­˜é»˜è®¤é…ç½®åˆ°Redis
      await this.setSystemSchedulingConfig(defaultConfig)
      return defaultConfig
    }

    return schedulingConfig
  }

  /**
   * åˆ é™¤ç³»ç»Ÿè°ƒåº¦é…ç½®
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteSystemSchedulingConfig() {
    const key = 'system:scheduling_config'
    return await this.client.del(key)
  }

  // ==================== ç®¡ç†å‘˜ä¿¡æ¯ç®¡ç† (4ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–æ‰€æœ‰ç®¡ç†å‘˜ä¿¡æ¯
   * @returns {Promise<Array>} ç®¡ç†å‘˜ä¿¡æ¯æ•°ç»„
   */
  async getAllAdmins() {
    try {
      const keys = await this.client.keys('admin:*')
      const admins = []

      for (const key of keys) {
        // è¿‡æ»¤æ‰ç”¨æˆ·åæ˜ å°„é”®ï¼Œåªå¤„ç†å®é™…çš„ç®¡ç†å‘˜æ•°æ®
        if (key.startsWith('admin_username:')) {
          continue
        }

        const adminData = await this.client.hgetall(key)
        if (adminData && Object.keys(adminData).length > 0) {
          const adminId = key.replace('admin:', '')
          admins.push({
            id: adminId,
            ...adminData
          })
        }
      }

      return admins
    } catch (error) {
      logger.error('âŒ Failed to get all admins:', error)
      throw error
    }
  }

  /**
   * æ ¹æ®IDè·å–ç®¡ç†å‘˜ä¿¡æ¯
   * @param {string} adminId ç®¡ç†å‘˜ID
   * @returns {Promise<Object|null>} ç®¡ç†å‘˜ä¿¡æ¯å¯¹è±¡æˆ–null
   */
  async getAdminById(adminId) {
    try {
      const key = `admin:${adminId}`
      const adminData = await this.client.hgetall(key)

      if (!adminData || Object.keys(adminData).length === 0) {
        return null
      }

      return {
        id: adminId,
        ...adminData
      }
    } catch (error) {
      logger.error(`âŒ Failed to get admin by ID ${adminId}:`, error)
      throw error
    }
  }

  /**
   * è®¾ç½®ç®¡ç†å‘˜æ•°æ®
   * @param {string} adminId ç®¡ç†å‘˜ID
   * @param {Object} adminData ç®¡ç†å‘˜æ•°æ®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} ç®¡ç†å‘˜æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setAdmin(adminId, adminData) {
    try {
      const key = `admin:${adminId}`
      const client = this.getClientSafe()

      // éªŒè¯ç®¡ç†å‘˜æ•°æ®
      if (!adminData || typeof adminData !== 'object' || Object.keys(adminData).length === 0) {
        throw new Error('Invalid admin data provided')
      }

      // è®¾ç½®ç®¡ç†å‘˜æ•°æ®
      await client.hmset(key, adminData)

      // ç»´æŠ¤ç”¨æˆ·åæ˜ å°„ï¼ˆå¦‚æœæä¾›äº†ç”¨æˆ·åï¼‰
      if (adminData.username) {
        const usernameMapKey = `admin_username:${adminData.username}`
        await client.set(usernameMapKey, adminId)
      }

      logger.info(`ğŸ‘¤ Admin ${adminId} data updated`)
    } catch (error) {
      logger.error(`âŒ Failed to set admin ${adminId}:`, error)
      throw error
    }
  }

  /**
   * åˆ é™¤ç®¡ç†å‘˜
   * @param {string} adminId ç®¡ç†å‘˜ID
   * @returns {Promise<number>} åˆ é™¤çš„è®°å½•æ•°
   */
  async deleteAdmin(adminId) {
    try {
      const key = `admin:${adminId}`

      // è·å–ç®¡ç†å‘˜æ•°æ®ä»¥ä¾¿æ¸…ç†ç”¨æˆ·åæ˜ å°„
      const adminData = await this.client.hgetall(key)

      // åˆ é™¤ç®¡ç†å‘˜æ•°æ®
      const result = await this.client.del(key)

      // æ¸…ç†ç”¨æˆ·åæ˜ å°„
      if (adminData && adminData.username) {
        const usernameMapKey = `admin_username:${adminData.username}`
        await this.client.del(usernameMapKey)
      }

      logger.info(`ğŸ—‘ï¸ Admin ${adminId} deleted`)
      return result
    } catch (error) {
      logger.error(`âŒ Failed to delete admin ${adminId}:`, error)
      throw error
    }
  }

  // ==================== 2FAé…ç½®ç®¡ç† (3ä¸ªæ–¹æ³•) ====================

  /**
   * è·å–æŒ‡å®šç”¨æˆ·åçš„2FAé…ç½®
   * @param {string} username ç”¨æˆ·å
   * @returns {Promise<Object|null>} 2FAé…ç½®å¯¹è±¡æˆ–null
   */
  async getTwoFactorConfig(username) {
    try {
      const key = `2fa:config:${username}`
      const twoFactorConfig = await this.client.hgetall(key)

      if (!twoFactorConfig || Object.keys(twoFactorConfig).length === 0) {
        return null
      }

      return {
        username,
        ...twoFactorConfig
      }
    } catch (error) {
      logger.error(`âŒ Failed to get 2FA config for ${username}:`, error)
      throw error
    }
  }

  /**
   * è®¾ç½®æŒ‡å®šç”¨æˆ·åçš„2FAé…ç½®
   * @param {string} username ç”¨æˆ·å
   * @param {Object} config 2FAé…ç½®å¯¹è±¡
   * @returns {Promise<void>}
   * @throws {Error} é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡ºé”™è¯¯
   */
  async setTwoFactorConfig(username, twoFactorConfig) {
    try {
      const key = `2fa:config:${username}`
      const client = this.getClientSafe()

      // éªŒè¯é…ç½®æ•°æ®
      if (
        !twoFactorConfig ||
        typeof twoFactorConfig !== 'object' ||
        Object.keys(twoFactorConfig).length === 0
      ) {
        throw new Error('Invalid 2FA configuration data provided')
      }

      // éªŒè¯ç”¨æˆ·å
      if (!username || typeof username !== 'string' || username.trim().length === 0) {
        throw new Error('Invalid username provided')
      }

      // è®¾ç½®2FAé…ç½®ï¼ŒåŒ…å«å®‰å…¨æ•æ„Ÿä¿¡æ¯çš„å¤„ç†
      const configToStore = {
        ...twoFactorConfig,
        createdAt: twoFactorConfig.createdAt || new Date().toISOString(),
        updatedAt: new Date().toISOString()
      }

      await client.hmset(key, configToStore)
      logger.info(`ğŸ” 2FA configuration updated for user: ${username}`)
    } catch (error) {
      logger.error(`âŒ Failed to set 2FA config for ${username}:`, error)
      throw error
    }
  }

  /**
   * è·å–æ‰€æœ‰2FAé…ç½®
   * @returns {Promise<Array>} æ‰€æœ‰2FAé…ç½®æ•°ç»„
   */
  async getAllTwoFactorConfigs() {
    try {
      const keys = await this.client.keys('2fa:config:*')
      const configs = []

      for (const key of keys) {
        const configData = await this.client.hgetall(key)
        if (configData && Object.keys(configData).length > 0) {
          const username = key.replace('2fa:config:', '')
          configs.push({
            username,
            ...configData
          })
        }
      }

      return configs
    } catch (error) {
      logger.error('âŒ Failed to get all 2FA configs:', error)
      throw error
    }
  }

  /**
   * è®°å½•è¯·æ±‚æ—¥å¿—åˆ°Redisï¼ˆå¢å¼ºç‰ˆæœ¬ - æ”¯æŒHeadersã€è¯¦ç»†ä¿¡æ¯å’Œæ™ºèƒ½åˆå¹¶ï¼‰
   * @param {string} keyId API Key ID
   * @param {Object} logData æ—¥å¿—æ•°æ®å¯¹è±¡
   * @param {Object} logData.requestHeaders è¿‡æ»¤åçš„è¯·æ±‚å¤´ä¿¡æ¯
   * @param {Object} logData.responseHeaders å“åº”å¤´ä¿¡æ¯
   * @param {Object} logData.tokenDetails è¯¦ç»†çš„Tokenç»Ÿè®¡ä¿¡æ¯
   * @param {Object} logData.costDetails è´¹ç”¨è¯¦ç»†ä¿¡æ¯
   * @param {number} ttl è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤604800ç§’ï¼ˆ7å¤©ï¼‰
   * @param {Object} mergeOptions æ—¥å¿—åˆå¹¶é…ç½®é€‰é¡¹
   * @param {boolean} mergeOptions.enabled æ˜¯å¦å¯ç”¨åˆå¹¶åŠŸèƒ½ï¼Œé»˜è®¤false
   * @param {number} mergeOptions.windowMs åˆå¹¶æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤15000ï¼ˆ15ç§’ï¼‰
   * @param {string} mergeOptions.priority æ—¥å¿—ä¼˜å…ˆçº§ï¼ˆenhanced|basic|unknownï¼‰ï¼Œé»˜è®¤'unknown'
   * @param {boolean} mergeOptions.forceWrite æ˜¯å¦å¼ºåˆ¶å†™å…¥ï¼ˆå¿½ç•¥åˆå¹¶ï¼‰ï¼Œé»˜è®¤false
   * @param {Function} mergeOptions.onDuplicate å¤„ç†é‡å¤æ—¥å¿—çš„å›è°ƒå‡½æ•°
   * @returns {Promise<string>} æ—¥å¿—å”¯ä¸€ID
   */
  async logRequest(keyId, logData, ttl = 604800, mergeOptions = {}) {
    try {
      const now = new Date()
      const today = getDateStringInTimezone(now)
      const timestamp = now.getTime()
      const logId = `request_log:${keyId}:${timestamp}`

      // è®¾ç½®åˆå¹¶é€‰é¡¹çš„é»˜è®¤å€¼
      const mergeConfig = {
        enabled: mergeOptions.enabled || false,
        windowMs: mergeOptions.windowMs || 15000, // 15ç§’æ—¶é—´çª—å£
        priority: mergeOptions.priority || 'unknown',
        forceWrite: mergeOptions.forceWrite || false,
        onDuplicate: mergeOptions.onDuplicate || null,
        ...mergeOptions
      }

      const defaultData = {
        timestamp,
        keyId,
        path: '',
        method: '',
        status: 0,
        model: '',
        tokens: 0,
        responseTime: 0,
        error: null,
        // æ–°å¢å­—æ®µ
        requestHeaders: null,
        responseHeaders: null,
        tokenDetails: null,
        costDetails: null,
        // åˆå¹¶ç›¸å…³å­—æ®µ
        logVersion: '2.1',
        priority: mergeConfig.priority,
        mergeCount: 0,
        originalTimestamp: timestamp,
        isDuplicate: false
      }

      const finalLogData = { ...defaultData, ...logData }

      // æ™ºèƒ½åˆå¹¶é€»è¾‘ - å¦‚æœå¯ç”¨åˆå¹¶åŠŸèƒ½ä¸”ä¸å¼ºåˆ¶å†™å…¥
      if (mergeConfig.enabled && !mergeConfig.forceWrite) {
        logger.debug(`ğŸ”„ æ£€æŸ¥é‡å¤æ—¥å¿—ï¼ŒkeyId: ${keyId}, æ—¶é—´çª—å£: ${mergeConfig.windowMs}ms`)

        try {
          // æ£€æµ‹é‡å¤æ—¥å¿—
          const duplicates = await this.detectDuplicateLogs(
            keyId,
            finalLogData,
            mergeConfig.windowMs
          )

          if (duplicates.length > 0) {
            logger.debug(`ğŸ” å‘ç° ${duplicates.length} ä¸ªé‡å¤æ—¥å¿—å€™é€‰é¡¹`)

            // æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„é‡å¤æ—¥å¿—
            const bestMatch = duplicates.reduce((best, current) =>
              current.similarity > best.similarity ? current : best
            )

            // å¦‚æœç›¸ä¼¼åº¦è¶³å¤Ÿé«˜ï¼Œåˆ™æ‰§è¡Œåˆå¹¶
            if (bestMatch.similarity > 0.8) {
              // 80%ç›¸ä¼¼åº¦é˜ˆå€¼
              logger.info(
                `ğŸš€ åˆå¹¶æ—¥å¿—: ${logId} -> ${bestMatch.logId} (ç›¸ä¼¼åº¦: ${(bestMatch.similarity * 100).toFixed(1)}%)`
              )

              // æ‰§è¡Œåˆå¹¶æ“ä½œ
              const mergeResult = await this.mergeLogEntries(bestMatch.logId, [logId], {
                priority: mergeConfig.priority === 'enhanced' ? 'higher' : 'lower',
                preserveHeaders: true,
                aggregateTokens: true
              })

              // è°ƒç”¨é‡å¤å¤„ç†å›è°ƒ
              if (mergeConfig.onDuplicate && typeof mergeConfig.onDuplicate === 'function') {
                try {
                  await mergeConfig.onDuplicate({
                    originalLogId: bestMatch.logId,
                    duplicateLogId: logId,
                    similarity: bestMatch.similarity,
                    mergeResult
                  })
                } catch (callbackError) {
                  logger.warn('âš ï¸ é‡å¤æ—¥å¿—å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥:', callbackError.message)
                }
              }

              return mergeResult.mergedLogId
            }
          }
        } catch (mergeError) {
          logger.warn('âš ï¸ æ—¥å¿—åˆå¹¶æ£€æµ‹å¤±è´¥ï¼Œç»§ç»­æ­£å¸¸å†™å…¥:', mergeError.message)
          // åˆå¹¶å¤±è´¥æ—¶ç»§ç»­æ­£å¸¸å†™å…¥ï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½
        }
      }

      // æ­£å¸¸å†™å…¥é€»è¾‘ï¼ˆå¦‚æœæ²¡æœ‰åˆå¹¶æˆ–åˆå¹¶å¤±è´¥ï¼‰

      // å¤„ç†å¤æ‚å¯¹è±¡å­—æ®µ - åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²ä»¥æ”¯æŒRediså­˜å‚¨
      if (finalLogData.requestHeaders && typeof finalLogData.requestHeaders === 'object') {
        finalLogData.requestHeaders = JSON.stringify(finalLogData.requestHeaders)
      }

      if (finalLogData.responseHeaders && typeof finalLogData.responseHeaders === 'object') {
        finalLogData.responseHeaders = JSON.stringify(finalLogData.responseHeaders)
      }

      if (finalLogData.tokenDetails && typeof finalLogData.tokenDetails === 'object') {
        finalLogData.tokenDetails = JSON.stringify(finalLogData.tokenDetails)
      }

      if (finalLogData.costDetails && typeof finalLogData.costDetails === 'object') {
        finalLogData.costDetails = JSON.stringify(finalLogData.costDetails)
      }

      const client = this.getClientSafe()

      // ä½¿ç”¨Pipelineæ‰¹é‡æ“ä½œæå‡æ€§èƒ½
      const pipeline = client.pipeline()

      // 1. å­˜å‚¨æ—¥å¿—æ•°æ®
      pipeline.hmset(logId, finalLogData)
      pipeline.expire(logId, ttl)

      // 2. å»ºç«‹å¤šç»´åº¦ç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢
      const dailyIndex = `request_log_index:${keyId}:${today}`
      pipeline.sadd(dailyIndex, logId)
      pipeline.expire(dailyIndex, ttl)

      // 3. æŒ‰çŠ¶æ€ç ç´¢å¼•ï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾é”™è¯¯æ—¥å¿—ï¼‰
      if (finalLogData.status) {
        const statusIndex = `request_log_status:${finalLogData.status}:${today}`
        pipeline.sadd(statusIndex, logId)
        pipeline.expire(statusIndex, ttl)
      }

      // 4. æŒ‰æ¨¡å‹ç´¢å¼•ï¼ˆç”¨äºæ¨¡å‹ä½¿ç”¨ç»Ÿè®¡ï¼‰
      if (finalLogData.model) {
        const modelIndex = `request_log_model:${finalLogData.model}:${today}`
        pipeline.sadd(modelIndex, logId)
        pipeline.expire(modelIndex, ttl)
      }

      // 5. å…¨å±€æ—¶é—´ç´¢å¼•ï¼ˆç”¨äºæ—¶é—´èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–ï¼‰
      const hourKey = `request_log_time:${Math.floor(timestamp / 3600000)}`
      pipeline.sadd(hourKey, logId)
      pipeline.expire(hourKey, ttl)

      // 6. é”™è¯¯æ—¥å¿—ç‰¹æ®Šç´¢å¼•
      if (finalLogData.error && finalLogData.error !== 'null') {
        const errorIndex = `request_log_errors:${today}`
        pipeline.sadd(errorIndex, logId)
        pipeline.expire(errorIndex, ttl)
      }

      await pipeline.exec()

      return logId
    } catch (error) {
      logger.error('Failed to log request:', error)
      throw error
    }
  }

  /**
   * æœç´¢è¯·æ±‚æ—¥å¿—ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @param {Object} options æŸ¥è¯¢é€‰é¡¹ï¼ˆåˆ†é¡µã€æ’åºç­‰ï¼‰
   * @param {boolean} options.includeEnhancedStats æ˜¯å¦åŒ…å«å¢å¼ºçš„ç»Ÿè®¡ä¿¡æ¯
   * @returns {Promise<Array>} æ—¥å¿—æ•°ç»„
   */
  async searchLogs(query = {}, options = {}) {
    const { offset = 0, limit = 20, sortOrder = 'desc', includeEnhancedStats = false } = options
    const startTime = Date.now()

    try {
      const client = this.getClientSafe()
      let matchingLogs = []

      // è®°å½•æœç´¢å‚æ•°
      if (query.search) {
        logger.debug(`æ‰§è¡Œæ–‡æœ¬æœç´¢: "${query.search}", é™åˆ¶: ${limit}, åç§»: ${offset}`)
      }

      // ä¼˜åŒ–ç­–ç•¥ï¼šåŸºäºæŸ¥è¯¢æ¡ä»¶é€‰æ‹©æœ€ä½³æœç´¢æ–¹æ³•
      if (query.status && query.dateRange) {
        // ä¼˜å…ˆä½¿ç”¨çŠ¶æ€ç ç´¢å¼•
        matchingLogs = await this._searchLogsByStatusAndDate(client, query.status, query.dateRange)
      } else if (query.model && query.dateRange) {
        // ä½¿ç”¨æ¨¡å‹ç´¢å¼•
        matchingLogs = await this._searchLogsByModelAndDate(client, query.model, query.dateRange)
      } else if (query.hasError && query.dateRange) {
        // ä½¿ç”¨é”™è¯¯ç´¢å¼•
        matchingLogs = await this._searchErrorLogsByDate(client, query.dateRange)
      } else if (query.keyId && query.dateRange) {
        // å¦‚æœæœ‰ keyId å’Œæ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨æ—¥å¿—ç´¢å¼•
        matchingLogs = await this._searchLogsByKeyIdAndDate(client, query.keyId, query.dateRange)
      } else if (query.keyId) {
        // å¦‚æœåªæœ‰ keyIdï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„æ¨¡å¼åŒ¹é…
        const pattern = `request_log:${query.keyId}:*`
        matchingLogs = await client.keys(pattern)
      } else if (query.dateRange) {
        // å¦‚æœåªæœ‰æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨æ—¥å¿—ç´¢å¼•
        matchingLogs = await this._searchLogsByDateRange(client, query.dateRange)
      } else if (query.status) {
        // ä»…çŠ¶æ€ç æŸ¥è¯¢ï¼Œä½¿ç”¨ä»Šæ—¥çŠ¶æ€ç ç´¢å¼•
        const today = getDateStringInTimezone()
        const statusIndex = `request_log_status:${query.status}:${today}`
        try {
          matchingLogs = await client.smembers(statusIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else if (query.model) {
        // ä»…æ¨¡å‹æŸ¥è¯¢ï¼Œä½¿ç”¨ä»Šæ—¥æ¨¡å‹ç´¢å¼•
        const today = getDateStringInTimezone()
        const modelIndex = `request_log_model:${query.model}:${today}`
        try {
          matchingLogs = await client.smembers(modelIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else {
        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å®é™…å­˜åœ¨çš„é”®æ¨¡å¼è¿›è¡Œå…¨é‡æœç´¢
        logger.info('ğŸ” DEBUGGING: Performing full scan for request logs')

        // æœç´¢æ‰€æœ‰è¯·æ±‚æ—¥å¿—ç›¸å…³çš„é”®æ¨¡å¼
        const [indexKeys, statusKeys, modelKeys, errorKeys, timeKeys] = await Promise.all([
          client.keys('request_log_index:*'),
          client.keys('request_log_status:*'),
          client.keys('request_log_model:*'),
          client.keys('request_log_errors:*'),
          client.keys('request_log_time:*')
        ])

        // åˆå¹¶æ‰€æœ‰ç´¢å¼•é”®ï¼Œä»ä¸­æå–ä¸»æ—¥å¿—é”®
        const allIndexKeys = [...indexKeys, ...statusKeys, ...modelKeys, ...errorKeys, ...timeKeys]
        logger.info('ğŸ” DEBUGGING: Found index keys:', {
          indexKeys: indexKeys.length,
          statusKeys: statusKeys.length,
          modelKeys: modelKeys.length,
          errorKeys: errorKeys.length,
          timeKeys: timeKeys.length,
          totalIndexKeys: allIndexKeys.length
        })

        // ä»ç´¢å¼•é”®ä¸­æå–å®é™…çš„æ—¥å¿—é”®
        const extractedLogKeys = new Set()
        for (const indexKey of allIndexKeys) {
          try {
            // å¯¹äºé›†åˆç´¢å¼•ï¼Œè·å–æˆå‘˜
            if (
              indexKey.includes('request_log_index:') ||
              indexKey.includes('request_log_status:') ||
              indexKey.includes('request_log_model:') ||
              indexKey.includes('request_log_errors:')
            ) {
              const members = await client.smembers(indexKey)
              members.forEach((member) => extractedLogKeys.add(member))
            }
            // å¯¹äºæ—¶é—´ç´¢å¼•ï¼Œè·å–æˆå‘˜
            else if (indexKey.includes('request_log_time:')) {
              const members = await client.smembers(indexKey)
              members.forEach((member) => extractedLogKeys.add(member))
            }
          } catch (error) {
            logger.debug(`Failed to extract from index ${indexKey}:`, error.message)
          }
        }

        matchingLogs = Array.from(extractedLogKeys)
        logger.info('ğŸ” DEBUGGING: Extracted log keys:', {
          extractedCount: matchingLogs.length,
          sampleKeys: matchingLogs.slice(0, 5)
        })

        // æŒ‰æ—¶é—´æˆ³æ’åºå¹¶æˆªå–æœ€è¿‘çš„è®°å½•
        matchingLogs = matchingLogs
          .filter((key) => key && key.includes(':')) // ç¡®ä¿é”®æ ¼å¼æ­£ç¡®
          .sort((a, b) => {
            const timestampA = parseInt(a.split(':')[2]) || 0
            const timestampB = parseInt(b.split(':')[2]) || 0
            return sortOrder === 'desc' ? timestampB - timestampA : timestampA - timestampB
          })
          .slice(0, Math.min(1000, offset + limit * 5)) // é™åˆ¶æœ€å¤§æ‰«æé‡
      }

      // é™åˆ¶æ–‡æœ¬æœç´¢çš„æ‰«æèŒƒå›´ï¼Œé¿å…æ€§èƒ½é—®é¢˜
      if (query.search && matchingLogs.length > 2000) {
        logger.warn(`æ–‡æœ¬æœç´¢çš„ç»“æœé›†è¿‡å¤§ (${matchingLogs.length})ï¼Œé™åˆ¶åˆ° 2000 æ¡`)
        matchingLogs = matchingLogs.slice(0, 2000)
      }

      // åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
      if (Object.keys(query).length > 0) {
        matchingLogs = await this._filterLogsByQuery(client, matchingLogs, query)
      }

      // æ’åºï¼ˆå¦‚æœè¿˜æœªæ’åºï¼‰
      if (!query.keyId || Object.keys(query).length > 1) {
        matchingLogs.sort((a, b) => {
          const timestampA = parseInt(a.split(':')[2]) || 0
          const timestampB = parseInt(b.split(':')[2]) || 0
          return sortOrder === 'desc' ? timestampB - timestampA : timestampA - timestampB
        })
      }

      // åˆ†é¡µ
      const paginatedLogs = matchingLogs.slice(offset, offset + limit)
      logger.info('ğŸ” DEBUGGING: About to fetch log data:', {
        totalMatching: matchingLogs.length,
        paginatedCount: paginatedLogs.length,
        samplePaginatedKeys: paginatedLogs.slice(0, 3)
      })

      // æ‰¹é‡è·å–æ—¥å¿—è¯¦æƒ…
      const pipeline = client.pipeline()
      paginatedLogs.forEach((logKey) => pipeline.hgetall(logKey))

      const results = await pipeline.exec()
      logger.info('ğŸ” DEBUGGING: Pipeline results:', {
        resultsCount: results.length,
        sampleResults: results.slice(0, 2).map(([err, data]) => ({
          error: err?.message,
          dataKeys: data ? Object.keys(data) : null,
          hasData: data && Object.keys(data).length > 0
        }))
      })

      const logs = results
        .map(([err, logData], index) => {
          if (err || !logData || Object.keys(logData).length === 0) {
            return null
          }

          // ååºåˆ—åŒ–JSONå­—ç¬¦ä¸²å­—æ®µ
          const processedLogData = { ...logData }

          // é€šç”¨çš„JSONååºåˆ—åŒ–å‡½æ•°
          const safeJSONParse = (fieldName, value) => {
            if (!value || typeof value !== 'string') {
              return null
            }

            try {
              return JSON.parse(value)
            } catch (e) {
              logger.debug(
                `Failed to parse ${fieldName} for log ${paginatedLogs[index]}:`,
                e.message
              )
              return null
            }
          }

          // æ•°æ®è§£å‹ç¼©å’Œååºåˆ—åŒ–
          const jsonFields = ['requestHeaders', 'responseHeaders', 'tokenDetails', 'costDetails']
          jsonFields.forEach((field) => {
            if (processedLogData[field]) {
              processedLogData[field] = safeJSONParse(field, processedLogData[field])
            }
          })

          // æ•°å€¼ç±»å‹è½¬æ¢
          const numericFields = {
            timestamp: 'int',
            duration: 'int',
            responseTime: 'float',
            inputTokens: 'int',
            outputTokens: 'int',
            totalTokens: 'int',
            cost: 'float',
            status: 'int',
            tokens: 'int'
          }

          Object.entries(numericFields).forEach(([field, type]) => {
            if (processedLogData[field] !== undefined && processedLogData[field] !== '') {
              if (type === 'int') {
                processedLogData[field] = parseInt(processedLogData[field]) || 0
              } else if (type === 'float') {
                processedLogData[field] = parseFloat(processedLogData[field]) || 0
              }
            }
          })

          // è®¡ç®—å¢å¼ºç»Ÿè®¡ä¿¡æ¯
          const enhancedLog = {
            ...processedLogData,
            logId: paginatedLogs[index],
            timestamp: processedLogData.timestamp
          }

          // æ·»åŠ tokenSummaryï¼ˆæ€»æ˜¯åŒ…å«ï¼‰
          enhancedLog.tokenSummary = {
            totalTokens: enhancedLog.totalTokens || enhancedLog.tokens || 0,
            inputTokens: enhancedLog.inputTokens || 0,
            outputTokens: enhancedLog.outputTokens || 0,
            cost: enhancedLog.cost || 0
          }

          // æ·»åŠ æ ‡å¿—ä¿¡æ¯ï¼ˆæ€»æ˜¯åŒ…å«ï¼‰
          enhancedLog.hasHeaders = !!(
            (enhancedLog.requestHeaders &&
              Object.keys(enhancedLog.requestHeaders || {}).length > 0) ||
            (enhancedLog.responseHeaders &&
              Object.keys(enhancedLog.responseHeaders || {}).length > 0)
          )

          enhancedLog.hasBody = !!(
            (enhancedLog.requestBody && enhancedLog.requestBody.trim().length > 0) ||
            (enhancedLog.responseBody && enhancedLog.responseBody.trim().length > 0)
          )

          enhancedLog.isError = (enhancedLog.status || 0) >= 400
          enhancedLog.dateTime = enhancedLog.timestamp
            ? new Date(enhancedLog.timestamp).toISOString()
            : null

          // å¦‚æœå¯ç”¨äº†å¢å¼ºç»Ÿè®¡ï¼Œæ·»åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯
          if (includeEnhancedStats) {
            enhancedLog.metadata = {
              hasRequestHeaders: !!(
                enhancedLog.requestHeaders && Object.keys(enhancedLog.requestHeaders).length > 0
              ),
              hasResponseHeaders: !!(
                enhancedLog.responseHeaders && Object.keys(enhancedLog.responseHeaders).length > 0
              ),
              hasTokenDetails: !!(
                enhancedLog.tokenDetails && Object.keys(enhancedLog.tokenDetails || {}).length > 0
              ),
              hasCostDetails: !!(
                enhancedLog.costDetails && Object.keys(enhancedLog.costDetails || {}).length > 0
              ),
              processedAt: new Date().toISOString()
            }
          }

          return enhancedLog
        })
        .filter(Boolean)

      logger.info('ğŸ” DEBUGGING: Final processed logs:', {
        processedCount: logs.length,
        includeEnhancedStats,
        sampleLogData: logs.slice(0, 2).map((log) => ({
          logId: log.logId,
          keyId: log.keyId,
          timestamp: log.timestamp,
          hasHeaders: log.hasHeaders,
          hasBody: log.hasBody,
          tokenSummary: log.tokenSummary,
          fieldsCount: Object.keys(log).length
        }))
      })

      const endTime = Date.now()
      const searchTime = endTime - startTime

      // è®°å½•æœç´¢ç»“æœå’Œæ€§èƒ½
      if (query.search) {
        logger.debug(`æ–‡æœ¬æœç´¢å®Œæˆ: è€—æ—¶ ${searchTime}ms, æ‰¾åˆ° ${logs.length} æ¡ç»“æœ`)
      }

      return logs
    } catch (error) {
      logger.error('Failed to search logs:', error)
      return []
    }
  }

  /**
   * ç»Ÿè®¡æ—¥å¿—æ•°é‡ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @returns {Promise<number>} åŒ¹é…çš„æ—¥å¿—æ•°é‡
   */
  async countLogs(query = {}) {
    try {
      const client = this.getClientSafe()
      let matchingLogs = []

      // ä½¿ç”¨ä¸ searchLogs ç›¸åŒçš„ä¼˜åŒ–ç­–ç•¥
      if (query.status && query.dateRange) {
        matchingLogs = await this._searchLogsByStatusAndDate(client, query.status, query.dateRange)
      } else if (query.model && query.dateRange) {
        matchingLogs = await this._searchLogsByModelAndDate(client, query.model, query.dateRange)
      } else if (query.hasError && query.dateRange) {
        matchingLogs = await this._searchErrorLogsByDate(client, query.dateRange)
      } else if (query.keyId && query.dateRange) {
        matchingLogs = await this._searchLogsByKeyIdAndDate(client, query.keyId, query.dateRange)
      } else if (query.keyId) {
        const pattern = `request_log:${query.keyId}:*`
        matchingLogs = await client.keys(pattern)
      } else if (query.dateRange) {
        matchingLogs = await this._searchLogsByDateRange(client, query.dateRange)
      } else if (query.status) {
        const today = getDateStringInTimezone()
        const statusIndex = `request_log_status:${query.status}:${today}`
        try {
          matchingLogs = await client.smembers(statusIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else if (query.model) {
        const today = getDateStringInTimezone()
        const modelIndex = `request_log_model:${query.model}:${today}`
        try {
          matchingLogs = await client.smembers(modelIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else {
        // å…¨é‡æ‰«ææ—¶ï¼Œå¯ä»¥ç›´æ¥è¿”å›é”®æ•°é‡è€Œä¸éœ€è¦è·å–å†…å®¹
        matchingLogs = await client.keys('request_log:*')
      }

      // åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
      if (Object.keys(query).length > 0 && !(query.keyId && Object.keys(query).length === 1)) {
        matchingLogs = await this._filterLogsByQuery(client, matchingLogs, query)
      }

      return matchingLogs.length
    } catch (error) {
      logger.error('Failed to count logs:', error)
      return 0
    }
  }

  /**
   * èšåˆæ—¥å¿—ç»Ÿè®¡
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @returns {Promise<Object>} èšåˆç»Ÿè®¡ç»“æœ
   */
  async aggregateLogs(query = {}) {
    try {
      const client = this.getClientSafe()
      let matchingLogs = []

      // ä½¿ç”¨ä¸ searchLogs ç›¸åŒçš„ä¼˜åŒ–ç­–ç•¥
      if (query.status && query.dateRange) {
        matchingLogs = await this._searchLogsByStatusAndDate(client, query.status, query.dateRange)
      } else if (query.model && query.dateRange) {
        matchingLogs = await this._searchLogsByModelAndDate(client, query.model, query.dateRange)
      } else if (query.hasError && query.dateRange) {
        matchingLogs = await this._searchErrorLogsByDate(client, query.dateRange)
      } else if (query.keyId && query.dateRange) {
        matchingLogs = await this._searchLogsByKeyIdAndDate(client, query.keyId, query.dateRange)
      } else if (query.keyId) {
        const pattern = `request_log:${query.keyId}:*`
        matchingLogs = await client.keys(pattern)
      } else if (query.dateRange) {
        matchingLogs = await this._searchLogsByDateRange(client, query.dateRange)
      } else {
        matchingLogs = await client.keys('request_log:*')
      }

      // åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
      if (Object.keys(query).length > 0) {
        matchingLogs = await this._filterLogsByQuery(client, matchingLogs, query)
      }

      const pipeline = client.pipeline()
      matchingLogs.forEach((logKey) => pipeline.hgetall(logKey))

      const results = await pipeline.exec()

      const stats = {
        totalRequests: 0,
        totalTokens: 0,
        totalResponseTime: 0,
        statusCodes: {},
        models: {},
        apiKeys: {}
      }

      results.forEach(([err, logData]) => {
        if (err || !logData) {
          return
        }

        stats.totalRequests++
        stats.totalTokens += parseInt(logData.tokens) || 0
        stats.totalResponseTime += parseFloat(logData.responseTime) || 0

        // çŠ¶æ€ç ç»Ÿè®¡
        const status = logData.status || 'unknown'
        stats.statusCodes[status] = (stats.statusCodes[status] || 0) + 1

        // æ¨¡å‹ç»Ÿè®¡
        const model = logData.model || 'unknown'
        stats.models[model] = (stats.models[model] || 0) + 1

        // API Keyç»Ÿè®¡
        const keyId = logData.keyId || 'unknown'
        stats.apiKeys[keyId] = (stats.apiKeys[keyId] || 0) + 1
      })

      return stats
    } catch (error) {
      logger.error('Failed to aggregate logs:', error)
      return {}
    }
  }

  /**
   * é€šè¿‡ keyId å’Œæ—¥æœŸèŒƒå›´æœç´¢æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {string} keyId API Key ID
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´ {start, end}
   * @returns {Promise<Array>} åŒ¹é…çš„æ—¥å¿—é”®æ•°ç»„
   */
  async _searchLogsByKeyIdAndDate(client, keyId, dateRange) {
    const { start, end } = dateRange
    const startTimestamp = new Date(start).getTime()
    const endTimestamp = new Date(end).getTime()

    // ä½¿ç”¨æ›´ç²¾ç¡®çš„æ¨¡å¼åŒ¹é…
    const pattern = `request_log:${keyId}:*`
    const logs = await client.keys(pattern)

    // è¿‡æ»¤æ—¶é—´èŒƒå›´
    return logs.filter((logKey) => {
      const timestamp = parseInt(logKey.split(':')[2]) || 0
      return timestamp >= startTimestamp && timestamp <= endTimestamp
    })
  }

  /**
   * é€šè¿‡æ—¥æœŸèŒƒå›´æœç´¢æ—¥å¿—ï¼ˆç´¢å¼•ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´ {start, end}
   * @returns {Promise<Array>} åŒ¹é…çš„æ—¥å¿—é”®æ•°ç»„
   */
  async _searchLogsByDateRange(client, dateRange) {
    const { start, end } = dateRange
    const startTimestamp = new Date(start).getTime()
    const endTimestamp = new Date(end).getTime()

    // ä¼˜åŒ–ç­–ç•¥ï¼šä½¿ç”¨æ—¶é—´ç´¢å¼•è€Œä¸æ˜¯å…¨é‡æ‰«æ
    const startHour = Math.floor(startTimestamp / 3600000)
    const endHour = Math.floor(endTimestamp / 3600000)

    const allLogs = new Set()

    // å¦‚æœæ—¶é—´èŒƒå›´è·¨åº¦ä¸å¤§ï¼ˆå°‘äº24å°æ—¶ï¼‰ï¼Œä½¿ç”¨å°æ—¶ç´¢å¼•
    if (endHour - startHour <= 24) {
      for (let hour = startHour; hour <= endHour; hour++) {
        const hourKey = `request_log_time:${hour}`
        try {
          const hourLogs = await client.smembers(hourKey)
          hourLogs.forEach((logKey) => allLogs.add(logKey))
        } catch (error) {
          // ç´¢å¼•ä¸å­˜åœ¨æ—¶å¿½ç•¥é”™è¯¯
        }
      }

      // è½¬æ¢ä¸ºæ•°ç»„å¹¶è¿›è¡Œç²¾ç¡®æ—¶é—´è¿‡æ»¤
      return Array.from(allLogs).filter((logKey) => {
        const timestamp = parseInt(logKey.split(':')[2]) || 0
        return timestamp >= startTimestamp && timestamp <= endTimestamp
      })
    } else {
      // é•¿æ—¶é—´èŒƒå›´é™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•
      const allLogKeys = await client.keys('request_log:*')
      return allLogKeys.filter((logKey) => {
        const timestamp = parseInt(logKey.split(':')[2]) || 0
        return timestamp >= startTimestamp && timestamp <= endTimestamp
      })
    }
  }

  /**
   * é€šè¿‡çŠ¶æ€ç å’Œæ—¥æœŸèŒƒå›´æœç´¢æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {string} status çŠ¶æ€ç 
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´
   * @returns {Promise<Array>} åŒ¹é…çš„æ—¥å¿—é”®æ•°ç»„
   */
  async _searchLogsByStatusAndDate(client, status, dateRange) {
    const { start, end } = dateRange
    const startDate = new Date(start)
    const endDate = new Date(end)
    const results = new Set()

    // éå†æ—¥æœŸèŒƒå›´å†…çš„æ¯ä¸€å¤©
    for (let d = new Date(startDate); d <= endDate; d.setDate(d.getDate() + 1)) {
      const dateStr = getDateStringInTimezone(d)
      const statusIndex = `request_log_status:${status}:${dateStr}`

      try {
        const dayLogs = await client.smembers(statusIndex)
        dayLogs.forEach((logKey) => results.add(logKey))
      } catch (error) {
        // ç´¢å¼•ä¸å­˜åœ¨æ—¶å¿½ç•¥
      }
    }

    return Array.from(results)
  }

  /**
   * é€šè¿‡æ¨¡å‹å’Œæ—¥æœŸèŒƒå›´æœç´¢æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {string} model æ¨¡å‹åç§°
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´
   * @returns {Promise<Array>} åŒ¹é…çš„æ—¥å¿—é”®æ•°ç»„
   */
  async _searchLogsByModelAndDate(client, model, dateRange) {
    const { start, end } = dateRange
    const startDate = new Date(start)
    const endDate = new Date(end)
    const results = new Set()

    // éå†æ—¥æœŸèŒƒå›´å†…çš„æ¯ä¸€å¤©
    for (let d = new Date(startDate); d <= endDate; d.setDate(d.getDate() + 1)) {
      const dateStr = getDateStringInTimezone(d)
      const modelIndex = `request_log_model:${model}:${dateStr}`

      try {
        const dayLogs = await client.smembers(modelIndex)
        dayLogs.forEach((logKey) => results.add(logKey))
      } catch (error) {
        // ç´¢å¼•ä¸å­˜åœ¨æ—¶å¿½ç•¥
      }
    }

    return Array.from(results)
  }

  /**
   * é€šè¿‡æ—¥æœŸèŒƒå›´æœç´¢é”™è¯¯æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {Object} dateRange æ—¥æœŸèŒƒå›´
   * @returns {Promise<Array>} åŒ¹é…çš„é”™è¯¯æ—¥å¿—é”®æ•°ç»„
   */
  async _searchErrorLogsByDate(client, dateRange) {
    const { start, end } = dateRange
    const startDate = new Date(start)
    const endDate = new Date(end)
    const results = new Set()

    // éå†æ—¥æœŸèŒƒå›´å†…çš„æ¯ä¸€å¤©
    for (let d = new Date(startDate); d <= endDate; d.setDate(d.getDate() + 1)) {
      const dateStr = getDateStringInTimezone(d)
      const errorIndex = `request_log_errors:${dateStr}`

      try {
        const dayLogs = await client.smembers(errorIndex)
        dayLogs.forEach((logKey) => results.add(logKey))
      } catch (error) {
        // ç´¢å¼•ä¸å­˜åœ¨æ—¶å¿½ç•¥
      }
    }

    return Array.from(results)
  }

  /**
   * é€šè¿‡æŸ¥è¯¢æ¡ä»¶è¿‡æ»¤æ—¥å¿—
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {Array} logKeys è¦è¿‡æ»¤çš„æ—¥å¿—é”®æ•°ç»„
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @returns {Promise<Array>} è¿‡æ»¤åçš„æ—¥å¿—é”®æ•°ç»„
   */
  async _filterLogsByQuery(client, logKeys, query) {
    if (logKeys.length === 0) {
      return []
    }

    // æ‰¹é‡è·å–æ—¥å¿—æ•°æ®ä»¥æ”¯æŒå¤æ‚è¿‡æ»¤
    const pipeline = client.pipeline()
    logKeys.forEach((logKey) => pipeline.hgetall(logKey))

    const results = await pipeline.exec()
    const filteredKeys = []

    // å¦‚æœæœ‰æ–‡æœ¬æœç´¢ï¼Œéœ€è¦é¢„åŠ è½½API Keyä¿¡æ¯
    let apiKeyCache = {}
    if (query.search) {
      try {
        logger.debug(`é¢„åŠ è½½API Keyä¿¡æ¯ä»¥æ”¯æŒæ–‡æœ¬æœç´¢: ${query.search}`)
        const allApiKeys = await this.getAllApiKeys()
        apiKeyCache = allApiKeys.reduce((cache, key) => {
          cache[key.id] = key
          return cache
        }, {})
        logger.debug(`å·²åŠ è½½ ${Object.keys(apiKeyCache).length} ä¸ªAPI Keyä¿¡æ¯`)
      } catch (error) {
        logger.warn('åŠ è½½API Keyä¿¡æ¯å¤±è´¥ï¼Œæ–‡æœ¬æœç´¢å¯èƒ½ä¸å®Œæ•´:', error.message)
      }
    }

    results.forEach(([err, logData], index) => {
      if (err || !logData) {
        return
      }

      const logKey = logKeys[index]
      let matches = true

      // åº”ç”¨å„ç§è¿‡æ»¤æ¡ä»¶
      for (const [key, value] of Object.entries(query)) {
        if (key === 'search') {
          // ç‰¹æ®Šå¤„ç†æ–‡æœ¬æœç´¢
          if (!this._performTextSearch(logData, logKey, value, apiKeyCache)) {
            matches = false
            break
          }
        } else if (!this._checkLogFieldMatch(logData, logKey, key, value)) {
          matches = false
          break
        }
      }

      if (matches) {
        filteredKeys.push(logKey)
      }
    })

    return filteredKeys
  }

  /**
   * æ£€æŸ¥æ—¥å¿—å­—æ®µæ˜¯å¦åŒ¹é…æŸ¥è¯¢æ¡ä»¶ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
   * @private
   * @param {Object} logData æ—¥å¿—æ•°æ®
   * @param {string} logKey æ—¥å¿—é”®
   * @param {string} fieldName å­—æ®µå
   * @param {*} value æœŸæœ›å€¼
   * @returns {boolean} æ˜¯å¦åŒ¹é…
   */
  _checkLogFieldMatch(logData, logKey, fieldName, value) {
    switch (fieldName) {
      case 'keyId':
        return logKey.includes(`:${value}:`) || logData.keyId === value

      case 'status':
        return logData.status === String(value)

      case 'method':
        return logData.method === value

      case 'path':
        return logData.path && logData.path.includes(value)

      case 'model':
        return logData.model === value

      case 'search':
        // æ–‡æœ¬æœç´¢åœ¨ä¸Šå±‚å¤„ç†ï¼Œè¿™é‡Œç›´æ¥è¿”å›true
        return true

      case 'dateRange':
        // æ—¥æœŸèŒƒå›´å·²åœ¨ä¸Šå±‚æ–¹æ³•ä¸­å¤„ç†
        return true

      case 'minTokens':
        return parseInt(logData.tokens) >= parseInt(value)

      case 'maxTokens':
        return parseInt(logData.tokens) <= parseInt(value)

      case 'minResponseTime':
        return parseFloat(logData.responseTime) >= parseFloat(value)

      case 'maxResponseTime':
        return parseFloat(logData.responseTime) <= parseFloat(value)

      case 'hasError':
        return value
          ? logData.error && logData.error !== 'null'
          : !logData.error || logData.error === 'null'

      default:
        // é€šç”¨å­—æ®µåŒ¹é…
        return logData[fieldName] === value
    }
  }

  /**
   * æ‰§è¡Œæ–‡æœ¬æœç´¢ï¼ˆå¤šå­—æ®µæ¨¡ç³ŠåŒ¹é…ï¼‰
   * @private
   * @param {Object} logData æ—¥å¿—æ•°æ®
   * @param {string} logKey æ—¥å¿—é”®
   * @param {string} searchText æœç´¢æ–‡æœ¬
   * @param {Object} apiKeyCache API Keyç¼“å­˜å¯¹è±¡
   * @returns {boolean} æ˜¯å¦åŒ¹é…
   */
  _performTextSearch(logData, logKey, searchText, apiKeyCache = {}) {
    if (!searchText || typeof searchText !== 'string') {
      return true
    }

    // é™åˆ¶æœç´¢è¯é•¿åº¦ï¼Œé¿å…è¿‡åº¦å¤æ‚æŸ¥è¯¢
    if (searchText.length > 100) {
      logger.warn(`æœç´¢è¯è¿‡é•¿ï¼Œæˆªæ–­åˆ°100å­—ç¬¦: ${searchText.substring(0, 100)}...`)
      searchText = searchText.substring(0, 100)
    }

    // ä¸åŒºåˆ†å¤§å°å†™çš„æœç´¢
    const searchLower = searchText.toLowerCase().trim()
    if (!searchLower) {
      return true
    }

    // æ”¯æŒå¤šè¯æœç´¢ï¼ˆç©ºæ ¼åˆ†å‰²ï¼‰
    const searchTerms = searchLower.split(/\s+/).filter((term) => term.length > 0)
    if (searchTerms.length === 0) {
      return true
    }

    // è·å–API Keyåç§°ï¼ˆä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½ï¼‰
    let apiKeyName = ''
    if (logData.keyId && apiKeyCache[logData.keyId]) {
      apiKeyName = (apiKeyCache[logData.keyId].name || '').toLowerCase()
    }

    // æ„å»ºæœç´¢å­—æ®µæ•°ç»„ï¼ˆä½¿ç”¨å®é™…çš„å­—æ®µåï¼‰
    const searchFields = [
      apiKeyName, // API Key åç§°
      (logData.path || '').toLowerCase(), // è¯·æ±‚è·¯å¾„
      (logData.ipAddress || '').toLowerCase(), // IP åœ°å€
      (logData.userAgent || '').toLowerCase(), // User Agent
      (logData.error || '').toLowerCase(), // é”™è¯¯ä¿¡æ¯
      (logData.method || '').toLowerCase(), // HTTPæ–¹æ³•
      (logData.model || '').toLowerCase(), // æ¨¡å‹åç§°
      (logData.keyId || '').toLowerCase(), // API Key ID
      (logData.statusCode || '').toString().toLowerCase() // çŠ¶æ€ç 
    ].filter((field) => field.length > 0)

    // åˆå¹¶æ‰€æœ‰æœç´¢å­—æ®µä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
    const searchableText = searchFields.join(' ')

    // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æœç´¢è¯éƒ½èƒ½åœ¨æœç´¢æ–‡æœ¬ä¸­æ‰¾åˆ°
    return searchTerms.every((term) => searchableText.includes(term))
  }

  /**
   * å¯¼å‡ºæ—¥å¿—åˆ°æ–‡ä»¶
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @param {string} format å¯¼å‡ºæ ¼å¼ï¼ˆcsv/jsonï¼‰
   * @param {string} filename å¯¼å‡ºæ–‡ä»¶å
   * @returns {Promise<string>} å¯¼å‡ºæ–‡ä»¶è·¯å¾„
   */
  async exportLogs(query = {}, format = 'csv', filename) {
    const path = require('path')
    const fs = require('fs')

    try {
      // æœç´¢æ—¥å¿—
      const logs = await this.searchLogs(query)

      // ç¡®å®šå¯¼å‡ºç›®å½•
      const exportDir = path.join(__dirname, '../../../logs/exports')
      fs.mkdirSync(exportDir, { recursive: true })

      const exportPath = path.join(exportDir, filename)

      if (format === 'json') {
        fs.writeFileSync(exportPath, JSON.stringify(logs, null, 2))
      } else {
        // CSVå¯¼å‡º
        const csvHeader = [
          'logId',
          'timestamp',
          'keyId',
          'path',
          'method',
          'status',
          'model',
          'tokens',
          'responseTime',
          'error'
        ]
        const csvContent = [
          csvHeader.join(','),
          ...logs.map((log) =>
            csvHeader
              .map((header) => `"${String(log[header] || '').replace(/"/g, '""')}"`)
              .join(',')
          )
        ].join('\n')

        fs.writeFileSync(exportPath, csvContent)
      }

      return exportPath
    } catch (error) {
      logger.error('Failed to export logs:', error)
      throw error
    }
  }

  /**
   * åˆ é™¤æŒ‡å®šæ¡ä»¶çš„æ—¥å¿—ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @param {Object} query æŸ¥è¯¢æ¡ä»¶
   * @returns {Promise<number>} åˆ é™¤çš„æ—¥å¿—æ•°é‡
   */
  async deleteLogs(query = {}) {
    try {
      const client = this.getClientSafe()
      let matchingLogs = []

      // ä½¿ç”¨ä¼˜åŒ–çš„æœç´¢ç­–ç•¥
      if (query.status && query.dateRange) {
        matchingLogs = await this._searchLogsByStatusAndDate(client, query.status, query.dateRange)
      } else if (query.model && query.dateRange) {
        matchingLogs = await this._searchLogsByModelAndDate(client, query.model, query.dateRange)
      } else if (query.hasError && query.dateRange) {
        matchingLogs = await this._searchErrorLogsByDate(client, query.dateRange)
      } else if (query.keyId && query.dateRange) {
        matchingLogs = await this._searchLogsByKeyIdAndDate(client, query.keyId, query.dateRange)
      } else if (query.keyId) {
        const pattern = `request_log:${query.keyId}:*`
        matchingLogs = await client.keys(pattern)
      } else if (query.dateRange) {
        matchingLogs = await this._searchLogsByDateRange(client, query.dateRange)
      } else if (query.status) {
        const today = getDateStringInTimezone()
        const statusIndex = `request_log_status:${query.status}:${today}`
        try {
          matchingLogs = await client.smembers(statusIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else if (query.model) {
        const today = getDateStringInTimezone()
        const modelIndex = `request_log_model:${query.model}:${today}`
        try {
          matchingLogs = await client.smembers(modelIndex)
        } catch (error) {
          matchingLogs = []
        }
      } else {
        matchingLogs = await client.keys('request_log:*')
      }

      // åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
      if (Object.keys(query).length > 0 && !(query.keyId && Object.keys(query).length === 1)) {
        matchingLogs = await this._filterLogsByQuery(client, matchingLogs, query)
      }

      // åˆ†æ‰¹åˆ é™¤ä»¥é¿å…Rediså‘½ä»¤è¿‡é•¿
      let totalDeleted = 0
      const batchSize = 100 // æ¯æ‰¹åˆ é™¤100ä¸ªkey

      for (let i = 0; i < matchingLogs.length; i += batchSize) {
        const batch = matchingLogs.slice(i, i + batchSize)
        if (batch.length > 0) {
          await client.del(...batch)
          totalDeleted += batch.length
        }
      }

      // åŒæ—¶æ¸…ç†ç›¸å…³ç´¢å¼•
      await this._cleanupLogIndexes(client, matchingLogs)

      logger.info(`æˆåŠŸåˆ é™¤ ${totalDeleted} æ¡æ—¥å¿—è®°å½•`)
      return totalDeleted
    } catch (error) {
      logger.error('Failed to delete logs:', error)
      return 0
    }
  }

  /**
   * åˆ é™¤è¿‡æœŸçš„æ—¥å¿—è®°å½•ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * @param {string} cutoffDate æˆªæ­¢æ—¥æœŸï¼ˆISOå­—ç¬¦ä¸²ï¼‰
   * @returns {Promise<number>} åˆ é™¤çš„æ—¥å¿—æ•°é‡
   */
  async deleteExpiredLogs(cutoffDate) {
    try {
      const client = this.getClientSafe()
      const cutoffTimestamp = new Date(cutoffDate).getTime()

      logger.info(`å¼€å§‹æ¸…ç† ${cutoffDate} ä¹‹å‰çš„è¿‡æœŸæ—¥å¿—`)

      // è·å–æ‰€æœ‰è¯·æ±‚æ—¥å¿—é”®
      const allLogKeys = await client.keys('request_log:*')
      logger.info(`å‘ç° ${allLogKeys.length} ä¸ªæ—¥å¿—æ–‡ä»¶`)

      // åˆ†æ‰¹å¤„ç†ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
      const batchSize = 500
      const expiredLogs = []

      for (let i = 0; i < allLogKeys.length; i += batchSize) {
        const batch = allLogKeys.slice(i, i + batchSize)

        // é¦–å…ˆä»keyä¸­æå–æ—¶é—´æˆ³è¿›è¡Œå¿«é€Ÿç­›é€‰
        const potentialExpired = batch.filter((logKey) => {
          const keyTimestamp = parseInt(logKey.split(':')[2]) || 0
          return keyTimestamp > 0 && keyTimestamp < cutoffTimestamp
        })

        // å¯¹äºå¯èƒ½è¿‡æœŸçš„æ—¥å¿—ï¼Œæ‰¹é‡è·å–è¯¦ç»†ä¿¡æ¯ç¡®è®¤
        if (potentialExpired.length > 0) {
          const pipeline = client.pipeline()
          potentialExpired.forEach((logKey) => pipeline.hget(logKey, 'timestamp'))

          const results = await pipeline.exec()

          results.forEach(([err, timestamp], index) => {
            if (!err && timestamp && parseInt(timestamp) < cutoffTimestamp) {
              expiredLogs.push(potentialExpired[index])
            }
          })
        }

        // è¿›åº¦æŠ¥å‘Š
        if (i + batchSize < allLogKeys.length) {
          logger.debug(
            `å·²å¤„ç† ${Math.min(i + batchSize, allLogKeys.length)}/${allLogKeys.length} ä¸ªæ—¥å¿—ï¼Œå‘ç° ${expiredLogs.length} ä¸ªè¿‡æœŸæ—¥å¿—`
          )
        }
      }

      // åˆ†æ‰¹åˆ é™¤è¿‡æœŸæ—¥å¿—
      let totalDeleted = 0
      const deleteBatchSize = 100

      for (let i = 0; i < expiredLogs.length; i += deleteBatchSize) {
        const batch = expiredLogs.slice(i, i + deleteBatchSize)
        if (batch.length > 0) {
          await client.del(...batch)
          totalDeleted += batch.length
        }
      }

      // æ¸…ç†ç›¸å…³ç´¢å¼•
      await this._cleanupLogIndexes(client, expiredLogs)

      logger.info(`æ¸…ç†è¿‡æœŸæ—¥å¿—å®Œæˆ: åˆ é™¤ ${totalDeleted} æ¡è®°å½•`)
      return totalDeleted
    } catch (error) {
      logger.error('Failed to delete expired logs:', error)
      return 0
    }
  }

  /**
   * æ¸…ç†æ—¥å¿—ç´¢å¼•
   * @private
   * @param {Object} client Rediså®¢æˆ·ç«¯
   * @param {Array} deletedLogKeys å·²åˆ é™¤çš„æ—¥å¿—é”®æ•°ç»„
   * @returns {Promise<void>}
   */
  async _cleanupLogIndexes(client, deletedLogKeys) {
    if (deletedLogKeys.length === 0) {
      return
    }

    try {
      // è·å–æ‰€æœ‰ç´¢å¼•é”®
      const indexKeys = await client.keys('request_log_index:*')

      if (indexKeys.length > 0) {
        const pipeline = client.pipeline()

        // æ‰¹é‡æ¸…ç†ç´¢å¼•
        indexKeys.forEach((indexKey) => {
          deletedLogKeys.forEach((logKey) => {
            pipeline.srem(indexKey, logKey)
          })
        })

        await pipeline.exec()
        logger.debug(`æ¸…ç†äº† ${indexKeys.length} ä¸ªç´¢å¼•ä¸­çš„ ${deletedLogKeys.length} æ¡è®°å½•`)
      }
    } catch (error) {
      logger.warn('ç´¢å¼•æ¸…ç†å¤±è´¥ï¼Œä½†ä¸å½±å“æ—¥å¿—åˆ é™¤:', error.message)
    }
  }

  /**
   * è·å–è¯·æ±‚æ—¥å¿—é…ç½®
   * @returns {Promise<Object>} æ—¥å¿—é…ç½®å¯¹è±¡
   */
  async getRequestLogsConfig() {
    try {
      const configStr = await this.get('request_logs_config')
      return configStr ? JSON.parse(configStr) : null
    } catch (error) {
      logger.error('Failed to get request logs config:', error)
      return null
    }
  }

  /**
   * è®¾ç½®è¯·æ±‚æ—¥å¿—é…ç½®
   * @param {Object} config é…ç½®å¯¹è±¡
   * @returns {Promise<void>}
   */
  async setRequestLogsConfig(requestLogsConfig) {
    try {
      await this.set('request_logs_config', JSON.stringify(requestLogsConfig))
      logger.info('è¯·æ±‚æ—¥å¿—é…ç½®å·²æ›´æ–°')
    } catch (error) {
      logger.error('Failed to set request logs config:', error)
      throw error
    }
  }

  /**
   * è·å–å•ä¸ªè¯·æ±‚æ—¥å¿—çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
   * @param {string} logId æ—¥å¿—ID (å®Œæ•´çš„Redis keyæˆ–ç®€åŒ–çš„ID)
   * @returns {Promise<Object|null>} æ—¥å¿—è¯¦ç»†ä¿¡æ¯å¯¹è±¡æˆ–null
   */
  async getRequestLogDetails(logId) {
    try {
      const client = this.getClientSafe()
      let actualLogKey = logId
      const startTime = Date.now()

      // å‚æ•°éªŒè¯å’Œæ¸…ç†
      if (!logId || typeof logId !== 'string') {
        logger.warn('è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥: æ— æ•ˆçš„æ—¥å¿—IDå‚æ•°', { logId, type: typeof logId })
        return null
      }

      // æ¸…ç†å’Œæ ‡å‡†åŒ–logId
      const cleanLogId = logId.trim().replace(/^["']|["']$/g, '') // ç§»é™¤å¯èƒ½çš„å¼•å·
      if (!cleanLogId) {
        logger.warn('è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥: æ¸…ç†åçš„æ—¥å¿—IDä¸ºç©º', { originalLogId: logId })
        return null
      }

      // æ™ºèƒ½è¯†åˆ«å’Œæ„é€ å®Œæ•´çš„Redis key
      if (!cleanLogId.startsWith('request_log:')) {
        // å¦‚æœæ˜¯ç®€åŒ–çš„IDæ ¼å¼ï¼ˆå¦‚ keyId:timestampï¼‰ï¼Œæ„é€ å®Œæ•´key
        if (cleanLogId.includes(':')) {
          const parts = cleanLogId.split(':')
          if (parts.length === 2 && parts[0] && parts[1]) {
            actualLogKey = `request_log:${parts[0]}:${parts[1]}`
          } else if (parts.length === 3 && parts[0] === 'request_log') {
            actualLogKey = cleanLogId // å·²ç»æ˜¯å®Œæ•´æ ¼å¼
          } else {
            logger.warn('è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥: æ— æ³•è§£ææ—¥å¿—IDæ ¼å¼', {
              cleanLogId,
              parts,
              expectedFormat: 'keyId:timestamp æˆ– request_log:keyId:timestamp'
            })
            return null
          }
        } else {
          // å¦‚æœåªæ˜¯timestampï¼Œå°è¯•é€šè¿‡æ¨¡å¼åŒ¹é…æŸ¥æ‰¾ï¼ˆæ€§èƒ½è¾ƒä½ï¼Œè°¨æ…ä½¿ç”¨ï¼‰
          logger.debug('å°è¯•é€šè¿‡timestampæŸ¥æ‰¾æ—¥å¿—', { timestamp: cleanLogId })
          const pattern = `request_log:*:${cleanLogId}`
          const matchingKeys = await client.keys(pattern)
          if (matchingKeys.length > 0) {
            actualLogKey = matchingKeys[0] // å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„key
            logger.debug('é€šè¿‡æ¨¡å¼åŒ¹é…æ‰¾åˆ°æ—¥å¿—', { pattern, matchingKey: actualLogKey })
          } else {
            logger.warn('è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥: æœªæ‰¾åˆ°åŒ¹é…çš„æ—¥å¿—key', { pattern })
            return null
          }
        }
      } else {
        actualLogKey = cleanLogId
      }

      logger.debug(`è·å–æ—¥å¿—è¯¦æƒ…: ${logId} -> ${actualLogKey}`)

      // è·å–å®Œæ•´çš„hashæ•°æ®
      const logData = await client.hgetall(actualLogKey)

      // æ£€æŸ¥æ—¥å¿—æ˜¯å¦å­˜åœ¨
      if (!logData || Object.keys(logData).length === 0) {
        logger.warn(`æ—¥å¿—ä¸å­˜åœ¨: ${actualLogKey}`)
        return null
      }

      // å¤„ç†å’Œååºåˆ—åŒ–å¤æ‚å¯¹è±¡å­—æ®µ
      const processedLogData = { ...logData }

      // æ”¹è¿›çš„JSONååºåˆ—åŒ–å‡½æ•°ï¼Œæ”¯æŒå‹ç¼©æ•°æ®
      const safeJSONParse = (fieldName, value) => {
        if (!value || typeof value !== 'string') {
          return null
        }

        try {
          // å°è¯•ç›´æ¥JSONè§£æ
          return JSON.parse(value)
        } catch (e) {
          // å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å…¶ä»–æ ¼å¼
          logger.debug(`è§£æ${fieldName}å¤±è´¥ for log ${actualLogKey}:`, e.message)

          // æ£€æŸ¥æ˜¯å¦æ˜¯è¢«è½¬ä¹‰çš„JSONå­—ç¬¦ä¸²
          if (value.startsWith('\\"') || value.includes('\\"')) {
            try {
              const unescaped = value.replace(/\\"/g, '"')
              return JSON.parse(unescaped)
            } catch (unescapeError) {
              logger.debug(`åè½¬ä¹‰åè§£æ${fieldName}ä»ç„¶å¤±è´¥:`, unescapeError.message)
            }
          }

          return null
        }
      }

      // æ‰©å±•çš„æ•°æ®è§£å‹ç¼©å’Œååºåˆ—åŒ–å­—æ®µ
      const jsonFields = [
        'requestHeaders',
        'responseHeaders',
        'tokenDetails',
        'costDetails',
        'metadata'
      ]
      jsonFields.forEach((field) => {
        if (processedLogData[field]) {
          processedLogData[field] = safeJSONParse(field, processedLogData[field])
        }
      })

      // æ‰©å±•çš„æ•°å€¼ç±»å‹å­—æ®µè½¬æ¢ï¼ˆæ”¯æŒæ›´å¤šç¼“å­˜tokenç±»å‹ï¼‰
      const numericFields = {
        timestamp: 'int',
        duration: 'int',
        responseTime: 'float',
        inputTokens: 'int',
        outputTokens: 'int',
        totalTokens: 'int',
        cacheCreateTokens: 'int', // æ–°å¢ç¼“å­˜token
        cacheReadTokens: 'int', // æ–°å¢ç¼“å­˜token
        cost: 'float',
        status: 'int',
        tokens: 'int'
      }

      Object.entries(numericFields).forEach(([field, type]) => {
        if (processedLogData[field] !== undefined && processedLogData[field] !== '') {
          if (type === 'int') {
            processedLogData[field] = parseInt(processedLogData[field]) || 0
          } else if (type === 'float') {
            processedLogData[field] = parseFloat(processedLogData[field]) || 0
          }
        }
      })

      // æ·»åŠ æ—¥å¿—IDä¿¡æ¯
      processedLogData.logId = actualLogKey
      processedLogData.shortLogId = cleanLogId
      processedLogData.originalLogId = logId

      // å¢å¼ºçš„è®¡ç®—å­—æ®µå’Œå…ƒæ•°æ®
      processedLogData.hasHeaders = !!(
        (processedLogData.requestHeaders &&
          Object.keys(processedLogData.requestHeaders).length > 0) ||
        (processedLogData.responseHeaders &&
          Object.keys(processedLogData.responseHeaders).length > 0)
      )

      processedLogData.hasBody = !!(
        (processedLogData.requestBody && processedLogData.requestBody.trim().length > 0) ||
        (processedLogData.responseBody && processedLogData.responseBody.trim().length > 0)
      )

      processedLogData.isError = (processedLogData.status || 0) >= 400
      processedLogData.dateTime = processedLogData.timestamp
        ? new Date(processedLogData.timestamp).toISOString()
        : null

      // è¯¦ç»†çš„çŠ¶æ€åˆ†ç±»
      const statusCode = processedLogData.status || 0
      processedLogData.statusCategory =
        statusCode >= 500
          ? 'server_error'
          : statusCode >= 400
            ? 'client_error'
            : statusCode >= 300
              ? 'redirect'
              : statusCode >= 200
                ? 'success'
                : 'unknown'

      // å¢å¼ºçš„Tokenæ±‡æ€»ä¿¡æ¯ï¼ˆæ”¯æŒç¼“å­˜tokenï¼‰
      processedLogData.tokenSummary = {
        totalTokens: processedLogData.totalTokens || processedLogData.tokens || 0,
        inputTokens: processedLogData.inputTokens || 0,
        outputTokens: processedLogData.outputTokens || 0,
        cacheCreateTokens: processedLogData.cacheCreateTokens || 0, // æ–°å¢
        cacheReadTokens: processedLogData.cacheReadTokens || 0, // æ–°å¢
        cost: processedLogData.cost || 0,
        costBreakdown: processedLogData.costDetails || null,
        efficiency: 0
      }

      // è®¡ç®—tokenä½¿ç”¨æ•ˆç‡
      if (processedLogData.tokenSummary.totalTokens > 0) {
        processedLogData.tokenSummary.efficiency = parseFloat(
          (
            (processedLogData.tokenSummary.outputTokens /
              processedLogData.tokenSummary.totalTokens) *
            100
          ).toFixed(2)
        )
      }

      // æ€§èƒ½åˆ†æ
      const responseTime = processedLogData.duration || processedLogData.responseTime || 0
      processedLogData.performanceAnalysis = {
        responseTimeMs: responseTime,
        isSlowRequest: responseTime > 5000, // è¶…è¿‡5ç§’
        performanceLevel:
          responseTime > 10000
            ? 'very_slow'
            : responseTime > 5000
              ? 'slow'
              : responseTime > 1000
                ? 'normal'
                : 'fast',
        tokenEfficiency: processedLogData.tokenSummary.efficiency,
        errorCategory: processedLogData.statusCategory
      }

      // å¢å¼ºçš„è¯¦ç»†å…ƒæ•°æ®æ ‡å¿—
      processedLogData.metadata = {
        // åŸºæœ¬æ£€ç´¢ä¿¡æ¯
        retrievedAt: new Date().toISOString(),
        processingTimeMs: Date.now() - startTime,

        // æ•°æ®å¯ç”¨æ€§æ ‡å¿—
        hasRequestHeaders: !!(
          processedLogData.requestHeaders && Object.keys(processedLogData.requestHeaders).length > 0
        ),
        hasResponseHeaders: !!(
          processedLogData.responseHeaders &&
          Object.keys(processedLogData.responseHeaders).length > 0
        ),
        hasRequestBody: !!(
          processedLogData.requestBody && processedLogData.requestBody.trim().length > 0
        ),
        hasResponseBody: !!(
          processedLogData.responseBody && processedLogData.responseBody.trim().length > 0
        ),
        hasTokenDetails: !!(
          processedLogData.tokenDetails &&
          Object.keys(processedLogData.tokenDetails || {}).length > 0
        ),
        hasCostDetails: !!(
          processedLogData.costDetails && Object.keys(processedLogData.costDetails || {}).length > 0
        ),

        // æ•°æ®å®Œæ•´æ€§æ ‡å¿—
        isComplete: !!(
          processedLogData.requestHeaders &&
          processedLogData.responseHeaders &&
          processedLogData.tokenSummary
        ),
        hasError: processedLogData.isError,

        // æ•°æ®å¤§å°ä¿¡æ¯
        dataSize: {
          requestBodySize: processedLogData.requestBody ? processedLogData.requestBody.length : 0,
          responseBodySize: processedLogData.responseBody
            ? processedLogData.responseBody.length
            : 0,
          requestHeadersSize: processedLogData.requestHeaders
            ? JSON.stringify(processedLogData.requestHeaders).length
            : 0,
          responseHeadersSize: processedLogData.responseHeaders
            ? JSON.stringify(processedLogData.responseHeaders).length
            : 0,
          totalSize: 0
        },

        // Headeråˆ†æ
        headerAnalysis: {
          requestCount: processedLogData.requestHeaders
            ? Object.keys(processedLogData.requestHeaders).length
            : 0,
          responseCount: processedLogData.responseHeaders
            ? Object.keys(processedLogData.responseHeaders).length
            : 0,
          hasUserAgent: !!(
            processedLogData.requestHeaders?.['user-agent'] ||
            processedLogData.requestHeaders?.['User-Agent']
          ),
          hasContentType: !!(
            processedLogData.requestHeaders?.['content-type'] ||
            processedLogData.requestHeaders?.['Content-Type'] ||
            processedLogData.responseHeaders?.['content-type'] ||
            processedLogData.responseHeaders?.['Content-Type']
          )
        }
      }

      // è®¡ç®—æ€»æ•°æ®å¤§å°
      processedLogData.metadata.dataSize.totalSize =
        processedLogData.metadata.dataSize.requestBodySize +
        processedLogData.metadata.dataSize.responseBodySize +
        processedLogData.metadata.dataSize.requestHeadersSize +
        processedLogData.metadata.dataSize.responseHeadersSize

      const endTime = Date.now()
      logger.debug(
        `æˆåŠŸè·å–æ—¥å¿—è¯¦æƒ…: ${actualLogKey}, è€—æ—¶: ${endTime - startTime}ms, å­—æ®µæ•°: ${Object.keys(processedLogData).length}, hasHeaders: ${processedLogData.hasHeaders}, hasBody: ${processedLogData.hasBody}, tokens: ${processedLogData.tokenSummary.totalTokens}`
      )

      return processedLogData
    } catch (error) {
      logger.error(`è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥ ${logId}:`, {
        error: error.message,
        stack: error.stack,
        logId,
        timestamp: new Date().toISOString()
      })
      return null
    }
  }

  /**
   * ==========================================
   * æŠ½è±¡æ—¥å¿—å­˜å‚¨æ¥å£ (Abstract Log Storage Interface)
   * ==========================================
   *
   * ä»¥ä¸‹æ–¹æ³•æä¾›æ•°æ®åº“æ— å…³çš„æ—¥å¿—å­˜å‚¨æŠ½è±¡æ¥å£
   * æ”¯æŒä¸åŒæ•°æ®åº“åç«¯çš„æ‰©å±• (Redis, MongoDB, PostgreSQLç­‰)
   */

  /**
   * æ‰¹é‡å†™å…¥æ—¥å¿—æ¡ç›®
   * @param {Array} logEntries æ—¥å¿—æ¡ç›®æ•°ç»„
   * @param {Object} options é…ç½®é€‰é¡¹
   * @param {number} options.retentionMaxAge æ•°æ®ä¿ç•™æ—¶é—´ (æ¯«ç§’)
   * @returns {Promise<Object>} å†™å…¥ç»“æœ {success: boolean, results: Array, errors: Array}
   */
  async batchWriteLogs(logEntries, options = {}) {
    const client = this.getClientSafe()
    const pipeline = client.pipeline()
    const results = { success: true, results: [], errors: [] }

    try {
      for (const logEntry of logEntries) {
        const logKey = this._generateLogKey(logEntry)
        const indexKey = this._generateIndexKey(logEntry)

        // å¤„ç†hashæ•°æ®
        const dataEntries = Object.entries(logEntry.data).flat()
        if (dataEntries.length > 0 && dataEntries.length % 2 === 0) {
          // æ¸…ç†null/undefinedå€¼
          const sanitizedEntries = dataEntries.map((entry) =>
            entry === null || entry === undefined ? '' : String(entry)
          )

          // æ‰¹é‡å†™å…¥æ“ä½œ
          pipeline.hmset(logKey, ...sanitizedEntries)
          pipeline.expire(logKey, Math.floor(options.retentionMaxAge / 1000))

          // æ›´æ–°ç´¢å¼•
          pipeline.sadd(indexKey, logKey)
          pipeline.expire(indexKey, Math.floor(options.retentionMaxAge / 1000))

          results.results.push({ logKey, indexKey, status: 'queued' })
        } else {
          const error = `Invalid data structure for log entry: ${logKey}`
          results.errors.push({ logKey, error })
          logger.warn(`âš ï¸ ${error}`)
        }
      }

      // æ‰§è¡Œæ‰¹é‡æ“ä½œ
      const pipelineResults = await pipeline.exec()

      // å¤„ç†æ‰§è¡Œç»“æœ
      if (pipelineResults) {
        const errorResults = pipelineResults.filter(([err]) => err !== null)
        if (errorResults.length > 0) {
          results.success = false
          results.errors.push(
            ...errorResults.map(([err, res]) => ({
              error: err?.message || err,
              result: res
            }))
          )
        }
      }

      logger.debug(
        `ğŸ“Š Batch write completed: ${logEntries.length} logs, ${results.errors.length} errors`
      )
      return results
    } catch (error) {
      logger.error('âŒ Batch write logs failed:', error)
      results.success = false
      results.errors.push({ error: error.message })
      return results
    }
  }

  /**
   * éªŒè¯æ—¥å¿—å†™å…¥ç»“æœ
   * @param {string} logKey æ—¥å¿—é”®
   * @returns {Promise<Object>} éªŒè¯ç»“æœ {success: boolean, data: Object|null}
   */
  async verifyLogWrite(logKey) {
    try {
      const client = this.getClientSafe()
      const data = await client.hgetall(logKey)

      return {
        success: data && Object.keys(data).length > 0,
        data: data || null,
        fieldsCount: data ? Object.keys(data).length : 0
      }
    } catch (error) {
      logger.error(`âŒ Log write verification failed for ${logKey}:`, error)
      return {
        success: false,
        data: null,
        error: error.message
      }
    }
  }

  /**
   * ç”Ÿæˆæ—¥å¿—é”®
   * @private
   * @param {Object} logEntry æ—¥å¿—æ¡ç›®
   * @returns {string} æ—¥å¿—é”®
   */
  _generateLogKey(logEntry) {
    return `request_log:${logEntry.keyId}:${logEntry.timestamp}`
  }

  /**
   * ç”Ÿæˆç´¢å¼•é”®
   * @private
   * @param {Object} logEntry æ—¥å¿—æ¡ç›®
   * @returns {string} ç´¢å¼•é”®
   */
  _generateIndexKey(logEntry) {
    // ä½¿ç”¨æ—¶åŒºè½¬æ¢çš„æ—¥æœŸ
    const date = getDateStringInTimezone(new Date(logEntry.timestamp))
    return `request_log_index:${logEntry.keyId}:${date}`
  }

  // ==================== æ™ºèƒ½æ—¥å¿—åˆå¹¶åŠŸèƒ½ ====================

  /**
   * æ£€æµ‹å’ŒæŸ¥æ‰¾é‡å¤çš„æ—¥å¿—æ¡ç›®
   * @param {string} keyId API Key ID
   * @param {Object} logData å¾…æ£€æµ‹çš„æ—¥å¿—æ•°æ®
   * @param {number} windowMs æ£€æµ‹æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰
   * @returns {Promise<Array>} é‡å¤æ—¥å¿—æ¡ç›®æ•°ç»„
   */
  async detectDuplicateLogs(keyId, logData, windowMs = 15000) {
    try {
      const client = this.getClientSafe()
      const currentTime = logData.timestamp || Date.now()
      const startTime = currentTime - windowMs
      const endTime = currentTime + windowMs

      // æœç´¢æ—¶é—´çª—å£å†…çš„ç›¸å…³æ—¥å¿—
      const pattern = `request_log:${keyId}:*`
      const logKeys = await client.keys(pattern)

      const duplicates = []

      // æ‰¹é‡è·å–æ—¥å¿—è¯¦æƒ…
      if (logKeys.length > 0) {
        const pipeline = client.pipeline()
        logKeys.forEach((key) => pipeline.hgetall(key))
        const results = await pipeline.exec()

        results.forEach(([err, logEntry], index) => {
          if (err || !logEntry) {
            return
          }

          const logTimestamp = parseInt(logEntry.timestamp)
          if (logTimestamp < startTime || logTimestamp > endTime) {
            return
          }

          // è®¡ç®—ç›¸ä¼¼åº¦
          const similarity = this._calculateLogSimilarity(logData, logEntry)
          if (similarity > 0.8) {
            // 80%ç›¸ä¼¼åº¦é˜ˆå€¼
            duplicates.push({
              logId: logKeys[index],
              timestamp: logTimestamp,
              priority: this._determinePriority(logEntry),
              similarity: Math.round(similarity * 100) / 100,
              data: logEntry
            })
          }
        })
      }

      // æŒ‰ä¼˜å…ˆçº§å’Œæ—¶é—´æ’åº
      duplicates.sort((a, b) => {
        const priorityOrder = { enhanced: 3, basic: 2, unknown: 1 }
        const priorityDiff = (priorityOrder[b.priority] || 1) - (priorityOrder[a.priority] || 1)
        return priorityDiff !== 0 ? priorityDiff : b.timestamp - a.timestamp
      })

      return duplicates
    } catch (error) {
      logger.error('âŒ Failed to detect duplicate logs:', error)
      return []
    }
  }

  /**
   * åˆå¹¶å¤šä¸ªæ—¥å¿—æ¡ç›®
   * @param {string} primaryLogId ä¸»è¦æ—¥å¿—ID
   * @param {Array} duplicateLogIds é‡å¤æ—¥å¿—IDæ•°ç»„
   * @param {Object} mergeStrategy åˆå¹¶ç­–ç•¥é…ç½®
   * @returns {Promise<Object>} åˆå¹¶ç»“æœ
   */
  async mergeLogEntries(primaryLogId, duplicateLogIds, mergeStrategy = {}) {
    try {
      const client = this.getClientSafe()

      // é»˜è®¤åˆå¹¶ç­–ç•¥
      const strategy = {
        priority: mergeStrategy.priority || 'higher',
        preserveHeaders: mergeStrategy.preserveHeaders !== false,
        aggregateTokens: mergeStrategy.aggregateTokens !== false,
        ...mergeStrategy
      }

      // è·å–æ‰€æœ‰è¦åˆå¹¶çš„æ—¥å¿—æ•°æ®
      const allLogIds = [primaryLogId, ...duplicateLogIds]
      const pipeline = client.pipeline()
      allLogIds.forEach((logId) => pipeline.hgetall(logId))
      const results = await pipeline.exec()

      const logEntries = results
        .filter(([err, data]) => !err && data && Object.keys(data).length > 0)
        .map(([, data]) => data)

      if (logEntries.length < 2) {
        return { success: false, error: 'Insufficient logs to merge' }
      }

      // æ‰§è¡Œåˆå¹¶
      const mergedData = this._performLogMerge(logEntries, strategy)

      // æ›´æ–°ä¸»æ—¥å¿—
      await client.hmset(primaryLogId, mergedData)

      // åˆ é™¤é‡å¤æ—¥å¿—
      if (duplicateLogIds.length > 0) {
        await client.del(...duplicateLogIds)

        // æ¸…ç†ç›¸å…³ç´¢å¼•
        await this._cleanupLogIndexes(client, duplicateLogIds)
      }

      logger.info(`ğŸ”„ Merged ${duplicateLogIds.length} duplicate logs into ${primaryLogId}`)

      return {
        success: true,
        mergedLogId: primaryLogId,
        details: {
          mergedCount: duplicateLogIds.length,
          strategy: strategy.priority,
          preservedHeaders: strategy.preserveHeaders,
          aggregatedTokens: strategy.aggregateTokens
        }
      }
    } catch (error) {
      logger.error('âŒ Failed to merge log entries:', error)
      return { success: false, error: error.message }
    }
  }

  /**
   * è®¡ç®—æ—¥å¿—ç›¸ä¼¼åº¦
   * @private
   * @param {Object} logA æ—¥å¿—A
   * @param {Object} logB æ—¥å¿—B
   * @returns {number} ç›¸ä¼¼åº¦ (0-1)
   */
  _calculateLogSimilarity(logA, logB) {
    let score = 0
    let factors = 0

    // è·¯å¾„ç›¸ä¼¼åº¦ (æƒé‡: 0.3)
    if (logA.path && logB.path) {
      score += logA.path === logB.path ? 0.3 : 0
      factors += 0.3
    }

    // æ–¹æ³•ç›¸ä¼¼åº¦ (æƒé‡: 0.2)
    if (logA.method && logB.method) {
      score += logA.method === logB.method ? 0.2 : 0
      factors += 0.2
    }

    // æ¨¡å‹ç›¸ä¼¼åº¦ (æƒé‡: 0.2)
    if (logA.model && logB.model) {
      score += logA.model === logB.model ? 0.2 : 0
      factors += 0.2
    }

    // çŠ¶æ€ç ç›¸ä¼¼åº¦ (æƒé‡: 0.15)
    if (logA.status && logB.status) {
      score += logA.status === logB.status ? 0.15 : 0
      factors += 0.15
    }

    // Tokenæ•°é‡ç›¸ä¼¼åº¦ (æƒé‡: 0.15)
    const tokensA = parseInt(logA.tokens || logA.totalTokens || 0)
    const tokensB = parseInt(logB.tokens || logB.totalTokens || 0)
    if (tokensA > 0 && tokensB > 0) {
      const tokenRatio = Math.min(tokensA, tokensB) / Math.max(tokensA, tokensB)
      score += tokenRatio > 0.8 ? 0.15 : 0
      factors += 0.15
    }

    return factors > 0 ? score / factors : 0
  }

  /**
   * ç¡®å®šæ—¥å¿—ä¼˜å…ˆçº§
   * @private
   * @param {Object} logEntry æ—¥å¿—æ¡ç›®
   * @returns {string} ä¼˜å…ˆçº§
   */
  _determinePriority(logEntry) {
    if (logEntry.source === 'unified_service' || logEntry.logVersion?.startsWith('2.')) {
      return 'enhanced'
    }

    if (logEntry.requestHeaders || logEntry.responseHeaders || logEntry.tokenDetails) {
      return 'enhanced'
    }

    if (logEntry.logVersion || logEntry.source) {
      return 'basic'
    }

    return 'unknown'
  }

  /**
   * æ‰§è¡Œæ—¥å¿—æ•°æ®åˆå¹¶
   * @private
   * @param {Array} logEntries æ—¥å¿—æ¡ç›®æ•°ç»„
   * @param {Object} strategy åˆå¹¶ç­–ç•¥
   * @returns {Object} åˆå¹¶åçš„æ•°æ®
   */
  _performLogMerge(logEntries, strategy) {
    // æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé€‰æ‹©æœ€ä½³æ•°æ®æº
    const sortedEntries = logEntries.sort((a, b) => {
      const priorityOrder = { enhanced: 3, basic: 2, unknown: 1 }
      const aPriority = this._determinePriority(a)
      const bPriority = this._determinePriority(b)
      return (priorityOrder[bPriority] || 1) - (priorityOrder[aPriority] || 1)
    })

    const primary = sortedEntries[0]
    const merged = { ...primary }

    // èšåˆTokenç»Ÿè®¡
    if (strategy.aggregateTokens) {
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let totalCacheCreateTokens = 0
      let totalCacheReadTokens = 0
      let totalRequests = 0

      logEntries.forEach((entry) => {
        totalTokens += parseInt(entry.tokens || entry.totalTokens || 0)
        totalInputTokens += parseInt(entry.inputTokens || 0)
        totalOutputTokens += parseInt(entry.outputTokens || 0)
        totalCacheCreateTokens += parseInt(entry.cacheCreateTokens || 0)
        totalCacheReadTokens += parseInt(entry.cacheReadTokens || 0)
        totalRequests += 1
      })

      merged.tokens = totalTokens
      merged.totalTokens = totalTokens
      merged.inputTokens = totalInputTokens
      merged.outputTokens = totalOutputTokens
      merged.cacheCreateTokens = totalCacheCreateTokens
      merged.cacheReadTokens = totalCacheReadTokens
      merged.mergedRequestCount = totalRequests
    }

    // åˆå¹¶Headersä¿¡æ¯
    if (strategy.preserveHeaders) {
      const allRequestHeaders = {}
      const allResponseHeaders = {}

      logEntries.forEach((entry) => {
        if (entry.requestHeaders) {
          const headers =
            typeof entry.requestHeaders === 'string'
              ? JSON.parse(entry.requestHeaders)
              : entry.requestHeaders
          Object.assign(allRequestHeaders, headers)
        }

        if (entry.responseHeaders) {
          const headers =
            typeof entry.responseHeaders === 'string'
              ? JSON.parse(entry.responseHeaders)
              : entry.responseHeaders
          Object.assign(allResponseHeaders, headers)
        }
      })

      if (Object.keys(allRequestHeaders).length > 0) {
        merged.requestHeaders = JSON.stringify(allRequestHeaders)
      }

      if (Object.keys(allResponseHeaders).length > 0) {
        merged.responseHeaders = JSON.stringify(allResponseHeaders)
      }
    }

    // æ·»åŠ åˆå¹¶å…ƒæ•°æ®
    merged.logVersion = '2.0.0-merged'
    merged.source = 'unified_service'
    merged.mergedAt = new Date().toISOString()
    merged.originalLogCount = logEntries.length

    return merged
  }
}

// å¯¼å‡ºæ—¶åŒºè¾…åŠ©å‡½æ•°
RedisAdapter.getDateInTimezone = getDateInTimezone
RedisAdapter.getDateStringInTimezone = getDateStringInTimezone
RedisAdapter.getHourInTimezone = getHourInTimezone

module.exports = RedisAdapter
