/**
 * @fileoverview æ•°æ®å®‰å…¨æœåŠ¡æ¨¡å—
 *
 * ä¸“é—¨è´Ÿè´£æ•°æ®å¯¼å‡ºå¯¼å…¥è¿‡ç¨‹ä¸­çš„å®‰å…¨å¤„ç†ï¼ŒåŒ…æ‹¬ï¼š
 * - æ•æ„Ÿä¿¡æ¯è„±æ•å’Œå®‰å…¨å¤„ç†
 * - æ•°æ®å®Œæ•´æ€§éªŒè¯å’Œæ ¡éªŒ
 * - æ“ä½œå®¡è®¡æ—¥å¿—è®°å½•
 * - å®‰å…¨é”™è¯¯å¤„ç†å’Œæ¢å¤
 *
 * éµå¾ªSOLIDåŸåˆ™è®¾è®¡ï¼Œæä¾›å¯æ’æ‹”çš„å®‰å…¨ç­–ç•¥å’Œçµæ´»çš„éªŒè¯æœºåˆ¶ã€‚
 * ç¡®ä¿æ•°æ®è¿ç§»è¿‡ç¨‹çš„å®‰å…¨æ€§å’Œå®Œæ•´æ€§ã€‚
 *
 * @author Claude Code
 * @version 1.0.0
 */

const logger = require('../utils/logger')
const crypto = require('crypto')
const fs = require('fs').promises
const path = require('path')
// const config = require('../../config/config')

/**
 * æ•°æ®å®‰å…¨æœåŠ¡ç±»
 *
 * æ ¸å¿ƒåŠŸèƒ½ï¼š
 * - ğŸ”’ æ•æ„Ÿæ•°æ®è„±æ•ï¼šç®¡ç†å‘˜å¯†ç ã€2FAå¯†é’¥ã€OAuthä»¤ç‰Œ
 * - âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯ï¼šå¤šå±‚æ ¡éªŒå’Œã€ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
 * - ğŸ“‹ æ“ä½œå®¡è®¡ï¼šå®Œæ•´çš„å®‰å…¨æ“ä½œæ—¥å¿—è®°å½•
 * - ğŸ›¡ï¸ å®‰å…¨ç­–ç•¥ï¼šå¯é…ç½®çš„å®‰å…¨å¤„ç†ç­–ç•¥
 * - ğŸ”„ é”™è¯¯æ¢å¤ï¼šè¯¦ç»†çš„é”™è¯¯åˆ†æå’Œæ¢å¤å»ºè®®
 */
class DataSecurityService {
  constructor(options = {}) {
    this.options = {
      // è„±æ•ç­–ç•¥
      sanitizationLevel: options.sanitizationLevel || 'strict', // 'strict' | 'moderate' | 'minimal'
      preserveFormat: options.preserveFormat !== false,

      // éªŒè¯ç­–ç•¥
      enableChecksumVerification: options.enableChecksumVerification !== false,
      enableVersionCheck: options.enableVersionCheck !== false,
      enableDependencyValidation: options.enableDependencyValidation !== false,

      // å®¡è®¡ç­–ç•¥
      enableAuditLogging: options.enableAuditLogging !== false,
      auditLogLevel: options.auditLogLevel || 'info', // 'debug' | 'info' | 'warn' | 'error'

      // å®‰å…¨é…ç½®
      encryptionAlgorithm: options.encryptionAlgorithm || 'aes-256-cbc',
      hashAlgorithm: options.hashAlgorithm || 'sha256',
      saltLength: options.saltLength || 32,

      ...options
    }

    // åˆå§‹åŒ–å®¡è®¡æ—¥å¿—
    this.auditLogEntries = []
    this.operationId = this._generateOperationId()

    logger.info('ğŸ›¡ï¸ DataSecurityService initialized', {
      operationId: this.operationId,
      sanitizationLevel: this.options.sanitizationLevel,
      enableAuditLogging: this.options.enableAuditLogging
    })
  }

  /**
   * æ•æ„Ÿä¿¡æ¯å¤„ç†å™¨ - ç®¡ç†å‘˜å¯†ç å“ˆå¸Œå¤„ç†
   * @param {Array} adminAccounts ç®¡ç†å‘˜è´¦æˆ·æ•°æ®
   * @param {string} operation æ“ä½œç±»å‹ 'export' | 'import'
   * @returns {Object} å¤„ç†ç»“æœå’Œå®‰å…¨å»ºè®®
   */
  async handleAdminPasswordHashes(adminAccounts, operation) {
    this._auditLog('handleAdminPasswordHashes', 'start', {
      operation,
      accountCount: adminAccounts.length
    })

    try {
      const result = {
        processed: [],
        warnings: [],
        recommendations: [],
        securityAlerts: []
      }

      for (const admin of adminAccounts) {
        const processedAdmin = { ...admin }

        if (operation === 'export') {
          // å¯¼å‡ºæ—¶è„±æ•å¤„ç†
          if (admin.passwordHash) {
            switch (this.options.sanitizationLevel) {
              case 'strict':
                processedAdmin.passwordHash = '[REDACTED-STRICT]'
                processedAdmin._originalHashType = this._detectHashType(admin.passwordHash)
                break
              case 'moderate':
                processedAdmin.passwordHash = this._partialMask(admin.passwordHash, 0.8)
                processedAdmin._originalHashType = this._detectHashType(admin.passwordHash)
                break
              case 'minimal':
                processedAdmin._originalHashType = this._detectHashType(admin.passwordHash)
                break
            }

            result.warnings.push({
              type: 'password_hash_sanitized',
              username: admin.username,
              level: this.options.sanitizationLevel,
              message: 'Password hash has been sanitized for security'
            })
          }

          // æ·»åŠ å®‰å…¨å…ƒæ•°æ®
          processedAdmin._securityMetadata = {
            sanitizedAt: new Date().toISOString(),
            sanitizationLevel: this.options.sanitizationLevel,
            requiresPasswordReset: true
          }
        } else if (operation === 'import') {
          // å¯¼å…¥æ—¶å®‰å…¨æ£€æŸ¥
          if (
            processedAdmin.passwordHash === '[REDACTED-STRICT]' ||
            processedAdmin.passwordHash === '[REDACTED]'
          ) {
            // ç”Ÿæˆä¸´æ—¶å®‰å…¨å¯†ç å“ˆå¸Œ
            const tempPassword = this._generateSecureTemporaryPassword()
            processedAdmin.passwordHash = await this._hashPassword(tempPassword)
            processedAdmin._tempPassword = tempPassword
            processedAdmin._requiresPasswordReset = true

            result.securityAlerts.push({
              type: 'temp_password_generated',
              username: admin.username,
              tempPassword,
              message: 'Temporary password generated due to sanitized import'
            })
          }

          // éªŒè¯å¯†ç å“ˆå¸Œå¼ºåº¦
          if (admin.passwordHash && !admin.passwordHash.startsWith('[REDACTED')) {
            const hashStrength = this._validatePasswordHashStrength(admin.passwordHash)
            if (hashStrength.score < 3) {
              result.warnings.push({
                type: 'weak_password_hash',
                username: admin.username,
                score: hashStrength.score,
                message: 'Password hash appears to use weak hashing algorithm'
              })
            }
          }
        }

        result.processed.push(processedAdmin)
      }

      // ç”Ÿæˆå®‰å…¨å»ºè®®
      result.recommendations = this._generatePasswordSecurityRecommendations(result)

      this._auditLog('handleAdminPasswordHashes', 'success', {
        processedCount: result.processed.length,
        warningsCount: result.warnings.length,
        alertsCount: result.securityAlerts.length
      })

      return result
    } catch (error) {
      this._auditLog('handleAdminPasswordHashes', 'error', {
        error: error.message,
        stack: error.stack
      })
      throw new Error(`Admin password hash processing failed: ${error.message}`)
    }
  }

  /**
   * æ•æ„Ÿä¿¡æ¯å¤„ç†å™¨ - 2FAå¯†é’¥è„±æ•å¤„ç†
   * @param {Array} twoFactorConfigs 2FAé…ç½®æ•°æ®
   * @param {string} operation æ“ä½œç±»å‹ 'export' | 'import'
   * @returns {Object} å¤„ç†ç»“æœå’Œå®‰å…¨å»ºè®®
   */
  async handleTwoFactorSecrets(twoFactorConfigs, operation) {
    this._auditLog('handleTwoFactorSecrets', 'start', {
      operation,
      configCount: twoFactorConfigs.length
    })

    try {
      const result = {
        processed: [],
        warnings: [],
        recommendations: [],
        securityAlerts: []
      }

      for (const tfConfig of twoFactorConfigs) {
        const processedConfig = { ...tfConfig }

        if (operation === 'export') {
          // è„±æ•æ•æ„Ÿ2FAæ•°æ®
          const sensitiveFields = ['secret', 'backupCodes', 'qrCodeDataUrl']

          for (const field of sensitiveFields) {
            if (tfConfig[field]) {
              switch (this.options.sanitizationLevel) {
                case 'strict':
                  processedConfig[field] = `[REDACTED-2FA-${field.toUpperCase()}]`
                  break
                case 'moderate':
                  if (field === 'backupCodes' && Array.isArray(tfConfig[field])) {
                    processedConfig[field] = tfConfig[field].map(() => '[REDACTED-CODE]')
                  } else {
                    processedConfig[field] = this._partialMask(tfConfig[field], 0.9)
                  }
                  break
                case 'minimal':
                  // ä¿ç•™æ•°æ®ä½†æ·»åŠ è­¦å‘Š
                  processedConfig[`_${field}_warning`] = 'Contains sensitive 2FA data'
                  break
              }
            }
          }

          // ä¿ç•™éæ•æ„Ÿå…ƒæ•°æ®
          processedConfig._securityMetadata = {
            sanitizedAt: new Date().toISOString(),
            originallyEnabled: tfConfig.isEnabled,
            requiresReconfiguration: true
          }

          result.warnings.push({
            type: '2fa_secrets_sanitized',
            username: tfConfig.username,
            message: '2FA secrets have been sanitized and must be reconfigured'
          })
        } else if (operation === 'import') {
          // å¯¼å…¥æ—¶å¤„ç†è„±æ•çš„2FAé…ç½®
          if (this._isRedactedValue(processedConfig.secret)) {
            processedConfig.isEnabled = false
            processedConfig.requiresReconfiguration = true
            processedConfig.secret = null
            processedConfig.backupCodes = []
            processedConfig.qrCodeDataUrl = null

            result.securityAlerts.push({
              type: '2fa_requires_reconfiguration',
              username: tfConfig.username,
              message: 'User must reconfigure 2FA authentication after import'
            })
          }

          // éªŒè¯2FAé…ç½®å®Œæ•´æ€§
          if (tfConfig.isEnabled && !this._isRedactedValue(tfConfig.secret)) {
            const validationResult = this._validate2FASecret(tfConfig.secret)
            if (!validationResult.valid) {
              result.warnings.push({
                type: 'invalid_2fa_secret',
                username: tfConfig.username,
                reason: validationResult.reason,
                message: '2FA secret validation failed'
              })
            }
          }
        }

        result.processed.push(processedConfig)
      }

      // ç”Ÿæˆ2FAå®‰å…¨å»ºè®®
      result.recommendations = this._generate2FASecurityRecommendations(result)

      this._auditLog('handleTwoFactorSecrets', 'success', {
        processedCount: result.processed.length,
        warningsCount: result.warnings.length
      })

      return result
    } catch (error) {
      this._auditLog('handleTwoFactorSecrets', 'error', {
        error: error.message,
        stack: error.stack
      })
      throw new Error(`2FA secrets processing failed: ${error.message}`)
    }
  }

  /**
   * æ•æ„Ÿä¿¡æ¯å¤„ç†å™¨ - åŠ å¯†Tokenå®‰å…¨è¿ç§»
   * @param {Array} accounts è´¦æˆ·æ•°æ®ï¼ˆåŒ…å«åŠ å¯†tokenï¼‰
   * @param {string} operation æ“ä½œç±»å‹ 'export' | 'import'
   * @returns {Object} å¤„ç†ç»“æœå’Œå®‰å…¨å»ºè®®
   */
  async handleEncryptedTokens(accounts, operation) {
    this._auditLog('handleEncryptedTokens', 'start', {
      operation,
      accountCount: accounts.length
    })

    try {
      const result = {
        processed: [],
        warnings: [],
        recommendations: [],
        securityAlerts: [],
        tokenStats: {
          encrypted: 0,
          plaintext: 0,
          invalid: 0,
          redacted: 0
        }
      }

      for (const account of accounts) {
        const processedAccount = { ...account }
        const tokenFields = ['accessToken', 'refreshToken', 'claudeAiOauth']

        for (const field of tokenFields) {
          if (account[field]) {
            const tokenInfo = this._analyzeTokenSecurity(account[field])
            result.tokenStats[tokenInfo.type]++

            if (operation === 'export') {
              // å¯¼å‡ºæ—¶tokenå®‰å…¨å¤„ç†
              switch (tokenInfo.type) {
                case 'encrypted':
                  // å·²åŠ å¯†çš„tokenä¿æŒåŸçŠ¶ï¼Œä½†æ·»åŠ å®‰å…¨æ ‡è®°
                  processedAccount[`_${field}_security`] = {
                    encrypted: true,
                    algorithm: tokenInfo.algorithm || 'unknown',
                    requiresCompatibleKey: true
                  }
                  break

                case 'plaintext':
                  // æ˜æ–‡tokenéœ€è¦è­¦å‘Š
                  result.warnings.push({
                    type: 'plaintext_token_detected',
                    accountId: account.id,
                    field,
                    message: 'Plaintext token detected - consider encryption'
                  })
                  break

                case 'invalid':
                  result.warnings.push({
                    type: 'invalid_token_format',
                    accountId: account.id,
                    field,
                    message: 'Token format appears invalid'
                  })
                  break
              }
            } else if (operation === 'import') {
              // å¯¼å…¥æ—¶tokenéªŒè¯å’Œå¤„ç†
              if (tokenInfo.type === 'encrypted') {
                // éªŒè¯åŠ å¯†tokenæ˜¯å¦å¯ä»¥æ­£ç¡®è§£å¯†
                try {
                  const decryptionTest = this._testTokenDecryption(account[field])
                  if (!decryptionTest.success) {
                    result.securityAlerts.push({
                      type: 'token_decryption_failed',
                      accountId: account.id,
                      field,
                      reason: decryptionTest.error,
                      message: 'Encrypted token cannot be decrypted with current key'
                    })
                  }
                } catch (decryptError) {
                  result.warnings.push({
                    type: 'token_decryption_test_failed',
                    accountId: account.id,
                    field,
                    error: decryptError.message
                  })
                }
              }
            }
          }
        }

        result.processed.push(processedAccount)
      }

      // ç”Ÿæˆtokenå®‰å…¨å»ºè®®
      result.recommendations = this._generateTokenSecurityRecommendations(result)

      this._auditLog('handleEncryptedTokens', 'success', {
        processedCount: result.processed.length,
        tokenStats: result.tokenStats
      })

      return result
    } catch (error) {
      this._auditLog('handleEncryptedTokens', 'error', {
        error: error.message,
        stack: error.stack
      })
      throw new Error(`Encrypted tokens processing failed: ${error.message}`)
    }
  }

  /**
   * æ•°æ®å®Œæ•´æ€§éªŒè¯ - å¢å¼ºæ ¡éªŒå’ŒéªŒè¯
   * @param {string} exportDir å¯¼å‡ºç›®å½•è·¯å¾„
   * @param {Object} options éªŒè¯é€‰é¡¹
   * @returns {Object} éªŒè¯ç»“æœ
   */
  async verifyDataIntegrity(exportDir, options = {}) {
    this._auditLog('verifyDataIntegrity', 'start', { exportDir })

    try {
      const result = {
        valid: true,
        checksums: {},
        errors: [],
        warnings: [],
        metrics: {
          filesChecked: 0,
          totalSize: 0,
          verificationTime: 0
        }
      }

      const startTime = Date.now()

      // è¯»å–åŸå§‹æ ¡éªŒå’Œæ–‡ä»¶
      const checksumPath = path.join(exportDir, 'checksums.json')
      let originalChecksums = {}

      try {
        const checksumContent = await fs.readFile(checksumPath, 'utf8')
        originalChecksums = JSON.parse(checksumContent)
      } catch (error) {
        if (options.requireChecksums !== false) {
          result.errors.push({
            type: 'missing_checksums_file',
            message: 'Checksums file not found or invalid',
            file: 'checksums.json'
          })
          result.valid = false
        } else {
          result.warnings.push({
            type: 'checksums_not_required',
            message: 'Checksums verification skipped (not required)'
          })
        }

        this._auditLog('verifyDataIntegrity', 'completed', result)
        return result
      }

      // éªŒè¯æ¯ä¸ªæ–‡ä»¶çš„æ ¡éªŒå’Œ
      const files = await fs.readdir(exportDir)
      const dataFiles = files.filter((file) => file.endsWith('.json') && file !== 'checksums.json')

      for (const file of dataFiles) {
        const filePath = path.join(exportDir, file)

        try {
          const content = await fs.readFile(filePath, 'utf8')
          let actualHash = crypto.createHash('sha256').update(content).digest('hex')
          const actualSize = content.length

          // å¦‚æœç›´æ¥æ ¡éªŒå’Œä¸åŒ¹é…ï¼Œå°è¯•JSONè§„èŒƒåŒ–æ ¡éªŒå’Œ
          let normalizedMatch = false
          let normalizedHash = null

          if (actualHash !== originalChecksums[file]?.sha256) {
            try {
              // è§£æå¹¶é‡æ–°åºåˆ—åŒ–JSONä»¥è§„èŒƒåŒ–æ ¼å¼
              const jsonData = JSON.parse(content)
              const normalizedContent = JSON.stringify(jsonData, null, 2)
              normalizedHash = crypto.createHash('sha256').update(normalizedContent).digest('hex')
              normalizedMatch = normalizedHash === originalChecksums[file]?.sha256

              // å¦‚æœè§„èŒƒåŒ–åçš„æ ¡éªŒå’ŒåŒ¹é…ï¼Œä½¿ç”¨è§„èŒƒåŒ–æ ¡éªŒå’Œ
              if (normalizedMatch) {
                actualHash = normalizedHash
                logger.debug(`ğŸ“ JSONè§„èŒƒåŒ–æ ¡éªŒå’ŒåŒ¹é…: ${file} (åŸå§‹ä¸åŒ¹é…ï¼Œè§„èŒƒåŒ–ååŒ¹é…)`)
              }
            } catch (jsonError) {
              // ä¸æ˜¯JSONæ–‡ä»¶æˆ–JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ ¡éªŒå’Œ
              logger.debug(`âš ï¸ JSONè§„èŒƒåŒ–å¤±è´¥: ${file}, é”™è¯¯: ${jsonError.message}`)
            }
          }

          result.checksums[file] = {
            expected: originalChecksums[file]?.sha256,
            actual: actualHash,
            match: actualHash === originalChecksums[file]?.sha256,
            normalizedHash,
            normalizedMatch,
            size: actualSize,
            expectedSize: originalChecksums[file]?.size
          }

          if (!result.checksums[file].match) {
            result.errors.push({
              type: 'checksum_mismatch',
              file,
              expected: originalChecksums[file]?.sha256,
              actual: actualHash,
              message: 'File integrity check failed'
            })
            result.valid = false
          }

          // æ£€æŸ¥æ–‡ä»¶å¤§å°
          if (
            originalChecksums[file]?.size &&
            Math.abs(actualSize - originalChecksums[file].size) > 0
          ) {
            result.warnings.push({
              type: 'size_mismatch',
              file,
              expectedSize: originalChecksums[file].size,
              actualSize,
              message: 'File size differs from expected'
            })
          }

          result.metrics.filesChecked++
          result.metrics.totalSize += actualSize
        } catch (error) {
          result.errors.push({
            type: 'file_read_error',
            file,
            error: error.message,
            message: 'Could not verify file integrity'
          })
          result.valid = false
        }
      }

      // æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„æ–‡ä»¶
      for (const expectedFile of Object.keys(originalChecksums)) {
        if (!dataFiles.includes(expectedFile)) {
          result.errors.push({
            type: 'missing_file',
            file: expectedFile,
            message: 'Expected file is missing from export'
          })
          result.valid = false
        }
      }

      result.metrics.verificationTime = Date.now() - startTime

      this._auditLog('verifyDataIntegrity', 'success', {
        filesChecked: result.metrics.filesChecked,
        valid: result.valid,
        errorsCount: result.errors.length
      })

      return result
    } catch (error) {
      this._auditLog('verifyDataIntegrity', 'error', {
        error: error.message,
        stack: error.stack
      })
      throw new Error(`Data integrity verification failed: ${error.message}`)
    }
  }

  /**
   * ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
   * @param {Object} metadata å¯¼å‡ºå…ƒæ•°æ®
   * @param {string} targetVersion ç›®æ ‡ç³»ç»Ÿç‰ˆæœ¬
   * @returns {Object} å…¼å®¹æ€§æ£€æŸ¥ç»“æœ
   */
  async checkVersionCompatibility(metadata, targetVersion = '1.0.0') {
    this._auditLog('checkVersionCompatibility', 'start', {
      exportVersion: metadata.exportVersion,
      targetVersion
    })

    try {
      const result = {
        compatible: true,
        warnings: [],
        recommendations: [],
        migrationRequired: false,
        supportedFeatures: [],
        unsupportedFeatures: []
      }

      const exportVersion = metadata.exportVersion || '1.0.0'

      // ç‰ˆæœ¬æ¯”è¾ƒé€»è¾‘
      const versionComparison = this._compareVersions(exportVersion, targetVersion)

      if (versionComparison > 0) {
        // å¯¼å‡ºç‰ˆæœ¬é«˜äºç›®æ ‡ç‰ˆæœ¬
        result.warnings.push({
          type: 'newer_export_version',
          exportVersion,
          targetVersion,
          message: 'Export was created with newer version, some features may not be supported'
        })
      } else if (versionComparison < 0) {
        // å¯¼å‡ºç‰ˆæœ¬ä½äºç›®æ ‡ç‰ˆæœ¬
        result.migrationRequired = true
        result.recommendations.push({
          type: 'upgrade_recommended',
          message: 'Consider upgrading export format for better compatibility'
        })
      }

      // æ£€æŸ¥ç‰¹å®šç‰ˆæœ¬çš„åŠŸèƒ½å…¼å®¹æ€§
      const compatibilityMatrix = this._getVersionCompatibilityMatrix()
      const exportFeatures = this._extractFeaturesFromMetadata(metadata)

      for (const feature of exportFeatures) {
        if (compatibilityMatrix[targetVersion]?.includes(feature)) {
          result.supportedFeatures.push(feature)
        } else {
          result.unsupportedFeatures.push(feature)
          result.warnings.push({
            type: 'unsupported_feature',
            feature,
            message: `Feature '${feature}' may not be supported in target version`
          })
        }
      }

      if (result.unsupportedFeatures.length > 0) {
        result.compatible = false
      }

      this._auditLog('checkVersionCompatibility', 'success', {
        compatible: result.compatible,
        migrationRequired: result.migrationRequired
      })

      return result
    } catch (error) {
      this._auditLog('checkVersionCompatibility', 'error', {
        error: error.message
      })
      throw new Error(`Version compatibility check failed: ${error.message}`)
    }
  }

  /**
   * ä¾èµ–å…³ç³»éªŒè¯
   * @param {Object} importData å¯¼å…¥æ•°æ®
   * @returns {Object} ä¾èµ–éªŒè¯ç»“æœ
   */
  async validateDependencies(importData) {
    this._auditLog('validateDependencies', 'start')

    try {
      const result = {
        valid: true,
        dependencies: [],
        conflicts: [],
        missing: [],
        circular: []
      }

      // å®šä¹‰ä¾èµ–å…³ç³»æ˜ å°„
      const dependencyMap = {
        apiKeys: [], // API Keys ä¸ä¾èµ–å…¶ä»–æ•°æ®
        adminAccounts: [], // ç®¡ç†å‘˜è´¦æˆ·ä¸ä¾èµ–å…¶ä»–æ•°æ®
        claudeAccounts: [], // Claudeè´¦æˆ·ä¸ä¾èµ–å…¶ä»–æ•°æ®
        geminiAccounts: [], // Geminiè´¦æˆ·ä¸ä¾èµ–å…¶ä»–æ•°æ®
        openaiAccounts: [], // OpenAIè´¦æˆ·ä¸ä¾èµ–å…¶ä»–æ•°æ®
        systemConfig: [], // ç³»ç»Ÿé…ç½®ä¸ä¾èµ–å…¶ä»–æ•°æ®
        twoFactorConfigs: ['adminAccounts'], // 2FAä¾èµ–ç®¡ç†å‘˜è´¦æˆ·
        usageStats: ['apiKeys', 'claudeAccounts'], // ä½¿ç”¨ç»Ÿè®¡ä¾èµ–API Keyså’Œè´¦æˆ·
        systemStats: ['usageStats'] // ç³»ç»Ÿç»Ÿè®¡ä¾èµ–ä½¿ç”¨ç»Ÿè®¡
      }

      // æ£€æŸ¥æ¯ç§æ•°æ®ç±»å‹çš„ä¾èµ–
      for (const [dataType, deps] of Object.entries(dependencyMap)) {
        if (importData[dataType]) {
          result.dependencies.push({
            type: dataType,
            requires: deps,
            satisfied: deps.every((dep) => importData[dep])
          })

          // æ£€æŸ¥ç¼ºå¤±çš„ä¾èµ–
          const missingDeps = deps.filter((dep) => !importData[dep])
          if (missingDeps.length > 0) {
            result.missing.push({
              type: dataType,
              missingDependencies: missingDeps,
              impact: 'Data may not function correctly without dependencies'
            })
            result.valid = false
          }
        }
      }

      // æ£€æŸ¥å¾ªç¯ä¾èµ–ï¼ˆè™½ç„¶å½“å‰è®¾è®¡ä¸­åº”è¯¥æ²¡æœ‰ï¼‰
      const circularDeps = this._detectCircularDependencies(dependencyMap)
      if (circularDeps.length > 0) {
        result.circular = circularDeps
        result.valid = false
      }

      // æ£€æŸ¥æ•°æ®å¼•ç”¨å®Œæ•´æ€§
      if (importData.usageStats && importData.apiKeys) {
        const referenceIntegrityCheck = this._checkReferenceIntegrity(
          importData.usageStats,
          importData.apiKeys
        )

        if (!referenceIntegrityCheck.valid) {
          result.conflicts.push({
            type: 'reference_integrity',
            issues: referenceIntegrityCheck.issues,
            message: 'Usage statistics reference non-existent API keys'
          })
          result.valid = false
        }
      }

      this._auditLog('validateDependencies', 'success', {
        valid: result.valid,
        dependenciesCount: result.dependencies.length,
        conflictsCount: result.conflicts.length
      })

      return result
    } catch (error) {
      this._auditLog('validateDependencies', 'error', {
        error: error.message
      })
      throw new Error(`Dependencies validation failed: ${error.message}`)
    }
  }

  /**
   * è„±æ•ç®¡ç†å‘˜å¯†ç æ•°æ®
   * @param {Object|Array} adminData ç®¡ç†å‘˜æ•°æ®ï¼ˆå•ä¸ªå¯¹è±¡æˆ–æ•°ç»„ï¼‰
   * @param {string} operation æ“ä½œç±»å‹ï¼Œé»˜è®¤ä¸º 'export'
   * @returns {Object|Array} è„±æ•åçš„æ•°æ®
   */
  sanitizeAdminPassword(adminData, operation = 'export') {
    try {
      const isArray = Array.isArray(adminData)
      const dataToProcess = isArray ? adminData : [adminData]

      logger.debug('ğŸ”’ Sanitizing admin password data', {
        count: dataToProcess.length,
        operation,
        sanitizationLevel: this.options.sanitizationLevel
      })

      const sanitizedData = dataToProcess.map((admin) => {
        const sanitized = { ...admin }

        if (admin.passwordHash) {
          switch (this.options.sanitizationLevel) {
            case 'strict':
              sanitized.passwordHash = '[REDACTED-PASSWORD]'
              sanitized._originalHashType = this._detectHashType(admin.passwordHash)
              break
            case 'moderate':
              sanitized.passwordHash = this._partialMask(admin.passwordHash, 0.8)
              sanitized._originalHashType = this._detectHashType(admin.passwordHash)
              break
            case 'minimal':
              sanitized._originalHashType = this._detectHashType(admin.passwordHash)
              break
          }

          sanitized._securityNote = 'Password requires reset after import'
        }

        return sanitized
      })

      return isArray ? sanitizedData : sanitizedData[0]
    } catch (error) {
      logger.error('âŒ Failed to sanitize admin password data:', error)
      throw new Error(`Admin password sanitization failed: ${error.message}`)
    }
  }

  /**
   * è„±æ•2FAå¯†é’¥æ•°æ®
   * @param {Object|Array} twoFactorData 2FAæ•°æ®ï¼ˆå•ä¸ªå¯¹è±¡æˆ–æ•°ç»„ï¼‰
   * @param {string} operation æ“ä½œç±»å‹ï¼Œé»˜è®¤ä¸º 'export'
   * @returns {Object|Array} è„±æ•åçš„æ•°æ®
   */
  sanitizeTwoFactorSecret(twoFactorData, operation = 'export') {
    try {
      const isArray = Array.isArray(twoFactorData)
      const dataToProcess = isArray ? twoFactorData : [twoFactorData]

      logger.debug('ğŸ”’ Sanitizing 2FA secret data', {
        count: dataToProcess.length,
        operation,
        sanitizationLevel: this.options.sanitizationLevel
      })

      const sanitizedData = dataToProcess.map((tfData) => {
        const sanitized = { ...tfData }
        const sensitiveFields = ['secret', 'backupCodes', 'qrCodeDataUrl']

        for (const field of sensitiveFields) {
          if (tfData[field]) {
            switch (this.options.sanitizationLevel) {
              case 'strict':
                sanitized[field] = `[REDACTED-2FA-${field.toUpperCase()}]`
                break
              case 'moderate':
                if (field === 'backupCodes' && Array.isArray(tfData[field])) {
                  sanitized[field] = tfData[field].map(() => '[REDACTED-CODE]')
                } else {
                  sanitized[field] = this._partialMask(tfData[field], 0.9)
                }
                break
              case 'minimal':
                sanitized[`_${field}_warning`] = 'Contains sensitive 2FA data'
                break
            }
          }
        }

        sanitized._securityNote = '2FA requires reconfiguration after import'
        return sanitized
      })

      return isArray ? sanitizedData : sanitizedData[0]
    } catch (error) {
      logger.error('âŒ Failed to sanitize 2FA secret data:', error)
      throw new Error(`2FA secret sanitization failed: ${error.message}`)
    }
  }

  /**
   * å¤„ç†åŠ å¯†Tokenæ•°æ®
   * @param {Object|Array} tokenData Tokenæ•°æ®ï¼ˆå•ä¸ªå¯¹è±¡æˆ–æ•°ç»„ï¼‰
   * @param {string} encryptionKey åŠ å¯†å¯†é’¥ï¼ˆå¯é€‰ï¼‰
   * @param {string} operation æ“ä½œç±»å‹ï¼Œé»˜è®¤ä¸º 'export'
   * @returns {Object|Array} å¤„ç†åçš„æ•°æ®
   */
  sanitizeEncryptedToken(tokenData, encryptionKey = null, operation = 'export') {
    try {
      const isArray = Array.isArray(tokenData)
      const dataToProcess = isArray ? tokenData : [tokenData]

      logger.debug('ğŸ”’ Processing encrypted token data', {
        count: dataToProcess.length,
        hasEncryptionKey: !!encryptionKey,
        operation
      })

      const processedData = dataToProcess.map((data) => {
        const processed = { ...data }
        const tokenFields = ['accessToken', 'refreshToken', 'claudeAiOauth']

        for (const field of tokenFields) {
          if (data[field]) {
            const tokenInfo = this._analyzeTokenSecurity(data[field])

            if (operation === 'export') {
              // ä¸ºå¯¼å‡ºæ·»åŠ å®‰å…¨å…ƒæ•°æ®
              processed[`_${field}_type`] = tokenInfo.type
              processed[`_${field}_algorithm`] = tokenInfo.algorithm

              if (tokenInfo.type === 'plaintext') {
                processed[`_${field}_warning`] = 'Plaintext token detected - consider encryption'
              }
            } else if (operation === 'import') {
              // å¯¼å…¥æ—¶éªŒè¯token
              if (tokenInfo.type === 'encrypted' && encryptionKey) {
                const testResult = this._testTokenDecryption(data[field])
                if (!testResult.success) {
                  processed[`_${field}_error`] =
                    `Cannot decrypt with provided key: ${testResult.error}`
                }
              }
            }
          }
        }

        return processed
      })

      return isArray ? processedData : processedData[0]
    } catch (error) {
      logger.error('âŒ Failed to process encrypted token data:', error)
      throw new Error(`Encrypted token processing failed: ${error.message}`)
    }
  }

  /**
   * éªŒè¯æ–‡ä»¶æ ¡éªŒå’Œ
   * @param {string} filePath æ–‡ä»¶è·¯å¾„
   * @param {string} expectedChecksum æœŸæœ›çš„æ ¡éªŒå’Œ
   * @param {string} algorithm å“ˆå¸Œç®—æ³•ï¼Œé»˜è®¤ä¸º 'sha256'
   * @returns {Object} éªŒè¯ç»“æœ
   */
  async validateFileChecksum(filePath, expectedChecksum, algorithm = 'sha256') {
    try {
      logger.debug('ğŸ” Validating file checksum', {
        filePath: path.basename(filePath),
        algorithm,
        expectedChecksum: `${expectedChecksum?.substring(0, 8)}...`
      })

      const content = await fs.readFile(filePath, 'utf8')
      const actualChecksum = crypto.createHash(algorithm).update(content).digest('hex')
      const matches = actualChecksum === expectedChecksum

      const result = {
        valid: matches,
        filePath,
        algorithm,
        expected: expectedChecksum,
        actual: actualChecksum,
        fileSize: content.length
      }

      if (!matches) {
        logger.warn('âš ï¸ File checksum mismatch', result)
      } else {
        logger.debug('âœ… File checksum validated successfully')
      }

      return result
    } catch (error) {
      logger.error('âŒ File checksum validation failed:', error)
      return {
        valid: false,
        error: error.message,
        filePath,
        algorithm,
        expected: expectedChecksum
      }
    }
  }

  /**
   * éªŒè¯æ•°æ®å®Œæ•´æ€§
   * @param {Object} data è¦éªŒè¯çš„æ•°æ®
   * @param {Object} schema éªŒè¯æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
   * @returns {Object} éªŒè¯ç»“æœ
   */
  validateDataIntegrity(data, schema = null) {
    try {
      logger.debug('ğŸ” Validating data integrity', {
        hasData: !!data,
        hasSchema: !!schema,
        dataType: typeof data
      })

      const result = {
        valid: true,
        errors: [],
        warnings: [],
        summary: {
          totalFields: 0,
          validFields: 0,
          nullFields: 0,
          invalidFields: 0
        }
      }

      if (!data || typeof data !== 'object') {
        result.valid = false
        result.errors.push({
          type: 'invalid_data_type',
          message: 'Data must be an object',
          actual: typeof data
        })
        return result
      }

      // åŸºæœ¬å®Œæ•´æ€§æ£€æŸ¥
      const fields = Object.keys(data)
      result.summary.totalFields = fields.length

      for (const field of fields) {
        const value = data[field]

        if (value === null || value === undefined) {
          result.summary.nullFields++
        } else if (typeof value === 'string' && value.trim() === '') {
          result.summary.nullFields++
          result.warnings.push({
            type: 'empty_field',
            field,
            message: 'Field contains empty string'
          })
        } else {
          result.summary.validFields++
        }
      }

      // å¦‚æœæœ‰schemaï¼Œæ‰§è¡Œè¯¦ç»†éªŒè¯
      if (schema && typeof schema === 'object') {
        for (const [field, rules] of Object.entries(schema)) {
          if (rules.required && !Object.prototype.hasOwnProperty.call(data, field)) {
            result.errors.push({
              type: 'required_field_missing',
              field,
              message: 'Required field is missing'
            })
            result.valid = false
          }

          if (Object.prototype.hasOwnProperty.call(data, field) && rules.type) {
            const actualType = Array.isArray(data[field]) ? 'array' : typeof data[field]
            if (actualType !== rules.type) {
              result.errors.push({
                type: 'type_mismatch',
                field,
                expected: rules.type,
                actual: actualType,
                message: `Field type mismatch`
              })
              result.summary.invalidFields++
            }
          }
        }
      }

      logger.debug('âœ… Data integrity validation completed', result.summary)
      return result
    } catch (error) {
      logger.error('âŒ Data integrity validation failed:', error)
      return {
        valid: false,
        error: error.message,
        errors: [
          {
            type: 'validation_error',
            message: error.message
          }
        ],
        warnings: []
      }
    }
  }

  /**
   * è®°å½•å®¡è®¡æ—¥å¿—
   * @param {string} operation æ“ä½œåç§°
   * @param {string} user ç”¨æˆ·æ ‡è¯†
   * @param {Object} details è¯¦ç»†ä¿¡æ¯
   * @returns {Object} å®¡è®¡æ—¥å¿—æ¡ç›®
   */
  auditLog(operation, user, details = {}) {
    try {
      const timestamp = new Date().toISOString()
      const auditEntry = {
        timestamp,
        operation,
        user: user || 'system',
        details,
        operationId: this.operationId,
        sessionId: details.sessionId || null
      }

      // è®°å½•åˆ°å†…éƒ¨å®¡è®¡æ—¥å¿—
      this._auditLog(operation, 'info', {
        user,
        ...details
      })

      // è®°å½•åˆ°ä¸»æ—¥å¿—ç³»ç»Ÿ
      logger.info(`ğŸ” Audit: ${operation}`, auditEntry)

      return auditEntry
    } catch (error) {
      logger.error('âŒ Failed to create audit log:', error)
    }
  }

  /**
   * ç”Ÿæˆå®‰å…¨æŠ¥å‘Š
   * @param {Object} stats ç»Ÿè®¡æ•°æ®ï¼ˆå¯é€‰ï¼‰
   * @returns {Object} å®‰å…¨æŠ¥å‘Š
   */
  generateSecurityReport(stats = {}) {
    try {
      logger.debug('ğŸ“Š Generating security report')

      const report = {
        generatedAt: new Date().toISOString(),
        operationId: this.operationId,
        securityConfiguration: {
          sanitizationLevel: this.options.sanitizationLevel,
          enabledFeatures: {
            checksumVerification: this.options.enableChecksumVerification,
            versionCheck: this.options.enableVersionCheck,
            dependencyValidation: this.options.enableDependencyValidation,
            auditLogging: this.options.enableAuditLogging
          }
        },
        statistics: {
          totalOperations: this.auditLogEntries.length,
          successfulOperations: this.auditLogEntries.filter((log) => log.status === 'success')
            .length,
          failedOperations: this.auditLogEntries.filter((log) => log.status === 'error').length,
          warningOperations: this.auditLogEntries.filter((log) => log.status === 'warn').length,
          ...stats
        },
        securityAssessment: {
          overallRisk: this._assessOverallSecurityRisk(),
          dataProtectionLevel: this._assessDataProtectionLevel(),
          complianceStatus: this._assessComplianceStatus()
        },
        recommendations: this._generateSecurityRecommendations()
      }

      logger.info('ğŸ“Š Security report generated successfully', {
        totalOperations: report.statistics.totalOperations,
        overallRisk: report.securityAssessment.overallRisk
      })

      return report
    } catch (error) {
      logger.error('âŒ Failed to generate security report:', error)
      return {
        generatedAt: new Date().toISOString(),
        error: error.message,
        operationId: this.operationId,
        status: 'error'
      }
    }
  }

  /**
   * è¯„ä¼°æ€»ä½“å®‰å…¨é£é™©
   * @private
   * @returns {string} é£é™©çº§åˆ«
   */
  _assessOverallSecurityRisk() {
    let riskScore = 0
    const _maxScore = 10 // æœ€å¤§é£é™©åˆ†æ•°ï¼Œä¾›å°†æ¥æ‰©å±•ä½¿ç”¨

    // è„±æ•çº§åˆ«å½±å“
    if (this.options.sanitizationLevel === 'minimal') {
      riskScore += 3
    } else if (this.options.sanitizationLevel === 'moderate') {
      riskScore += 1
    }

    // éªŒè¯åŠŸèƒ½å½±å“
    if (!this.options.enableChecksumVerification) {
      riskScore += 2
    }
    if (!this.options.enableVersionCheck) {
      riskScore += 1
    }
    if (!this.options.enableAuditLogging) {
      riskScore += 2
    }

    // é”™è¯¯ç‡å½±å“
    const errorRate =
      this.auditLogEntries.filter((log) => log.status === 'error').length /
      Math.max(this.auditLogEntries.length, 1)
    if (errorRate > 0.1) {
      riskScore += 2
    }

    if (riskScore >= 7) {
      return 'high'
    }
    if (riskScore >= 4) {
      return 'medium'
    }
    return 'low'
  }

  /**
   * è¯„ä¼°æ•°æ®ä¿æŠ¤çº§åˆ«
   * @private
   * @returns {string} ä¿æŠ¤çº§åˆ«
   */
  _assessDataProtectionLevel() {
    if (this.options.sanitizationLevel === 'strict' && this.options.enableAuditLogging) {
      return 'excellent'
    }
    if (this.options.sanitizationLevel === 'moderate') {
      return 'good'
    }
    if (this.options.sanitizationLevel === 'minimal') {
      return 'basic'
    }
    return 'unknown'
  }

  /**
   * ç”Ÿæˆè¯¦ç»†çš„å®‰å…¨å®¡è®¡æŠ¥å‘Š
   * @returns {Object} å®¡è®¡æŠ¥å‘Š
   */
  generateSecurityAuditReport() {
    const report = {
      operationId: this.operationId,
      timestamp: new Date().toISOString(),
      summary: {
        totalOperations: this.auditLogEntries.length,
        successfulOperations: this.auditLogEntries.filter((log) => log.status === 'success').length,
        failedOperations: this.auditLogEntries.filter((log) => log.status === 'error').length,
        warningOperations: this.auditLogEntries.filter((log) => log.status === 'warn').length
      },
      securityConfiguration: {
        sanitizationLevel: this.options.sanitizationLevel,
        enabledVerifications: {
          checksumVerification: this.options.enableChecksumVerification,
          versionCheck: this.options.enableVersionCheck,
          dependencyValidation: this.options.enableDependencyValidation
        },
        auditingEnabled: this.options.enableAuditLogging
      },
      operationLog: this.auditLogEntries.map((entry) => ({
        timestamp: entry.timestamp,
        operation: entry.operation,
        status: entry.status,
        duration: entry.duration,
        details: entry.details
      })),
      recommendations: this._generateSecurityRecommendations(),
      complianceStatus: this._assessComplianceStatus()
    }

    logger.info('ğŸ›¡ï¸ Security audit report generated', {
      operationId: this.operationId,
      totalOperations: report.summary.totalOperations
    })

    return report
  }

  /**
   * ç§æœ‰è¾…åŠ©æ–¹æ³• - è®°å½•å®¡è®¡æ—¥å¿—
   */
  _auditLog(operation, status, details = {}) {
    if (!this.options.enableAuditLogging) {
      return
    }

    const timestamp = new Date().toISOString()
    const logEntry = {
      timestamp,
      operation,
      status,
      details,
      operationId: this.operationId,
      duration: details.startTime ? Date.now() - details.startTime : null
    }

    this.auditLogEntries.push(logEntry)

    // æ ¹æ®å®¡è®¡çº§åˆ«è®°å½•æ—¥å¿—
    const logLevel = this.options.auditLogLevel
    const message = `ğŸ” Security audit: ${operation} - ${status}`

    switch (status) {
      case 'error':
        logger.error(message, logEntry)
        break
      case 'warn':
        logger.warn(message, logEntry)
        break
      default:
        if (logLevel === 'debug' || (logLevel === 'info' && status !== 'start')) {
          logger.info(message, logEntry)
        }
    }
  }

  /**
   * ç”Ÿæˆæ“ä½œID
   */
  _generateOperationId() {
    return `sec_${Date.now()}_${crypto.randomBytes(4).toString('hex')}`
  }

  /**
   * æ£€æµ‹å“ˆå¸Œç±»å‹
   */
  _detectHashType(hash) {
    if (!hash || hash.startsWith('[REDACTED')) {
      return 'redacted'
    }
    if (hash.startsWith('$2a$') || hash.startsWith('$2b$')) {
      return 'bcrypt'
    }
    if (hash.startsWith('$argon2')) {
      return 'argon2'
    }
    if (hash.startsWith('pbkdf2')) {
      return 'pbkdf2'
    }
    if (hash.length === 64) {
      return 'sha256'
    }
    if (hash.length === 32) {
      return 'md5'
    }
    return 'unknown'
  }

  /**
   * éƒ¨åˆ†æ©ç å¤„ç†
   */
  _partialMask(value, maskRatio = 0.7) {
    if (!value) {
      return value
    }
    const maskLength = Math.floor(value.length * maskRatio)
    const keepLength = value.length - maskLength
    const keepStart = Math.floor(keepLength / 2)
    const keepEnd = keepLength - keepStart

    return (
      value.substring(0, keepStart) +
      '*'.repeat(maskLength) +
      value.substring(value.length - keepEnd)
    )
  }

  /**
   * ç”Ÿæˆå®‰å…¨çš„ä¸´æ—¶å¯†ç 
   */
  _generateSecureTemporaryPassword() {
    const chars = 'ABCDEFGHJKMNPQRSTUVWXYZabcdefghijkmnpqrstuvwxyz23456789!@#$%^&*'
    const array = new Uint8Array(16)
    crypto.getRandomValues(array)
    return Array.from(array, (byte) => chars[byte % chars.length]).join('')
  }

  /**
   * å“ˆå¸Œå¯†ç 
   */
  async _hashPassword(password) {
    const bcrypt = require('bcryptjs')
    return await bcrypt.hash(password, 12)
  }

  /**
   * éªŒè¯å¯†ç å“ˆå¸Œå¼ºåº¦
   */
  _validatePasswordHashStrength(hash) {
    const hashType = this._detectHashType(hash)
    let score = 0
    const recommendations = []

    switch (hashType) {
      case 'argon2':
        score = 5
        break
      case 'bcrypt':
        score = 4
        break
      case 'pbkdf2':
        score = 3
        break
      case 'sha256':
        score = 2
        recommendations.push('Consider upgrading to bcrypt or argon2')
        break
      case 'md5':
        score = 1
        recommendations.push('MD5 is cryptographically broken, upgrade immediately')
        break
      default:
        score = 0
        recommendations.push('Unknown hash type, manual review required')
    }

    return { score, type: hashType, recommendations }
  }

  /**
   * ç”Ÿæˆå¯†ç å®‰å…¨å»ºè®®
   */
  _generatePasswordSecurityRecommendations(result) {
    const recommendations = []

    if (result.securityAlerts.some((alert) => alert.type === 'temp_password_generated')) {
      recommendations.push({
        priority: 'high',
        type: 'password_reset_required',
        message: 'Admin users with temporary passwords must reset passwords immediately',
        action: 'Provide password reset instructions to affected users'
      })
    }

    if (result.warnings.some((warning) => warning.type === 'weak_password_hash')) {
      recommendations.push({
        priority: 'medium',
        type: 'hash_upgrade_recommended',
        message: 'Consider upgrading password hashing algorithm',
        action: 'Implement progressive hash upgrade on next login'
      })
    }

    return recommendations
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºè„±æ•å€¼
   */
  _isRedactedValue(value) {
    return !value || (typeof value === 'string' && value.startsWith('[REDACTED'))
  }

  /**
   * éªŒè¯2FAå¯†é’¥
   */
  _validate2FASecret(secret) {
    if (!secret) {
      return { valid: false, reason: 'Secret is empty' }
    }

    // Base32 æ ¼å¼éªŒè¯
    if (!/^[A-Z2-7]+=*$/i.test(secret)) {
      return { valid: false, reason: 'Invalid Base32 format' }
    }

    // é•¿åº¦éªŒè¯ï¼ˆé€šå¸¸æ˜¯16æˆ–32å­—ç¬¦ï¼‰
    const cleanSecret = secret.replace(/=/g, '')
    if (cleanSecret.length < 16) {
      return { valid: false, reason: 'Secret too short' }
    }

    return { valid: true }
  }

  /**
   * ç”Ÿæˆ2FAå®‰å…¨å»ºè®®
   */
  _generate2FASecurityRecommendations(result) {
    const recommendations = []

    const requiresReconfigCount = result.securityAlerts.filter(
      (alert) => alert.type === '2fa_requires_reconfiguration'
    ).length

    if (requiresReconfigCount > 0) {
      recommendations.push({
        priority: 'high',
        type: '2fa_reconfiguration_required',
        message: `${requiresReconfigCount} users need to reconfigure 2FA`,
        action: 'Send 2FA setup instructions to affected users'
      })
    }

    return recommendations
  }

  /**
   * åˆ†æTokenå®‰å…¨æ€§
   */
  _analyzeTokenSecurity(token) {
    if (!token) {
      return { type: 'empty', algorithm: null }
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºè„±æ•å€¼
    if (this._isRedactedValue(token)) {
      return { type: 'redacted', algorithm: null }
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºåŠ å¯†æ ¼å¼ï¼ˆåŒ…å«å†’å·åˆ†éš”çš„IVï¼‰
    if (token.includes(':') && token.split(':').length === 2) {
      const [iv, encrypted] = token.split(':')
      if (/^[0-9a-fA-F]{32}$/.test(iv) && /^[0-9a-fA-F]+$/.test(encrypted)) {
        return { type: 'encrypted', algorithm: 'aes-256-cbc' }
      }
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºæ—§æ ¼å¼åŠ å¯†
    if (/^[0-9a-fA-F]+$/.test(token) && token.length > 32) {
      return { type: 'encrypted', algorithm: 'legacy' }
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºJWTæ ¼å¼
    if (token.split('.').length === 3) {
      return { type: 'plaintext', algorithm: 'jwt' }
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºæ˜æ–‡token
    if (token.length > 10 && /^[A-Za-z0-9_-]+$/.test(token)) {
      return { type: 'plaintext', algorithm: null }
    }

    return { type: 'invalid', algorithm: null }
  }

  /**
   * æµ‹è¯•Tokenè§£å¯†
   */
  _testTokenDecryption(encryptedToken) {
    try {
      // è¿™é‡Œåº”è¯¥ä½¿ç”¨ä¸ClaudeAccountServiceç›¸åŒçš„è§£å¯†é€»è¾‘
      // ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬åªè¿›è¡Œæ ¼å¼éªŒè¯ï¼Œä¸å®é™…è§£å¯†
      const parts = encryptedToken.split(':')
      if (parts.length !== 2) {
        return { success: false, error: 'Invalid encrypted format' }
      }

      const [iv, encrypted] = parts
      if (!/^[0-9a-fA-F]{32}$/.test(iv)) {
        return { success: false, error: 'Invalid IV format' }
      }

      if (!/^[0-9a-fA-F]+$/.test(encrypted)) {
        return { success: false, error: 'Invalid encrypted data format' }
      }

      return { success: true }
    } catch (error) {
      return { success: false, error: error.message }
    }
  }

  /**
   * ç”ŸæˆTokenå®‰å…¨å»ºè®®
   */
  _generateTokenSecurityRecommendations(result) {
    const recommendations = []

    if (result.tokenStats.plaintext > 0) {
      recommendations.push({
        priority: 'high',
        type: 'encrypt_plaintext_tokens',
        message: `${result.tokenStats.plaintext} plaintext tokens detected`,
        action: 'Encrypt all plaintext tokens for security'
      })
    }

    if (result.securityAlerts.some((alert) => alert.type === 'token_decryption_failed')) {
      recommendations.push({
        priority: 'critical',
        type: 'key_compatibility_issue',
        message: 'Some tokens cannot be decrypted with current encryption key',
        action: 'Verify encryption key compatibility before importing'
      })
    }

    return recommendations
  }

  /**
   * æ¯”è¾ƒç‰ˆæœ¬å·
   */
  _compareVersions(version1, version2) {
    const v1parts = version1.split('.').map(Number)
    const v2parts = version2.split('.').map(Number)

    for (let i = 0; i < Math.max(v1parts.length, v2parts.length); i++) {
      const v1part = v1parts[i] || 0
      const v2part = v2parts[i] || 0

      if (v1part > v2part) {
        return 1
      }
      if (v1part < v2part) {
        return -1
      }
    }

    return 0
  }

  /**
   * è·å–ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µ
   */
  _getVersionCompatibilityMatrix() {
    return {
      '1.0.0': [
        'apiKeys',
        'claudeAccounts',
        'geminiAccounts',
        'openaiAccounts',
        'adminAccounts',
        'systemConfig',
        'usageStats'
      ],
      '1.1.0': [
        'apiKeys',
        'claudeAccounts',
        'geminiAccounts',
        'openaiAccounts',
        'adminAccounts',
        'systemConfig',
        'usageStats',
        'systemStats',
        'twoFactorConfigs',
        'brandingConfig'
      ]
    }
  }

  /**
   * ä»å…ƒæ•°æ®æå–åŠŸèƒ½ç‰¹æ€§
   */
  _extractFeaturesFromMetadata(metadata) {
    const features = []

    if (metadata.categories) {
      features.push(...Object.keys(metadata.categories))
    }

    if (metadata.exportOptions?.includeTwoFactorConfigs) {
      features.push('twoFactorConfigs')
    }

    if (metadata.exportOptions?.includeStats) {
      features.push('advancedStats')
    }

    return [...new Set(features)]
  }

  /**
   * æ£€æµ‹å¾ªç¯ä¾èµ–
   */
  _detectCircularDependencies(dependencyMap) {
    const circular = []
    const visited = new Set()
    const recursionStack = new Set()

    const dfs = (node, nodePath) => {
      if (recursionStack.has(node)) {
        circular.push([...nodePath, node])
        return
      }

      if (visited.has(node)) {
        return
      }

      visited.add(node)
      recursionStack.add(node)

      const deps = dependencyMap[node] || []
      for (const dep of deps) {
        dfs(dep, [...nodePath, node])
      }

      recursionStack.delete(node)
    }

    for (const node of Object.keys(dependencyMap)) {
      if (!visited.has(node)) {
        dfs(node, [])
      }
    }

    return circular
  }

  /**
   * æ£€æŸ¥å¼•ç”¨å®Œæ•´æ€§
   */
  _checkReferenceIntegrity(usageStats, apiKeys) {
    const result = { valid: true, issues: [] }

    if (!Array.isArray(usageStats) || !Array.isArray(apiKeys)) {
      return result
    }

    const apiKeyIds = new Set(apiKeys.map((key) => key.id))

    for (const stat of usageStats) {
      if (stat.keyId && !apiKeyIds.has(stat.keyId)) {
        result.issues.push({
          type: 'orphaned_usage_stat',
          statId: stat.id || 'unknown',
          keyId: stat.keyId,
          message: 'Usage statistic references non-existent API key'
        })
        result.valid = false
      }
    }

    return result
  }

  /**
   * ç”Ÿæˆå®‰å…¨å»ºè®®
   */
  _generateSecurityRecommendations() {
    const recommendations = []

    const errorCount = this.auditLogEntries.filter((log) => log.status === 'error').length
    if (errorCount > 0) {
      recommendations.push({
        priority: 'high',
        category: 'error_handling',
        message: `${errorCount} security operations failed`,
        action: 'Review error logs and resolve security issues before proceeding'
      })
    }

    if (this.options.sanitizationLevel === 'minimal') {
      recommendations.push({
        priority: 'medium',
        category: 'data_sanitization',
        message: 'Minimal sanitization level may expose sensitive data',
        action: 'Consider using strict sanitization level for production exports'
      })
    }

    return recommendations
  }

  /**
   * è¯„ä¼°åˆè§„çŠ¶æ€
   */
  _assessComplianceStatus() {
    const status = {
      overall: 'compliant',
      dataProtection: 'compliant',
      integrityChecks: 'compliant',
      auditTrail: 'compliant',
      issues: []
    }

    // æ£€æŸ¥æ•°æ®ä¿æŠ¤åˆè§„
    if (this.options.sanitizationLevel === 'minimal') {
      status.dataProtection = 'warning'
      status.issues.push('Minimal sanitization may not meet data protection requirements')
    }

    // æ£€æŸ¥å®Œæ•´æ€§æ£€æŸ¥åˆè§„
    if (!this.options.enableChecksumVerification) {
      status.integrityChecks = 'warning'
      status.issues.push('Checksum verification disabled')
    }

    // æ£€æŸ¥å®¡è®¡è·Ÿè¸ªåˆè§„
    if (!this.options.enableAuditLogging) {
      status.auditTrail = 'non-compliant'
      status.issues.push('Audit logging disabled')
    }

    // æ€»ä½“è¯„ä¼°
    if (status.issues.length > 0) {
      status.overall = status.auditTrail === 'non-compliant' ? 'non-compliant' : 'warning'
    }

    return status
  }
}

module.exports = DataSecurityService
