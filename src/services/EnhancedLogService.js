/**
 * @fileoverview å¢å¼ºæ—¥å¿—è®°å½•æœåŠ¡ - é›†æˆHeadersè¿‡æ»¤å’Œè¯¦ç»†ä¿¡æ¯
 *
 * æ‰©å±•ç°æœ‰çš„æ—¥å¿—è®°å½•åŠŸèƒ½ï¼Œæ·»åŠ ï¼š
 * - è¿‡æ»¤åçš„è¯·æ±‚å¤´å’Œå“åº”å¤´ä¿¡æ¯
 * - è¯¦ç»†çš„Tokenç»Ÿè®¡ä¿¡æ¯
 * - è´¹ç”¨è¯¦ç»†ä¿¡æ¯
 * - æ•°æ®å‹ç¼©ä¼˜åŒ–
 *
 * @author Claude Code
 * @version 1.0.0
 */

const logger = require('../utils/logger')
const database = require('../models/database')
const HeadersFilterService = require('./HeadersFilterService')

/**
 * å¢å¼ºæ—¥å¿—è®°å½•æœåŠ¡
 *
 * åŠŸèƒ½ç‰¹æ€§ï¼š
 * - å®‰å…¨çš„Headersè¿‡æ»¤å’Œè®°å½•
 * - è¯¦ç»†çš„Tokenä½¿ç”¨ç»Ÿè®¡
 * - è´¹ç”¨ä¿¡æ¯è®°å½•
 * - å‘åå…¼å®¹ç°æœ‰ç³»ç»Ÿ
 * - å¼‚æ­¥å¤„ç†ä¼˜åŒ–æ€§èƒ½
 */
class EnhancedLogService {
  constructor() {
    this.headersFilter = new HeadersFilterService()
    this.isEnabled = true

    // ç»Ÿè®¡ä¿¡æ¯
    this.stats = {
      totalRequests: 0,
      successfulLogs: 0,
      failedLogs: 0,
      headersFiltered: 0,
      tokenDetailsProcessed: 0,
      costDetailsProcessed: 0,
      dataCompressionSaved: 0,
      averageProcessingTime: 0
    }

    // æ€§èƒ½ç›‘æ§
    this.performanceMetrics = {
      processingTimes: [],
      maxProcessingTime: 0,
      minProcessingTime: Infinity
    }

    // é…ç½®é€‰é¡¹
    this.config = {
      maxHeadersSize: 50000, // 50KB
      maxTokenDetailsSize: 10000, // 10KB
      maxCostDetailsSize: 5000, // 5KB
      enableDataValidation: true,
      enablePerformanceTracking: true
    }
  }

  /**
   * å¢å¼ºçš„æ—¥å¿—è®°å½•æ–¹æ³•
   * @param {Object} logData åŸºç¡€æ—¥å¿—æ•°æ®
   * @param {Object} requestHeaders åŸå§‹è¯·æ±‚å¤´
   * @param {Object} responseHeaders åŸå§‹å“åº”å¤´
   * @param {Object} tokenDetails è¯¦ç»†Tokenä¿¡æ¯
   * @param {Object} costDetails è´¹ç”¨è¯¦ç»†ä¿¡æ¯
   * @param {Object} options è®°å½•é€‰é¡¹
   * @returns {Promise<string|null>} æ—¥å¿—IDæˆ–null
   */
  async logRequestWithDetails(
    logData,
    requestHeaders = {},
    responseHeaders = {},
    tokenDetails = {},
    costDetails = {},
    options = {}
  ) {
    if (!this.isEnabled) {
      return null
    }

    const startTime = Date.now()
    this.stats.totalRequests++

    try {
      // 1. æ•°æ®éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
      if (this.config.enableDataValidation) {
        this._validateInputData(logData, requestHeaders, responseHeaders, tokenDetails, costDetails)
      }

      // 2. è¿‡æ»¤Headersä¿¡æ¯
      const { requestHeaders: filteredRequestHeaders, responseHeaders: filteredResponseHeaders } =
        this.headersFilter.filterHeaders(requestHeaders, responseHeaders, {
          enableCompression: options.enableCompression !== false,
          maxValueLength: options.maxValueLength || 2000,
          includeIpInfo: options.includeIpInfo !== false
        })

      this.stats.headersFiltered++

      // 3. æ„å»ºè¯¦ç»†çš„Tokenä¿¡æ¯
      const enhancedTokenDetails = this._buildTokenDetails(tokenDetails, logData)
      if (Object.keys(enhancedTokenDetails).length > 5) {
        this.stats.tokenDetailsProcessed++
      }

      // 4. æ„å»ºè´¹ç”¨è¯¦ç»†ä¿¡æ¯
      const enhancedCostDetails = this._buildCostDetails(costDetails, logData, enhancedTokenDetails)
      if (enhancedCostDetails.totalCost > 0) {
        this.stats.costDetailsProcessed++
      }

      // 5. æ•°æ®å¤§å°æ£€æŸ¥å’Œå‹ç¼©
      const compressedData = this._optimizeDataSize({
        requestHeaders: filteredRequestHeaders,
        responseHeaders: filteredResponseHeaders,
        tokenDetails: enhancedTokenDetails,
        costDetails: enhancedCostDetails
      })

      // 6. å‡†å¤‡å¢å¼ºçš„æ—¥å¿—æ•°æ®
      const enhancedLogData = {
        ...logData,
        ...compressedData,
        // å…ƒæ•°æ®
        logVersion: '2.1',
        processTime: Date.now() - startTime,
        dataOptimized: compressedData.wasCompressed || false
      }

      // 7. å†™å…¥åˆ°æ•°æ®åº“
      const logId = await database.logRequest(logData.keyId, enhancedLogData, options.ttl)

      this.stats.successfulLogs++

      // 8. æ€§èƒ½ç›‘æ§
      if (this.config.enablePerformanceTracking) {
        this._updatePerformanceMetrics(Date.now() - startTime)
      }

      logger.debug(`ğŸ“ Enhanced log recorded: ${logId} (${Date.now() - startTime}ms)`, {
        keyId: logData.keyId,
        hasHeaders: !!(compressedData.requestHeaders || compressedData.responseHeaders),
        hasTokenDetails: !!enhancedTokenDetails.totalTokens,
        hasCostDetails: !!enhancedCostDetails.totalCost,
        dataOptimized: compressedData.wasCompressed
      })

      return logId
    } catch (error) {
      this.stats.failedLogs++
      logger.error('âŒ Enhanced log recording failed:', {
        keyId: logData.keyId,
        error: error.message,
        processingTime: Date.now() - startTime
      })

      // é™çº§å¤„ç†ï¼šå¦‚æœå¢å¼ºæ—¥å¿—è®°å½•å¤±è´¥ï¼Œå°è¯•è®°å½•åŸºç¡€æ—¥å¿—
      try {
        return await database.logRequest(logData.keyId, logData, options.ttl)
      } catch (fallbackError) {
        logger.error('âŒ Fallback log recording also failed:', fallbackError.message)
        return null
      }
    }
  }

  /**
   * æ„å»ºè¯¦ç»†çš„Tokenç»Ÿè®¡ä¿¡æ¯
   * @private
   * @param {Object} tokenDetails Tokenè¯¦æƒ…
   * @param {Object} logData åŸºç¡€æ—¥å¿—æ•°æ®
   * @returns {Object} å¢å¼ºçš„Tokenè¯¦ç»†ä¿¡æ¯
   */
  _buildTokenDetails(tokenDetails, logData) {
    const details = {
      // åŸºç¡€Tokenä¿¡æ¯
      totalTokens: tokenDetails.totalTokens || logData.tokens || 0,
      inputTokens: tokenDetails.inputTokens || logData.inputTokens || 0,
      outputTokens: tokenDetails.outputTokens || logData.outputTokens || 0,

      // ç¼“å­˜Tokenä¿¡æ¯
      cacheCreateTokens: tokenDetails.cacheCreateTokens || 0,
      cacheReadTokens: tokenDetails.cacheReadTokens || 0,

      // è¯¦ç»†ç¼“å­˜ç±»å‹
      ephemeral5mTokens: tokenDetails.ephemeral5mTokens || 0,
      ephemeral1hTokens: tokenDetails.ephemeral1hTokens || 0,

      // è®¡ç®—å­—æ®µ
      cacheHitRatio: 0,
      tokenEfficiency: 0,

      // æ¨¡å‹ä¿¡æ¯
      model: tokenDetails.model || logData.model || 'unknown',

      // æ—¶é—´æˆ³
      recordedAt: new Date().toISOString()
    }

    // è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
    if (details.totalTokens > 0) {
      details.cacheHitRatio = (details.cacheReadTokens / details.totalTokens) * 100
    }

    // è®¡ç®—Tokenæ•ˆç‡ (è¾“å‡º/è¾“å…¥æ¯”ç‡)
    if (details.inputTokens > 0) {
      details.tokenEfficiency = details.outputTokens / details.inputTokens
    }

    // éªŒè¯æ•°æ®ä¸€è‡´æ€§
    const calculatedTotal =
      details.inputTokens +
      details.outputTokens +
      details.cacheCreateTokens +
      details.cacheReadTokens
    if (Math.abs(calculatedTotal - details.totalTokens) > 5) {
      logger.warn('âš ï¸ Token count mismatch detected:', {
        provided: details.totalTokens,
        calculated: calculatedTotal,
        keyId: logData.keyId
      })
    }

    return details
  }

  /**
   * æ„å»ºè´¹ç”¨è¯¦ç»†ä¿¡æ¯
   * @private
   * @param {Object} costDetails è´¹ç”¨è¯¦æƒ…
   * @param {Object} logData åŸºç¡€æ—¥å¿—æ•°æ®
   * @param {Object} tokenDetails Tokenè¯¦ç»†ä¿¡æ¯
   * @returns {Object} å¢å¼ºçš„è´¹ç”¨è¯¦ç»†ä¿¡æ¯
   */
  _buildCostDetails(costDetails, logData, tokenDetails) {
    const details = {
      // åŸºç¡€è´¹ç”¨ä¿¡æ¯
      totalCost: costDetails.totalCost || 0,
      inputCost: costDetails.inputCost || 0,
      outputCost: costDetails.outputCost || 0,
      cacheCost: costDetails.cacheCost || 0,

      // è´¹ç”¨è®¡ç®—ç»†èŠ‚
      inputTokenPrice: costDetails.inputTokenPrice || 0,
      outputTokenPrice: costDetails.outputTokenPrice || 0,
      cacheTokenPrice: costDetails.cacheTokenPrice || 0,

      // æ±‡ç‡å’Œè´§å¸
      currency: costDetails.currency || 'USD',
      exchangeRate: costDetails.exchangeRate || 1.0,

      // æ—¶é—´ç›¸å…³è´¹ç”¨ä¿¡æ¯
      billingPeriod: costDetails.billingPeriod || 'per-request',
      recordedAt: new Date().toISOString(),

      // æˆæœ¬æ•ˆç›Šåˆ†æ
      costPerToken: 0,
      costPerSecond: 0
    }

    // è®¡ç®—æ¯Tokenæˆæœ¬
    if (tokenDetails.totalTokens > 0) {
      details.costPerToken = details.totalCost / tokenDetails.totalTokens
    }

    // è®¡ç®—æ¯ç§’æˆæœ¬ï¼ˆå¦‚æœæœ‰å“åº”æ—¶é—´ï¼‰
    if (logData.responseTime > 0) {
      details.costPerSecond = details.totalCost / (logData.responseTime / 1000)
    }

    // éªŒè¯è´¹ç”¨ä¸€è‡´æ€§
    const calculatedTotal = details.inputCost + details.outputCost + details.cacheCost
    if (Math.abs(calculatedTotal - details.totalCost) > 0.001) {
      logger.debug('ğŸ’° Cost calculation verification:', {
        provided: details.totalCost,
        calculated: calculatedTotal,
        keyId: logData.keyId
      })
    }

    return details
  }

  /**
   * æ‰¹é‡è®°å½•å¤šä¸ªè¯·æ±‚çš„æ—¥å¿—
   * @param {Array<Object>} logEntries æ—¥å¿—æ¡ç›®æ•°ç»„
   * @param {Object} options æ‰¹é‡é€‰é¡¹
   * @returns {Promise<Array>} è®°å½•ç»“æœæ•°ç»„
   */
  async batchLogRequests(logEntries, options = {}) {
    if (!this.isEnabled || !Array.isArray(logEntries) || logEntries.length === 0) {
      return []
    }

    const startTime = Date.now()
    const results = []
    const batchSize = options.batchSize || 10

    logger.info(`ğŸ“Š Starting batch log processing: ${logEntries.length} entries`)

    // åˆ†æ‰¹å¤„ç†ä»¥æ§åˆ¶å†…å­˜ä½¿ç”¨
    for (let i = 0; i < logEntries.length; i += batchSize) {
      const batch = logEntries.slice(i, i + batchSize)

      const batchPromises = batch.map(async (entry, index) => {
        try {
          const logId = await this.logRequestWithDetails(
            entry.logData,
            entry.requestHeaders,
            entry.responseHeaders,
            entry.tokenDetails,
            entry.costDetails,
            entry.options
          )

          return {
            index: i + index,
            success: true,
            logId,
            error: null
          }
        } catch (error) {
          return {
            index: i + index,
            success: false,
            logId: null,
            error: error.message
          }
        }
      })

      const batchResults = await Promise.all(batchPromises)
      results.push(...batchResults)

      // çŸ­æš‚å»¶è¿Ÿä»¥å‡å°‘ç³»ç»Ÿå‹åŠ›
      if (i + batchSize < logEntries.length) {
        await new Promise((resolve) => setTimeout(resolve, 10))
      }
    }

    const processingTime = Date.now() - startTime
    const successCount = results.filter((r) => r.success).length

    logger.info(
      `ğŸ“Š Batch log processing completed: ${successCount}/${logEntries.length} successful (${processingTime}ms)`
    )

    return results
  }

  /**
   * å¯ç”¨æ—¥å¿—è®°å½•
   */
  enable() {
    this.isEnabled = true
    logger.info('âœ… Enhanced log service enabled')
  }

  /**
   * ç¦ç”¨æ—¥å¿—è®°å½•
   */
  disable() {
    this.isEnabled = false
    logger.info('â›” Enhanced log service disabled')
  }

  /**
   * éªŒè¯è¾“å…¥æ•°æ®
   * @private
   * @param {Object} logData æ—¥å¿—æ•°æ®
   * @param {Object} requestHeaders è¯·æ±‚å¤´
   * @param {Object} responseHeaders å“åº”å¤´
   * @param {Object} tokenDetails Tokenè¯¦æƒ…
   * @param {Object} costDetails è´¹ç”¨è¯¦æƒ…
   */
  _validateInputData(logData, requestHeaders, responseHeaders, tokenDetails, costDetails) {
    // åŸºç¡€æ•°æ®éªŒè¯
    if (!logData || typeof logData !== 'object') {
      throw new Error('logData must be a valid object')
    }

    if (!logData.keyId) {
      throw new Error('logData.keyId is required')
    }

    // Headerså¤§å°æ£€æŸ¥
    const headersSize = JSON.stringify({ requestHeaders, responseHeaders }).length
    if (headersSize > this.config.maxHeadersSize) {
      logger.warn(
        `âš ï¸ Headers data too large: ${headersSize} bytes (max: ${this.config.maxHeadersSize})`
      )
    }

    // Tokenè¯¦æƒ…å¤§å°æ£€æŸ¥
    if (tokenDetails && Object.keys(tokenDetails).length > 0) {
      const tokenDetailsSize = JSON.stringify(tokenDetails).length
      if (tokenDetailsSize > this.config.maxTokenDetailsSize) {
        logger.warn(
          `âš ï¸ Token details too large: ${tokenDetailsSize} bytes (max: ${this.config.maxTokenDetailsSize})`
        )
      }
    }

    // è´¹ç”¨è¯¦æƒ…å¤§å°æ£€æŸ¥
    if (costDetails && Object.keys(costDetails).length > 0) {
      const costDetailsSize = JSON.stringify(costDetails).length
      if (costDetailsSize > this.config.maxCostDetailsSize) {
        logger.warn(
          `âš ï¸ Cost details too large: ${costDetailsSize} bytes (max: ${this.config.maxCostDetailsSize})`
        )
      }
    }
  }

  /**
   * ä¼˜åŒ–æ•°æ®å¤§å°
   * @private
   * @param {Object} data æ•°æ®å¯¹è±¡
   * @returns {Object} ä¼˜åŒ–åçš„æ•°æ®
   */
  _optimizeDataSize(data) {
    let wasCompressed = false
    const originalSize = JSON.stringify(data).length

    // å¦‚æœæ•°æ®å¤ªå¤§ï¼Œè¿›è¡Œå‹ç¼©ä¼˜åŒ–
    if (originalSize > 100000) {
      // 100KB
      wasCompressed = true
      this.stats.dataCompressionSaved++

      logger.debug(`ğŸ—œï¸ Compressing large log data: ${originalSize} bytes`)

      // ç®€å•çš„å‹ç¼©ç­–ç•¥ï¼šç§»é™¤ç©ºå­—æ®µã€ç®€åŒ–é‡å¤æ•°æ®
      const optimizedData = this._compressLogData(data)

      const newSize = JSON.stringify(optimizedData).length
      logger.debug(
        `âœ… Data compression completed: ${originalSize} â†’ ${newSize} bytes (${(((originalSize - newSize) / originalSize) * 100).toFixed(1)}% saved)`
      )

      return {
        ...optimizedData,
        wasCompressed
      }
    }

    return {
      ...data,
      wasCompressed
    }
  }

  /**
   * å‹ç¼©æ—¥å¿—æ•°æ®
   * @private
   * @param {Object} data åŸå§‹æ•°æ®
   * @returns {Object} å‹ç¼©åçš„æ•°æ®
   */
  _compressLogData(data) {
    const compressed = { ...data }

    // ç§»é™¤ç©ºå€¼å’Œæ— æ•ˆæ•°æ®
    Object.keys(compressed).forEach((key) => {
      if (compressed[key] === null || compressed[key] === undefined || compressed[key] === '') {
        delete compressed[key]
      }
    })

    // ç®€åŒ–Headersæ•°æ®
    if (compressed.requestHeaders && Object.keys(compressed.requestHeaders).length > 20) {
      compressed.requestHeaders = this._simplifyHeaders(compressed.requestHeaders)
    }

    if (compressed.responseHeaders && Object.keys(compressed.responseHeaders).length > 20) {
      compressed.responseHeaders = this._simplifyHeaders(compressed.responseHeaders)
    }

    return compressed
  }

  /**
   * ç®€åŒ–Headersæ•°æ®
   * @private
   * @param {Object} headers Headerså¯¹è±¡
   * @returns {Object} ç®€åŒ–åçš„Headers
   */
  _simplifyHeaders(headers) {
    const important = ['user-agent', 'content-type', 'authorization', 'x-request-id']
    const simplified = {}

    // ä¿ç•™é‡è¦å¤´éƒ¨
    important.forEach((key) => {
      const value = headers[key] || headers[key.toLowerCase()]
      if (value) {
        simplified[key] = value
      }
    })

    // æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    simplified['_original_count'] = Object.keys(headers).length
    simplified['_simplified'] = true

    return simplified
  }

  /**
   * æ›´æ–°æ€§èƒ½æŒ‡æ ‡
   * @private
   * @param {number} processingTime å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
   */
  _updatePerformanceMetrics(processingTime) {
    this.performanceMetrics.processingTimes.push(processingTime)

    // ä¿æŒæœ€è¿‘1000æ¬¡è®°å½•
    if (this.performanceMetrics.processingTimes.length > 1000) {
      this.performanceMetrics.processingTimes.shift()
    }

    // æ›´æ–°æœ€å¤§æœ€å°å€¼
    this.performanceMetrics.maxProcessingTime = Math.max(
      this.performanceMetrics.maxProcessingTime,
      processingTime
    )
    this.performanceMetrics.minProcessingTime = Math.min(
      this.performanceMetrics.minProcessingTime,
      processingTime
    )

    // è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
    const times = this.performanceMetrics.processingTimes
    this.stats.averageProcessingTime = times.reduce((sum, time) => sum + time, 0) / times.length
  }

  /**
   * è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
   * @returns {Object} ç»Ÿè®¡ä¿¡æ¯
   */
  getStats() {
    return {
      ...this.stats,
      isEnabled: this.isEnabled,
      headersFilterStats: this.headersFilter.getFilterStats(),
      performanceMetrics: {
        ...this.performanceMetrics,
        averageProcessingTime: this.stats.averageProcessingTime,
        totalSamples: this.performanceMetrics.processingTimes.length
      },
      config: this.config,
      successRate:
        this.stats.totalRequests > 0
          ? (this.stats.successfulLogs / this.stats.totalRequests) * 100
          : 0
    }
  }

  /**
   * é‡ç½®ç»Ÿè®¡ä¿¡æ¯
   */
  resetStats() {
    this.stats = {
      totalRequests: 0,
      successfulLogs: 0,
      failedLogs: 0,
      headersFiltered: 0
    }
    logger.info('ğŸ”„ Enhanced log service stats reset')
  }

  /**
   * æ›´æ–°Headersè¿‡æ»¤é…ç½®
   * @param {string} type ç±»å‹ ('request' | 'response')
   * @param {Array<string>} whitelist ç™½åå•æ•°ç»„
   */
  updateHeadersFilter(type, whitelist) {
    this.headersFilter.updateWhitelist(type, whitelist)
    logger.info(`ğŸ”„ Headers filter updated: ${type}`)
  }

  /**
   * éªŒè¯æ—¥å¿—æ•°æ®å®Œæ•´æ€§
   * @param {string} logId æ—¥å¿—ID
   * @returns {Promise<Object>} éªŒè¯ç»“æœ
   */
  async validateLogData(logId) {
    try {
      const verification = await database.verifyLogWrite(logId)
      return {
        isValid: verification.success,
        data: verification.data,
        hasHeaders: !!(verification.data?.requestHeaders || verification.data?.responseHeaders),
        hasTokenDetails: !!verification.data?.tokenDetails,
        hasCostDetails: !!verification.data?.costDetails,
        logVersion: verification.data?.logVersion || '1.0'
      }
    } catch (error) {
      logger.error(`âŒ Log validation failed for ${logId}:`, error)
      return {
        isValid: false,
        error: error.message
      }
    }
  }
}

// åˆ›å»ºå•ä¾‹å®ä¾‹
const enhancedLogService = new EnhancedLogService()

module.exports = {
  EnhancedLogService,
  enhancedLogService
}
